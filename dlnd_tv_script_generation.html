<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_tv_script_generation</title><script src="https://unpkg.com/jupyter-js-widgets@2.0.*/dist/embed.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="TV-Script-Generation">TV Script Generation<a class="anchor-link" href="#TV-Script-Generation">&#182;</a></h1><p>In this project, you'll generate your own <a href="https://en.wikipedia.org/wiki/The_Simpsons">Simpsons</a> TV scripts using RNNs.  You'll be using part of the <a href="https://www.kaggle.com/wcukierski/the-simpsons-by-the-data">Simpsons dataset</a> of scripts from 27 seasons.  The Neural Network you'll build will generate a new TV script for a scene at <a href="https://simpsonswiki.com/wiki/Moe&#39;s_Tavern">Moe's Tavern</a>.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>The data is already provided for you.  You'll be using a subset of the original dataset.  It consists of only the scenes in Moe's Tavern.  This doesn't include other versions of the tavern, like "Moe's Cavern", "Flaming Moe's", "Uncle Moe's Family Feed-Bag", etc..</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;./data/simpsons/moes_tavern_lines.txt&#39;</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
<span class="c1"># Ignore notice, since we don&#39;t use it for analysing the data</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="mi">81</span><span class="p">:]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with <code>view_sentence_range</code> to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>
<span class="n">scenes</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of scenes: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">scenes</span><span class="p">)))</span>
<span class="n">sentence_count_scene</span> <span class="o">=</span> <span class="p">[</span><span class="n">scene</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">scene</span> <span class="ow">in</span> <span class="n">scenes</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of sentences in each scene: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">sentence_count_scene</span><span class="p">)))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span> <span class="k">for</span> <span class="n">scene</span> <span class="ow">in</span> <span class="n">scenes</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">scene</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of lines: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="n">word_count_sentence</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in each line: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_count_sentence</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 11492
Number of scenes: 262
Average number of sentences in each scene: 15.248091603053435
Number of lines: 4257
Average number of words in each line: 11.50434578341555

The sentences 0 to 10:
Moe_Szyslak: (INTO PHONE) Moe&#39;s Tavern. Where the elite meet to drink.
Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.
Moe_Szyslak: (INTO PHONE) Hold on, I&#39;ll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?
Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I&#39;m gonna catch you, and I&#39;m gonna carve my name on your back with an ice pick.
Moe_Szyslak: What&#39;s the matter Homer? You&#39;re not your normal effervescent self.
Homer_Simpson: I got my problems, Moe. Give me another one.
Moe_Szyslak: Homer, hey, you should not drink to forget your problems.
Barney_Gumble: Yeah, you should only drink to enhance your social skills.


</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Functions">Implement Preprocessing Functions<a class="anchor-link" href="#Implement-Preprocessing-Functions">&#182;</a></h2><p>The first thing to do to any dataset is preprocessing.  Implement the following preprocessing functions below:</p>
<ul>
<li>Lookup Table</li>
<li>Tokenize Punctuation</li>
</ul>
<h3 id="Lookup-Table">Lookup Table<a class="anchor-link" href="#Lookup-Table">&#182;</a></h3><p>To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:</p>
<ul>
<li>Dictionary to go from the words to an id, we'll call <code>vocab_to_int</code></li>
<li>Dictionary to go from the id to word, we'll call <code>int_to_vocab</code></li>
</ul>
<p>Return these dictionaries in the following tuple <code>(vocab_to_int, int_to_vocab)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="k">def</span> <span class="nf">create_lookup_tables</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create lookup tables for vocabulary</span>
<span class="sd">    :param text: The text of tv scripts split into words</span>
<span class="sd">    :return: A tuple of dicts (vocab_to_int, int_to_vocab)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vocab_to_int</span> <span class="o">=</span> <span class="p">{</span> <span class="n">word</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">))}</span>
    <span class="n">int_to_vocab</span> <span class="o">=</span> <span class="p">{</span> <span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]:</span> <span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab_to_int</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">vocab_to_int</span><span class="p">,</span> <span class="n">int_to_vocab</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_create_lookup_tables</span><span class="p">(</span><span class="n">create_lookup_tables</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tokenize-Punctuation">Tokenize Punctuation<a class="anchor-link" href="#Tokenize-Punctuation">&#182;</a></h3><p>We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks make it hard for the neural network to distinguish between the word "bye" and "bye!".</p>
<p>Implement the function <code>token_lookup</code> to return a dict that will be used to tokenize symbols like "!" into "||Exclamation_Mark||".  Create a dictionary for the following symbols where the symbol is the key and value is the token:</p>
<ul>
<li>Period ( . )</li>
<li>Comma ( , )</li>
<li>Quotation Mark ( " )</li>
<li>Semicolon ( ; )</li>
<li>Exclamation mark ( ! )</li>
<li>Question mark ( ? )</li>
<li>Left Parentheses ( ( )</li>
<li>Right Parentheses ( ) )</li>
<li>Dash ( -- )</li>
<li>Return ( \n )</li>
</ul>
<p>This dictionary will be used to token the symbols and add the delimiter (space) around it.  This separates the symbols as it's own word, making it easier for the neural network to predict on the next word. Make sure you don't use a token that could be confused as a word. Instead of using the token "dash", try using something like "||dash||".</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">token_lookup</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate a dict to turn punctuation into a token.</span>
<span class="sd">    :return: Tokenize dictionary where the key is the punctuation and the value is the token</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;.&#39;</span><span class="p">:</span> <span class="s1">&#39;||Period||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;,&#39;</span><span class="p">:</span> <span class="s1">&#39;||Comma||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;&quot;&#39;</span><span class="p">:</span> <span class="s1">&#39;||Quotation_Mark||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;;&#39;</span><span class="p">:</span> <span class="s1">&#39;||Semicolon||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;!&#39;</span><span class="p">:</span> <span class="s1">&#39;||Exclamation_Mark||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;?&#39;</span><span class="p">:</span> <span class="s1">&#39;||Question_Mark||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;(&#39;</span><span class="p">:</span> <span class="s1">&#39;||Left_Parentheses||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;)&#39;</span><span class="p">:</span> <span class="s1">&#39;||Right_Parenttheses||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;--&#39;</span><span class="p">:</span> <span class="s1">&#39;||Dash||&#39;</span><span class="p">,</span>
        <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">:</span> <span class="s1">&#39;||Return&#39;</span>
    <span class="p">}</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_tokenize</span><span class="p">(</span><span class="n">token_lookup</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h2><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Preprocess Training, Validation, and Testing Data</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">token_lookup</span><span class="p">,</span> <span class="n">create_lookup_tables</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">int_text</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">,</span> <span class="n">int_to_vocab</span><span class="p">,</span> <span class="n">token_dict</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a RNN by implementing the following functions below:</p>
<ul>
<li>get_inputs</li>
<li>get_init_cell</li>
<li>get_embed</li>
<li>build_rnn</li>
<li>build_nn</li>
<li>get_batches</li>
</ul>
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.0&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.0 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.0.0
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/ubuntu/anaconda3/envs/cpu/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: No GPU found. Please use a GPU to train your neural network.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>get_inputs()</code> function to create TF Placeholders for the Neural Network.  It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a> <code>name</code> parameter.</li>
<li>Targets placeholder</li>
<li>Learning Rate placeholder</li>
</ul>
<p>Return the placeholders in the following tuple <code>(Input, Targets, LearningRate)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, and learning rate.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">input_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">)</span>
    <span class="n">target_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">input_placeholder</span><span class="p">,</span> <span class="n">target_placeholder</span><span class="p">,</span> <span class="n">lr</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_inputs</span><span class="p">(</span><span class="n">get_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-RNN-Cell-and-Initialize">Build RNN Cell and Initialize<a class="anchor-link" href="#Build-RNN-Cell-and-Initialize">&#182;</a></h3><p>Stack one or more <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell"><code>BasicLSTMCells</code></a> in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell"><code>MultiRNNCell</code></a>.</p>
<ul>
<li>The Rnn size should be set using <code>rnn_size</code></li>
<li>Initalize Cell State using the MultiRNNCell's <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell#zero_state"><code>zero_state()</code></a> function<ul>
<li>Apply the name "initial_state" to the initial state using <a href="https://www.tensorflow.org/api_docs/python/tf/identity"><code>tf.identity()</code></a></li>
</ul>
</li>
</ul>
<p>Return the cell and initial state in the following tuple <code>(Cell, InitialState)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_init_cell</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create an RNN Cell and initialize it.</span>
<span class="sd">    :param batch_size: Size of batches</span>
<span class="sd">    :param rnn_size: Size of RNNs</span>
<span class="sd">    :return: Tuple (cell, initialize state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)]</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">initial_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="s2">&quot;initial_state&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cell</span><span class="p">,</span> <span class="n">initial_state</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_init_cell</span><span class="p">(</span><span class="n">get_init_cell</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Word-Embedding">Word Embedding<a class="anchor-link" href="#Word-Embedding">&#182;</a></h3><p>Apply embedding to <code>input_data</code> using TensorFlow.  Return the embedded sequence.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_embed</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create embedding for &lt;input_data&gt;.</span>
<span class="sd">    :param input_data: TF placeholder for text input.</span>
<span class="sd">    :param vocab_size: Number of words in vocabulary.</span>
<span class="sd">    :param embed_dim: Number of embedding dimensions</span>
<span class="sd">    :return: Embedded input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_embed</span><span class="p">(</span><span class="n">get_embed</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-RNN">Build RNN<a class="anchor-link" href="#Build-RNN">&#182;</a></h3><p>You created a RNN Cell in the <code>get_init_cell()</code> function.  Time to use the cell to create a RNN.</p>
<ul>
<li>Build the RNN using the <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a><ul>
<li>Apply the name "final_state" to the final state using <a href="https://www.tensorflow.org/api_docs/python/tf/identity"><code>tf.identity()</code></a></li>
</ul>
</li>
</ul>
<p>Return the outputs and final_state state in the following tuple <code>(Outputs, FinalState)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a RNN using a RNN Cell</span>
<span class="sd">    :param cell: RNN Cell</span>
<span class="sd">    :param inputs: Input text data</span>
<span class="sd">    :return: Tuple (Outputs, Final State)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;build_rnn cell=&#39;</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">finalstate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="s2">&quot;final_state&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">finalstate</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_build_rnn</span><span class="p">(</span><span class="n">build_rnn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>build_rnn cell= &lt;tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.MultiRNNCell object at 0x7fa18a8fb278&gt;
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Apply embedding to <code>input_data</code> using your <code>get_embed(input_data, vocab_size, embed_dim)</code> function.</li>
<li>Build RNN using <code>cell</code> and your <code>build_rnn(cell, inputs)</code> function.</li>
<li>Apply a fully connected layer with a linear activation and <code>vocab_size</code> as the number of outputs.</li>
</ul>
<p>Return the logits and final state in the following tuple (Logits, FinalState)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_nn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build part of the neural network</span>
<span class="sd">    :param cell: RNN cell</span>
<span class="sd">    :param rnn_size: Size of rnns</span>
<span class="sd">    :param input_data: Input data</span>
<span class="sd">    :param vocab_size: Vocabulary size</span>
<span class="sd">    :param embed_dim: Number of embedding dimensions</span>
<span class="sd">    :return: Tuple (Logits, FinalState)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">enc_embed_input</span> <span class="o">=</span> <span class="n">get_embed</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
    <span class="n">rnn</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="n">build_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">enc_embed_input</span><span class="p">)</span>
    <span class="c1"># rnn = tf.concat(rnn, axis=1)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;input_data&#39;</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;rnn_size&#39;</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;vocab_size&#39;</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;rnn&#39;</span><span class="p">,</span> <span class="n">rnn</span><span class="p">)</span>
    <span class="c1"># print(&#39;rnn shape&#39;, rnn.get_shape())  # batch_size * sequence_length * num_features (embeding_size)</span>
    <span class="c1"># seq_output = tf.concat(rnn, axis=1)</span>
    <span class="c1"># print(&#39;seq_output&#39;, seq_output)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">rnn</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
    <span class="c1"># print([128,5] + [vocab_size])</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">):</span>
        <span class="n">softmax_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">((</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
        <span class="n">softmax_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">))</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">softmax_w</span><span class="p">)</span> <span class="o">+</span> <span class="n">softmax_b</span>
    
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># Handle place-holder dimension</span>
        <span class="n">rnn_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">rnn</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="n">rnn_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sequence_length&#39;</span><span class="p">,</span> <span class="n">rnn_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">[</span><span class="n">rnn_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">rnn_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">vocab_size</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">[</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">vocab_size</span><span class="p">])</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">final_state</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_build_nn</span><span class="p">(</span><span class="n">build_nn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>build_rnn cell= &lt;tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.MultiRNNCell object at 0x7fa18a7cedd8&gt;
input_data Tensor(&#34;Placeholder:0&#34;, shape=(128, 5), dtype=int32)
rnn_size 256
vocab_size 27
rnn Tensor(&#34;rnn/transpose:0&#34;, shape=(128, 5, 256), dtype=float32)
output Tensor(&#34;Reshape:0&#34;, shape=(640, 256), dtype=float32)
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Batches">Batches<a class="anchor-link" href="#Batches">&#182;</a></h3><p>Implement <code>get_batches</code> to create batches of input and targets using <code>int_text</code>.  The batches should be a Numpy array with the shape <code>(number of batches, 2, batch size, sequence length)</code>. Each batch contains two elements:</p>
<ul>
<li>The first element is a single batch of <strong>input</strong> with the shape <code>[batch size, sequence length]</code></li>
<li>The second element is a single batch of <strong>targets</strong> with the shape <code>[batch size, sequence length]</code></li>
</ul>
<p>If you can't fill the last batch with enough data, drop the last batch.</p>
<p>For exmple, <code>get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 2, 3)</code> would return a Numpy array of the following:</p>

<pre><code>[
  # First Batch
  [
    # Batch of Input
    [[ 1  2  3], [ 7  8  9]],
    # Batch of targets
    [[ 2  3  4], [ 8  9 10]]
  ],

  # Second Batch
  [
    # Batch of Input
    [[ 4  5  6], [10 11 12]],
    # Batch of targets
    [[ 5  6  7], [11 12 13]]
  ]
]</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">int_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return batches of input and target</span>
<span class="sd">    :param int_text: Text with the words replaced by their ids</span>
<span class="sd">    :param batch_size: The size of batch</span>
<span class="sd">    :param seq_length: The length of sequence</span>
<span class="sd">    :return: Batches as a Numpy array</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;seq_length&#39;</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">)</span>
    <span class="n">batch_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">int_text</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">seq_length</span><span class="p">))</span>
    <span class="n">int_length</span> <span class="o">=</span> <span class="n">batch_count</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">seq_length</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">int_text</span><span class="p">[:</span><span class="n">int_length</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">int_text</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">int_length</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">)</span>
    
    <span class="c1"># print(outputs)</span>
    <span class="c1"># Merge inputs and outputs?</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batches</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_batches</span><span class="p">(</span><span class="n">get_batches</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>batch_size 128
seq_length 5
[[[[   0    1    2    3    4]
   [   5    6    7    8    9]
   [  10   11   12   13   14]
   ..., 
   [ 625  626  627  628  629]
   [ 630  631  632  633  634]
   [ 635  636  637  638  639]]

  [[   1    2    3    4    5]
   [   6    7    8    9   10]
   [  11   12   13   14   15]
   ..., 
   [ 626  627  628  629  630]
   [ 631  632  633  634  635]
   [ 636  637  638  639  640]]]


 [[[ 640  641  642  643  644]
   [ 645  646  647  648  649]
   [ 650  651  652  653  654]
   ..., 
   [1265 1266 1267 1268 1269]
   [1270 1271 1272 1273 1274]
   [1275 1276 1277 1278 1279]]

  [[ 641  642  643  644  645]
   [ 646  647  648  649  650]
   [ 651  652  653  654  655]
   ..., 
   [1266 1267 1268 1269 1270]
   [1271 1272 1273 1274 1275]
   [1276 1277 1278 1279 1280]]]


 [[[1280 1281 1282 1283 1284]
   [1285 1286 1287 1288 1289]
   [1290 1291 1292 1293 1294]
   ..., 
   [1905 1906 1907 1908 1909]
   [1910 1911 1912 1913 1914]
   [1915 1916 1917 1918 1919]]

  [[1281 1282 1283 1284 1285]
   [1286 1287 1288 1289 1290]
   [1291 1292 1293 1294 1295]
   ..., 
   [1906 1907 1908 1909 1910]
   [1911 1912 1913 1914 1915]
   [1916 1917 1918 1919 1920]]]


 ..., 
 [[[2560 2561 2562 2563 2564]
   [2565 2566 2567 2568 2569]
   [2570 2571 2572 2573 2574]
   ..., 
   [3185 3186 3187 3188 3189]
   [3190 3191 3192 3193 3194]
   [3195 3196 3197 3198 3199]]

  [[2561 2562 2563 2564 2565]
   [2566 2567 2568 2569 2570]
   [2571 2572 2573 2574 2575]
   ..., 
   [3186 3187 3188 3189 3190]
   [3191 3192 3193 3194 3195]
   [3196 3197 3198 3199 3200]]]


 [[[3200 3201 3202 3203 3204]
   [3205 3206 3207 3208 3209]
   [3210 3211 3212 3213 3214]
   ..., 
   [3825 3826 3827 3828 3829]
   [3830 3831 3832 3833 3834]
   [3835 3836 3837 3838 3839]]

  [[3201 3202 3203 3204 3205]
   [3206 3207 3208 3209 3210]
   [3211 3212 3213 3214 3215]
   ..., 
   [3826 3827 3828 3829 3830]
   [3831 3832 3833 3834 3835]
   [3836 3837 3838 3839 3840]]]


 [[[3840 3841 3842 3843 3844]
   [3845 3846 3847 3848 3849]
   [3850 3851 3852 3853 3854]
   ..., 
   [4465 4466 4467 4468 4469]
   [4470 4471 4472 4473 4474]
   [4475 4476 4477 4478 4479]]

  [[3841 3842 3843 3844 3845]
   [3846 3847 3848 3849 3850]
   [3851 3852 3853 3854 3855]
   ..., 
   [4466 4467 4468 4469 4470]
   [4471 4472 4473 4474 4475]
   [4476 4477 4478 4479 4480]]]]
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>num_epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>embed_dim</code> to the size of the embedding.</li>
<li>Set <code>seq_length</code> to the length of sequence.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>show_every_n_batches</code> to the number of batches the neural network should print progress.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span>  <span class="c1"># average sentence size</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1"># Embedding Dimension Size</span>
<span class="n">embed_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Sequence Length</span>
<span class="n">seq_length</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Show stats for every n number of batches</span>
<span class="n">show_every_n_batches</span> <span class="o">=</span> <span class="mi">1</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_dir</span> <span class="o">=</span> <span class="s1">&#39;./save&#39;</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib</span> <span class="k">import</span> <span class="n">seq2seq</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_to_vocab</span><span class="p">)</span>
    <span class="n">input_text</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">get_inputs</span><span class="p">()</span>
    <span class="n">input_data_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>
    <span class="n">cell</span><span class="p">,</span> <span class="n">initial_state</span> <span class="o">=</span> <span class="n">get_init_cell</span><span class="p">(</span><span class="n">input_data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">rnn_size</span><span class="p">)</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="n">build_nn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>

    <span class="c1"># Probabilities for generating words</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;probs&#39;</span><span class="p">)</span>

    <span class="c1"># Loss function</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
        <span class="n">logits</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">input_data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_data_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>

    <span class="c1"># Optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

    <span class="c1"># Gradient Clipping</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>build_rnn cell= &lt;tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.MultiRNNCell object at 0x7fa18a812978&gt;
input_data Tensor(&#34;input:0&#34;, shape=(?, ?), dtype=int32)
rnn_size 100
vocab_size 6779
rnn Tensor(&#34;rnn/transpose:0&#34;, shape=(?, ?, 100), dtype=float32)
output Tensor(&#34;Reshape:0&#34;, shape=(?, 100), dtype=float32)
batch_size Tensor(&#34;strided_slice_1:0&#34;, shape=(), dtype=int32)
sequence_length Tensor(&#34;strided_slice_2:0&#34;, shape=(), dtype=int32)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h2><p>Train the neural network on the preprocessed data.  If you have a hard time getting a good loss, check the <a href="https://discussions.udacity.com/">forms</a> to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">batches</span> <span class="o">=</span> <span class="n">get_batches</span><span class="p">(</span><span class="n">int_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">initial_state</span><span class="p">,</span> <span class="p">{</span><span class="n">input_text</span><span class="p">:</span> <span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>

        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batches</span><span class="p">):</span>
            <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">input_text</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                <span class="n">targets</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
                <span class="n">initial_state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">}</span>
            <span class="n">train_loss</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">cost</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">train_op</span><span class="p">],</span> <span class="n">feed</span><span class="p">)</span>

            <span class="c1"># Show every &lt;show_every_n_batches&gt; batches</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">epoch_i</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span> <span class="o">+</span> <span class="n">batch_i</span><span class="p">)</span> <span class="o">%</span> <span class="n">show_every_n_batches</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">   train_loss = </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">epoch_i</span><span class="p">,</span>
                    <span class="n">batch_i</span><span class="p">,</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">),</span>
                    <span class="n">train_loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>batch_size 12
seq_length 10
[[[[5638 4636  532 ..., 6239 3139  971]
   [2475 1089 6149 ..., 4257 2592 4662]
   [2592 6577 2592 ..., 3624 4911 2592]
   ..., 
   [2812 3754 5983 ..., 6239 1946 5638]
   [2821  971 2252 ..., 3754 2573 2868]
   [3714 6239 1946 ..., 2732 2592 5348]]

  [[4636  532 5384 ..., 3139  971 2475]
   [1089 6149 2293 ..., 2592 4662 2592]
   [6577 2592 6107 ..., 4911 2592 6167]
   ..., 
   [3754 5983 3041 ..., 1946 5638 2821]
   [ 971 2252 5039 ..., 2573 2868 3714]
   [6239 1946 3228 ..., 2592 5348 6239]]]


 [[[6239 2786 3601 ..., 5638 5039 2592]
   [1259 2592 1494 ..., 5169 3754 2732]
   [6239 1946 5858 ...,  204 2293 6149]
   ..., 
   [3993 4709 6239 ..., 3161 6022 1075]
   [4777 2740  971 ..., 6053 1946 5638]
   [4636 5670 3041 ..., 2128  197 5410]]

  [[2786 3601 4384 ..., 5039 2592 1259]
   [2592 1494 3718 ..., 3754 2732 6239]
   [1946 5858 4662 ..., 2293 6149 3878]
   ..., 
   [4709 6239 4807 ..., 6022 1075 4777]
   [2740  971 5888 ..., 1946 5638 4636]
   [5670 3041 5780 ...,  197 5410 4488]]]


 [[[4488 1075 4475 ..., 2592 1095 5621]
   [2592 5348 6239 ..., 4636 6603 2700]
   [6447 6239 1946 ..., 2691 3312 6107]
   ..., 
   [4567 4438 5217 ..., 2700 1087 2713]
   [6036 2442 3044 ..., 5217 3196 4709]
   [6149 2867 5410 ..., 1946 5858 6460]]

  [[1075 4475 2837 ..., 1095 5621 2592]
   [5348 6239 6239 ..., 6603 2700 6447]
   [6239 1946 1946 ..., 3312 6107  971]
   ..., 
   [4438 5217  971 ..., 1087 2713 6036]
   [2442 3044 6149 ..., 3196 4709 6149]
   [2867 5410 5973 ..., 5858 6460 2592]]]


 ..., 
 [[[2700 2166 5420 ..., 1422 5074 5385]
   [1779 1524 1348 ..., 1494 4614 4526]
   [6239 2848 6236 ..., 6239 6239 6460]
   ..., 
   [4265 6053 1946 ..., 2592 5039 2592]
   [2700 4274 1494 ..., 1946 3228 4662]
   [2592 1202 2270 ..., 4567 5888 6239]]

  [[2166 5420 1494 ..., 5074 5385 1779]
   [1524 1348 2592 ..., 4614 4526 6239]
   [2848 6236 2700 ..., 6239 6460 2592]
   ..., 
   [6053 1946 1946 ..., 5039 2592 2700]
   [4274 1494  147 ..., 3228 4662 2592]
   [1202 2270 6239 ..., 5888 6239 1933]]]


 [[[1933 3505 2592 ..., 5858 1259 2592]
   [5348 2592  895 ..., 2646 5217  971]
   [4723 2837 1946 ..., 1868 5779 2646]
   ..., 
   [3604 1362 6239 ..., 2682 1232 6239]
   [4636 6149 5039 ..., 6239 2700  688]
   [2162 5180 1003 ..., 1002   20 2592]]

  [[3505 2592 1933 ..., 1259 2592 5348]
   [2592  895 1933 ..., 5217  971 4723]
   [2837 1946 5638 ..., 5779 2646 5160]
   ..., 
   [1362 6239 2713 ..., 1232 6239 4636]
   [6149 5039 6053 ..., 2700  688 2162]
   [5180 1003 1027 ...,   20 2592 5039]]]


 [[[5039 6239 4282 ..., 4754 6239 1946]
   [3228 5233 2592 ...,  273 3196 3551]
   [5217 4567 2966 ..., 1663 2592 5418]
   ..., 
   [3196 4983 6239 ..., 2536 1362 2837]
   [1946 4660 1307 ..., 1429  396 2166]
   [6149 2867  622 ..., 4150 2700 5513]]

  [[6239 4282 4199 ..., 6239 1946 3228]
   [5233 2592 5348 ..., 3196 3551 5217]
   [4567 2966 2592 ..., 2592 5418 6239]
   ..., 
   [4983 6239 1946 ..., 1362 2837 1946]
   [4660 1307  588 ...,  396 2166 6149]
   [2867  622 1429 ..., 2700 5513 2700]]]]
Epoch   0 Batch    0/575   train_loss = 8.821
Epoch   0 Batch    1/575   train_loss = 8.819
Epoch   0 Batch    2/575   train_loss = 8.818
Epoch   0 Batch    3/575   train_loss = 8.815
Epoch   0 Batch    4/575   train_loss = 8.810
Epoch   0 Batch    5/575   train_loss = 8.809
Epoch   0 Batch    6/575   train_loss = 8.804
Epoch   0 Batch    7/575   train_loss = 8.803
Epoch   0 Batch    8/575   train_loss = 8.795
Epoch   0 Batch    9/575   train_loss = 8.787
Epoch   0 Batch   10/575   train_loss = 8.778
Epoch   0 Batch   11/575   train_loss = 8.769
Epoch   0 Batch   12/575   train_loss = 8.756
Epoch   0 Batch   13/575   train_loss = 8.737
Epoch   0 Batch   14/575   train_loss = 8.707
Epoch   0 Batch   15/575   train_loss = 8.692
Epoch   0 Batch   16/575   train_loss = 8.653
Epoch   0 Batch   17/575   train_loss = 8.529
Epoch   0 Batch   18/575   train_loss = 8.487
Epoch   0 Batch   19/575   train_loss = 8.501
Epoch   0 Batch   20/575   train_loss = 8.269
Epoch   0 Batch   21/575   train_loss = 8.165
Epoch   0 Batch   22/575   train_loss = 8.278
Epoch   0 Batch   23/575   train_loss = 7.937
Epoch   0 Batch   24/575   train_loss = 7.923
Epoch   0 Batch   25/575   train_loss = 7.743
Epoch   0 Batch   26/575   train_loss = 7.807
Epoch   0 Batch   27/575   train_loss = 7.372
Epoch   0 Batch   28/575   train_loss = 7.131
Epoch   0 Batch   29/575   train_loss = 7.257
Epoch   0 Batch   30/575   train_loss = 7.554
Epoch   0 Batch   31/575   train_loss = 7.704
Epoch   0 Batch   32/575   train_loss = 7.013
Epoch   0 Batch   33/575   train_loss = 7.051
Epoch   0 Batch   34/575   train_loss = 6.842
Epoch   0 Batch   35/575   train_loss = 6.813
Epoch   0 Batch   36/575   train_loss = 7.153
Epoch   0 Batch   37/575   train_loss = 6.161
Epoch   0 Batch   38/575   train_loss = 6.925
Epoch   0 Batch   39/575   train_loss = 6.235
Epoch   0 Batch   40/575   train_loss = 6.039
Epoch   0 Batch   41/575   train_loss = 7.697
Epoch   0 Batch   42/575   train_loss = 6.654
Epoch   0 Batch   43/575   train_loss = 6.788
Epoch   0 Batch   44/575   train_loss = 6.597
Epoch   0 Batch   45/575   train_loss = 6.449
Epoch   0 Batch   46/575   train_loss = 6.562
Epoch   0 Batch   47/575   train_loss = 6.403
Epoch   0 Batch   48/575   train_loss = 6.031
Epoch   0 Batch   49/575   train_loss = 6.058
Epoch   0 Batch   50/575   train_loss = 6.212
Epoch   0 Batch   51/575   train_loss = 6.288
Epoch   0 Batch   52/575   train_loss = 6.494
Epoch   0 Batch   53/575   train_loss = 6.555
Epoch   0 Batch   54/575   train_loss = 6.810
Epoch   0 Batch   55/575   train_loss = 6.569
Epoch   0 Batch   56/575   train_loss = 6.275
Epoch   0 Batch   57/575   train_loss = 6.495
Epoch   0 Batch   58/575   train_loss = 6.172
Epoch   0 Batch   59/575   train_loss = 5.968
Epoch   0 Batch   60/575   train_loss = 6.273
Epoch   0 Batch   61/575   train_loss = 6.514
Epoch   0 Batch   62/575   train_loss = 6.216
Epoch   0 Batch   63/575   train_loss = 6.902
Epoch   0 Batch   64/575   train_loss = 6.548
Epoch   0 Batch   65/575   train_loss = 6.648
Epoch   0 Batch   66/575   train_loss = 6.281
Epoch   0 Batch   67/575   train_loss = 6.354
Epoch   0 Batch   68/575   train_loss = 6.351
Epoch   0 Batch   69/575   train_loss = 6.096
Epoch   0 Batch   70/575   train_loss = 6.280
Epoch   0 Batch   71/575   train_loss = 6.290
Epoch   0 Batch   72/575   train_loss = 6.478
Epoch   0 Batch   73/575   train_loss = 6.500
Epoch   0 Batch   74/575   train_loss = 6.950
Epoch   0 Batch   75/575   train_loss = 6.352
Epoch   0 Batch   76/575   train_loss = 6.753
Epoch   0 Batch   77/575   train_loss = 6.599
Epoch   0 Batch   78/575   train_loss = 6.615
Epoch   0 Batch   79/575   train_loss = 6.374
Epoch   0 Batch   80/575   train_loss = 6.365
Epoch   0 Batch   81/575   train_loss = 6.180
Epoch   0 Batch   82/575   train_loss = 6.041
Epoch   0 Batch   83/575   train_loss = 5.989
Epoch   0 Batch   84/575   train_loss = 6.198
Epoch   0 Batch   85/575   train_loss = 6.948
Epoch   0 Batch   86/575   train_loss = 6.115
Epoch   0 Batch   87/575   train_loss = 6.470
Epoch   0 Batch   88/575   train_loss = 5.576
Epoch   0 Batch   89/575   train_loss = 6.168
Epoch   0 Batch   90/575   train_loss = 6.334
Epoch   0 Batch   91/575   train_loss = 6.405
Epoch   0 Batch   92/575   train_loss = 6.922
Epoch   0 Batch   93/575   train_loss = 6.528
Epoch   0 Batch   94/575   train_loss = 6.107
Epoch   0 Batch   95/575   train_loss = 6.267
Epoch   0 Batch   96/575   train_loss = 6.400
Epoch   0 Batch   97/575   train_loss = 6.381
Epoch   0 Batch   98/575   train_loss = 6.075
Epoch   0 Batch   99/575   train_loss = 7.094
Epoch   0 Batch  100/575   train_loss = 6.708
Epoch   0 Batch  101/575   train_loss = 6.020
Epoch   0 Batch  102/575   train_loss = 5.922
Epoch   0 Batch  103/575   train_loss = 6.533
Epoch   0 Batch  104/575   train_loss = 6.310
Epoch   0 Batch  105/575   train_loss = 6.294
Epoch   0 Batch  106/575   train_loss = 6.271
Epoch   0 Batch  107/575   train_loss = 5.972
Epoch   0 Batch  108/575   train_loss = 6.567
Epoch   0 Batch  109/575   train_loss = 6.370
Epoch   0 Batch  110/575   train_loss = 5.606
Epoch   0 Batch  111/575   train_loss = 6.083
Epoch   0 Batch  112/575   train_loss = 6.465
Epoch   0 Batch  113/575   train_loss = 6.692
Epoch   0 Batch  114/575   train_loss = 6.387
Epoch   0 Batch  115/575   train_loss = 6.095
Epoch   0 Batch  116/575   train_loss = 6.181
Epoch   0 Batch  117/575   train_loss = 5.841
Epoch   0 Batch  118/575   train_loss = 6.554
Epoch   0 Batch  119/575   train_loss = 6.781
Epoch   0 Batch  120/575   train_loss = 6.422
Epoch   0 Batch  121/575   train_loss = 6.557
Epoch   0 Batch  122/575   train_loss = 6.438
Epoch   0 Batch  123/575   train_loss = 6.065
Epoch   0 Batch  124/575   train_loss = 6.598
Epoch   0 Batch  125/575   train_loss = 6.514
Epoch   0 Batch  126/575   train_loss = 6.428
Epoch   0 Batch  127/575   train_loss = 5.800
Epoch   0 Batch  128/575   train_loss = 6.015
Epoch   0 Batch  129/575   train_loss = 6.279
Epoch   0 Batch  130/575   train_loss = 6.110
Epoch   0 Batch  131/575   train_loss = 5.780
Epoch   0 Batch  132/575   train_loss = 5.954
Epoch   0 Batch  133/575   train_loss = 6.288
Epoch   0 Batch  134/575   train_loss = 6.259
Epoch   0 Batch  135/575   train_loss = 5.752
Epoch   0 Batch  136/575   train_loss = 7.111
Epoch   0 Batch  137/575   train_loss = 6.229
Epoch   0 Batch  138/575   train_loss = 6.764
Epoch   0 Batch  139/575   train_loss = 6.650
Epoch   0 Batch  140/575   train_loss = 6.524
Epoch   0 Batch  141/575   train_loss = 6.948
Epoch   0 Batch  142/575   train_loss = 7.555
Epoch   0 Batch  143/575   train_loss = 6.467
Epoch   0 Batch  144/575   train_loss = 6.054
Epoch   0 Batch  145/575   train_loss = 5.981
Epoch   0 Batch  146/575   train_loss = 5.869
Epoch   0 Batch  147/575   train_loss = 6.002
Epoch   0 Batch  148/575   train_loss = 5.487
Epoch   0 Batch  149/575   train_loss = 6.109
Epoch   0 Batch  150/575   train_loss = 6.457
Epoch   0 Batch  151/575   train_loss = 6.198
Epoch   0 Batch  152/575   train_loss = 5.901
Epoch   0 Batch  153/575   train_loss = 5.607
Epoch   0 Batch  154/575   train_loss = 5.777
Epoch   0 Batch  155/575   train_loss = 6.319
Epoch   0 Batch  156/575   train_loss = 5.994
Epoch   0 Batch  157/575   train_loss = 6.175
Epoch   0 Batch  158/575   train_loss = 6.081
Epoch   0 Batch  159/575   train_loss = 6.615
Epoch   0 Batch  160/575   train_loss = 6.012
Epoch   0 Batch  161/575   train_loss = 6.557
Epoch   0 Batch  162/575   train_loss = 6.407
Epoch   0 Batch  163/575   train_loss = 6.061
Epoch   0 Batch  164/575   train_loss = 6.622
Epoch   0 Batch  165/575   train_loss = 6.561
Epoch   0 Batch  166/575   train_loss = 5.843
Epoch   0 Batch  167/575   train_loss = 5.942
Epoch   0 Batch  168/575   train_loss = 6.407
Epoch   0 Batch  169/575   train_loss = 5.945
Epoch   0 Batch  170/575   train_loss = 6.536
Epoch   0 Batch  171/575   train_loss = 6.134
Epoch   0 Batch  172/575   train_loss = 6.369
Epoch   0 Batch  173/575   train_loss = 6.179
Epoch   0 Batch  174/575   train_loss = 6.684
Epoch   0 Batch  175/575   train_loss = 6.363
Epoch   0 Batch  176/575   train_loss = 6.202
Epoch   0 Batch  177/575   train_loss = 6.388
Epoch   0 Batch  178/575   train_loss = 6.483
Epoch   0 Batch  179/575   train_loss = 6.159
Epoch   0 Batch  180/575   train_loss = 6.085
Epoch   0 Batch  181/575   train_loss = 6.538
Epoch   0 Batch  182/575   train_loss = 6.243
Epoch   0 Batch  183/575   train_loss = 6.538
Epoch   0 Batch  184/575   train_loss = 5.748
Epoch   0 Batch  185/575   train_loss = 6.024
Epoch   0 Batch  186/575   train_loss = 6.580
Epoch   0 Batch  187/575   train_loss = 5.994
Epoch   0 Batch  188/575   train_loss = 6.126
Epoch   0 Batch  189/575   train_loss = 5.977
Epoch   0 Batch  190/575   train_loss = 6.154
Epoch   0 Batch  191/575   train_loss = 6.579
Epoch   0 Batch  192/575   train_loss = 6.369
Epoch   0 Batch  193/575   train_loss = 6.187
Epoch   0 Batch  194/575   train_loss = 6.482
Epoch   0 Batch  195/575   train_loss = 5.860
Epoch   0 Batch  196/575   train_loss = 5.875
Epoch   0 Batch  197/575   train_loss = 5.769
Epoch   0 Batch  198/575   train_loss = 6.504
Epoch   0 Batch  199/575   train_loss = 5.725
Epoch   0 Batch  200/575   train_loss = 5.839
Epoch   0 Batch  201/575   train_loss = 6.108
Epoch   0 Batch  202/575   train_loss = 5.578
Epoch   0 Batch  203/575   train_loss = 5.863
Epoch   0 Batch  204/575   train_loss = 5.966
Epoch   0 Batch  205/575   train_loss = 5.937
Epoch   0 Batch  206/575   train_loss = 6.301
Epoch   0 Batch  207/575   train_loss = 5.686
Epoch   0 Batch  208/575   train_loss = 5.536
Epoch   0 Batch  209/575   train_loss = 5.861
Epoch   0 Batch  210/575   train_loss = 5.931
Epoch   0 Batch  211/575   train_loss = 6.927
Epoch   0 Batch  212/575   train_loss = 6.325
Epoch   0 Batch  213/575   train_loss = 6.205
Epoch   0 Batch  214/575   train_loss = 5.890
Epoch   0 Batch  215/575   train_loss = 5.454
Epoch   0 Batch  216/575   train_loss = 5.999
Epoch   0 Batch  217/575   train_loss = 5.779
Epoch   0 Batch  218/575   train_loss = 6.140
Epoch   0 Batch  219/575   train_loss = 6.175
Epoch   0 Batch  220/575   train_loss = 5.496
Epoch   0 Batch  221/575   train_loss = 6.310
Epoch   0 Batch  222/575   train_loss = 6.459
Epoch   0 Batch  223/575   train_loss = 6.286
Epoch   0 Batch  224/575   train_loss = 5.815
Epoch   0 Batch  225/575   train_loss = 6.234
Epoch   0 Batch  226/575   train_loss = 6.426
Epoch   0 Batch  227/575   train_loss = 6.371
Epoch   0 Batch  228/575   train_loss = 6.428
Epoch   0 Batch  229/575   train_loss = 5.379
Epoch   0 Batch  230/575   train_loss = 5.572
Epoch   0 Batch  231/575   train_loss = 6.031
Epoch   0 Batch  232/575   train_loss = 5.860
Epoch   0 Batch  233/575   train_loss = 6.320
Epoch   0 Batch  234/575   train_loss = 6.089
Epoch   0 Batch  235/575   train_loss = 5.656
Epoch   0 Batch  236/575   train_loss = 5.348
Epoch   0 Batch  237/575   train_loss = 5.876
Epoch   0 Batch  238/575   train_loss = 5.844
Epoch   0 Batch  239/575   train_loss = 6.080
Epoch   0 Batch  240/575   train_loss = 6.228
Epoch   0 Batch  241/575   train_loss = 6.561
Epoch   0 Batch  242/575   train_loss = 5.719
Epoch   0 Batch  243/575   train_loss = 6.291
Epoch   0 Batch  244/575   train_loss = 5.978
Epoch   0 Batch  245/575   train_loss = 6.155
Epoch   0 Batch  246/575   train_loss = 6.333
Epoch   0 Batch  247/575   train_loss = 5.723
Epoch   0 Batch  248/575   train_loss = 6.154
Epoch   0 Batch  249/575   train_loss = 6.126
Epoch   0 Batch  250/575   train_loss = 5.778
Epoch   0 Batch  251/575   train_loss = 6.339
Epoch   0 Batch  252/575   train_loss = 6.228
Epoch   0 Batch  253/575   train_loss = 5.913
Epoch   0 Batch  254/575   train_loss = 5.623
Epoch   0 Batch  255/575   train_loss = 6.178
Epoch   0 Batch  256/575   train_loss = 5.966
Epoch   0 Batch  257/575   train_loss = 6.196
Epoch   0 Batch  258/575   train_loss = 6.546
Epoch   0 Batch  259/575   train_loss = 5.848
Epoch   0 Batch  260/575   train_loss = 5.727
Epoch   0 Batch  261/575   train_loss = 6.665
Epoch   0 Batch  262/575   train_loss = 6.320
Epoch   0 Batch  263/575   train_loss = 5.950
Epoch   0 Batch  264/575   train_loss = 5.430
Epoch   0 Batch  265/575   train_loss = 5.292
Epoch   0 Batch  266/575   train_loss = 5.561
Epoch   0 Batch  267/575   train_loss = 5.919
Epoch   0 Batch  268/575   train_loss = 5.924
Epoch   0 Batch  269/575   train_loss = 6.012
Epoch   0 Batch  270/575   train_loss = 6.442
Epoch   0 Batch  271/575   train_loss = 5.767
Epoch   0 Batch  272/575   train_loss = 6.283
Epoch   0 Batch  273/575   train_loss = 6.138
Epoch   0 Batch  274/575   train_loss = 6.061
Epoch   0 Batch  275/575   train_loss = 6.188
Epoch   0 Batch  276/575   train_loss = 6.552
Epoch   0 Batch  277/575   train_loss = 5.590
Epoch   0 Batch  278/575   train_loss = 5.844
Epoch   0 Batch  279/575   train_loss = 5.877
Epoch   0 Batch  280/575   train_loss = 6.473
Epoch   0 Batch  281/575   train_loss = 5.548
Epoch   0 Batch  282/575   train_loss = 5.884
Epoch   0 Batch  283/575   train_loss = 6.427
Epoch   0 Batch  284/575   train_loss = 6.473
Epoch   0 Batch  285/575   train_loss = 5.886
Epoch   0 Batch  286/575   train_loss = 6.132
Epoch   0 Batch  287/575   train_loss = 6.238
Epoch   0 Batch  288/575   train_loss = 5.930
Epoch   0 Batch  289/575   train_loss = 6.077
Epoch   0 Batch  290/575   train_loss = 6.384
Epoch   0 Batch  291/575   train_loss = 7.028
Epoch   0 Batch  292/575   train_loss = 6.248
Epoch   0 Batch  293/575   train_loss = 6.617
Epoch   0 Batch  294/575   train_loss = 6.419
Epoch   0 Batch  295/575   train_loss = 5.898
Epoch   0 Batch  296/575   train_loss = 5.829
Epoch   0 Batch  297/575   train_loss = 5.924
Epoch   0 Batch  298/575   train_loss = 6.150
Epoch   0 Batch  299/575   train_loss = 6.173
Epoch   0 Batch  300/575   train_loss = 5.904
Epoch   0 Batch  301/575   train_loss = 5.949
Epoch   0 Batch  302/575   train_loss = 6.233
Epoch   0 Batch  303/575   train_loss = 5.555
Epoch   0 Batch  304/575   train_loss = 5.693
Epoch   0 Batch  305/575   train_loss = 5.773
Epoch   0 Batch  306/575   train_loss = 6.282
Epoch   0 Batch  307/575   train_loss = 6.331
Epoch   0 Batch  308/575   train_loss = 6.249
Epoch   0 Batch  309/575   train_loss = 6.398
Epoch   0 Batch  310/575   train_loss = 6.136
Epoch   0 Batch  311/575   train_loss = 5.510
Epoch   0 Batch  312/575   train_loss = 6.240
Epoch   0 Batch  313/575   train_loss = 6.486
Epoch   0 Batch  314/575   train_loss = 6.209
Epoch   0 Batch  315/575   train_loss = 6.611
Epoch   0 Batch  316/575   train_loss = 6.102
Epoch   0 Batch  317/575   train_loss = 5.572
Epoch   0 Batch  318/575   train_loss = 5.480
Epoch   0 Batch  319/575   train_loss = 5.981
Epoch   0 Batch  320/575   train_loss = 5.671
Epoch   0 Batch  321/575   train_loss = 6.668
Epoch   0 Batch  322/575   train_loss = 5.883
Epoch   0 Batch  323/575   train_loss = 6.154
Epoch   0 Batch  324/575   train_loss = 5.863
Epoch   0 Batch  325/575   train_loss = 6.190
Epoch   0 Batch  326/575   train_loss = 5.972
Epoch   0 Batch  327/575   train_loss = 6.214
Epoch   0 Batch  328/575   train_loss = 6.293
Epoch   0 Batch  329/575   train_loss = 6.299
Epoch   0 Batch  330/575   train_loss = 5.977
Epoch   0 Batch  331/575   train_loss = 6.605
Epoch   0 Batch  332/575   train_loss = 6.348
Epoch   0 Batch  333/575   train_loss = 6.313
Epoch   0 Batch  334/575   train_loss = 5.809
Epoch   0 Batch  335/575   train_loss = 5.933
Epoch   0 Batch  336/575   train_loss = 6.098
Epoch   0 Batch  337/575   train_loss = 6.190
Epoch   0 Batch  338/575   train_loss = 5.644
Epoch   0 Batch  339/575   train_loss = 6.100
Epoch   0 Batch  340/575   train_loss = 5.978
Epoch   0 Batch  341/575   train_loss = 5.884
Epoch   0 Batch  342/575   train_loss = 5.557
Epoch   0 Batch  343/575   train_loss = 6.177
Epoch   0 Batch  344/575   train_loss = 6.136
Epoch   0 Batch  345/575   train_loss = 5.849
Epoch   0 Batch  346/575   train_loss = 6.499
Epoch   0 Batch  347/575   train_loss = 5.719
Epoch   0 Batch  348/575   train_loss = 5.550
Epoch   0 Batch  349/575   train_loss = 5.584
Epoch   0 Batch  350/575   train_loss = 6.079
Epoch   0 Batch  351/575   train_loss = 6.460
Epoch   0 Batch  352/575   train_loss = 6.066
Epoch   0 Batch  353/575   train_loss = 6.202
Epoch   0 Batch  354/575   train_loss = 5.881
Epoch   0 Batch  355/575   train_loss = 6.540
Epoch   0 Batch  356/575   train_loss = 5.923
Epoch   0 Batch  357/575   train_loss = 5.770
Epoch   0 Batch  358/575   train_loss = 6.102
Epoch   0 Batch  359/575   train_loss = 6.582
Epoch   0 Batch  360/575   train_loss = 5.508
Epoch   0 Batch  361/575   train_loss = 6.306
Epoch   0 Batch  362/575   train_loss = 5.856
Epoch   0 Batch  363/575   train_loss = 5.977
Epoch   0 Batch  364/575   train_loss = 5.526
Epoch   0 Batch  365/575   train_loss = 6.141
Epoch   0 Batch  366/575   train_loss = 5.590
Epoch   0 Batch  367/575   train_loss = 5.967
Epoch   0 Batch  368/575   train_loss = 6.470
Epoch   0 Batch  369/575   train_loss = 6.174
Epoch   0 Batch  370/575   train_loss = 6.278
Epoch   0 Batch  371/575   train_loss = 6.352
Epoch   0 Batch  372/575   train_loss = 5.843
Epoch   0 Batch  373/575   train_loss = 6.258
Epoch   0 Batch  374/575   train_loss = 5.421
Epoch   0 Batch  375/575   train_loss = 5.682
Epoch   0 Batch  376/575   train_loss = 5.969
Epoch   0 Batch  377/575   train_loss = 6.285
Epoch   0 Batch  378/575   train_loss = 6.443
Epoch   0 Batch  379/575   train_loss = 5.905
Epoch   0 Batch  380/575   train_loss = 5.559
Epoch   0 Batch  381/575   train_loss = 5.940
Epoch   0 Batch  382/575   train_loss = 6.085
Epoch   0 Batch  383/575   train_loss = 5.846
Epoch   0 Batch  384/575   train_loss = 5.950
Epoch   0 Batch  385/575   train_loss = 5.642
Epoch   0 Batch  386/575   train_loss = 5.608
Epoch   0 Batch  387/575   train_loss = 6.213
Epoch   0 Batch  388/575   train_loss = 5.841
Epoch   0 Batch  389/575   train_loss = 5.724
Epoch   0 Batch  390/575   train_loss = 6.059
Epoch   0 Batch  391/575   train_loss = 6.425
Epoch   0 Batch  392/575   train_loss = 5.834
Epoch   0 Batch  393/575   train_loss = 5.837
Epoch   0 Batch  394/575   train_loss = 6.169
Epoch   0 Batch  395/575   train_loss = 5.351
Epoch   0 Batch  396/575   train_loss = 5.966
Epoch   0 Batch  397/575   train_loss = 6.320
Epoch   0 Batch  398/575   train_loss = 6.263
Epoch   0 Batch  399/575   train_loss = 6.263
Epoch   0 Batch  400/575   train_loss = 6.149
Epoch   0 Batch  401/575   train_loss = 5.512
Epoch   0 Batch  402/575   train_loss = 5.784
Epoch   0 Batch  403/575   train_loss = 6.125
Epoch   0 Batch  404/575   train_loss = 6.353
Epoch   0 Batch  405/575   train_loss = 6.195
Epoch   0 Batch  406/575   train_loss = 5.576
Epoch   0 Batch  407/575   train_loss = 5.776
Epoch   0 Batch  408/575   train_loss = 6.139
Epoch   0 Batch  409/575   train_loss = 5.767
Epoch   0 Batch  410/575   train_loss = 5.865
Epoch   0 Batch  411/575   train_loss = 5.834
Epoch   0 Batch  412/575   train_loss = 6.378
Epoch   0 Batch  413/575   train_loss = 6.776
Epoch   0 Batch  414/575   train_loss = 6.300
Epoch   0 Batch  415/575   train_loss = 6.664
Epoch   0 Batch  416/575   train_loss = 5.951
Epoch   0 Batch  417/575   train_loss = 5.787
Epoch   0 Batch  418/575   train_loss = 5.842
Epoch   0 Batch  419/575   train_loss = 5.801
Epoch   0 Batch  420/575   train_loss = 5.907
Epoch   0 Batch  421/575   train_loss = 6.474
Epoch   0 Batch  422/575   train_loss = 5.981
Epoch   0 Batch  423/575   train_loss = 6.865
Epoch   0 Batch  424/575   train_loss = 6.741
Epoch   0 Batch  425/575   train_loss = 6.341
Epoch   0 Batch  426/575   train_loss = 6.114
Epoch   0 Batch  427/575   train_loss = 5.898
Epoch   0 Batch  428/575   train_loss = 5.911
Epoch   0 Batch  429/575   train_loss = 5.600
Epoch   0 Batch  430/575   train_loss = 5.902
Epoch   0 Batch  431/575   train_loss = 5.962
Epoch   0 Batch  432/575   train_loss = 6.339
Epoch   0 Batch  433/575   train_loss = 6.339
Epoch   0 Batch  434/575   train_loss = 6.122
Epoch   0 Batch  435/575   train_loss = 6.098
Epoch   0 Batch  436/575   train_loss = 5.643
Epoch   0 Batch  437/575   train_loss = 6.153
Epoch   0 Batch  438/575   train_loss = 6.233
Epoch   0 Batch  439/575   train_loss = 6.021
Epoch   0 Batch  440/575   train_loss = 6.047
Epoch   0 Batch  441/575   train_loss = 6.164
Epoch   0 Batch  442/575   train_loss = 6.042
Epoch   0 Batch  443/575   train_loss = 6.058
Epoch   0 Batch  444/575   train_loss = 6.075
Epoch   0 Batch  445/575   train_loss = 5.852
Epoch   0 Batch  446/575   train_loss = 5.888
Epoch   0 Batch  447/575   train_loss = 6.175
Epoch   0 Batch  448/575   train_loss = 5.795
Epoch   0 Batch  449/575   train_loss = 6.174
Epoch   0 Batch  450/575   train_loss = 6.715
Epoch   0 Batch  451/575   train_loss = 6.595
Epoch   0 Batch  452/575   train_loss = 6.776
Epoch   0 Batch  453/575   train_loss = 6.215
Epoch   0 Batch  454/575   train_loss = 6.363
Epoch   0 Batch  455/575   train_loss = 5.779
Epoch   0 Batch  456/575   train_loss = 6.494
Epoch   0 Batch  457/575   train_loss = 5.704
Epoch   0 Batch  458/575   train_loss = 6.227
Epoch   0 Batch  459/575   train_loss = 6.408
Epoch   0 Batch  460/575   train_loss = 6.269
Epoch   0 Batch  461/575   train_loss = 6.424
Epoch   0 Batch  462/575   train_loss = 5.824
Epoch   0 Batch  463/575   train_loss = 6.030
Epoch   0 Batch  464/575   train_loss = 5.572
Epoch   0 Batch  465/575   train_loss = 5.949
Epoch   0 Batch  466/575   train_loss = 5.963
Epoch   0 Batch  467/575   train_loss = 5.499
Epoch   0 Batch  468/575   train_loss = 5.656
Epoch   0 Batch  469/575   train_loss = 6.315
Epoch   0 Batch  470/575   train_loss = 6.560
Epoch   0 Batch  471/575   train_loss = 5.686
Epoch   0 Batch  472/575   train_loss = 6.269
Epoch   0 Batch  473/575   train_loss = 5.939
Epoch   0 Batch  474/575   train_loss = 6.028
Epoch   0 Batch  475/575   train_loss = 5.745
Epoch   0 Batch  476/575   train_loss = 5.898
Epoch   0 Batch  477/575   train_loss = 6.293
Epoch   0 Batch  478/575   train_loss = 6.570
Epoch   0 Batch  479/575   train_loss = 6.169
Epoch   0 Batch  480/575   train_loss = 6.381
Epoch   0 Batch  481/575   train_loss = 6.373
Epoch   0 Batch  482/575   train_loss = 5.293
Epoch   0 Batch  483/575   train_loss = 6.837
Epoch   0 Batch  484/575   train_loss = 6.072
Epoch   0 Batch  485/575   train_loss = 6.367
Epoch   0 Batch  486/575   train_loss = 6.143
Epoch   0 Batch  487/575   train_loss = 6.086
Epoch   0 Batch  488/575   train_loss = 5.895
Epoch   0 Batch  489/575   train_loss = 6.270
Epoch   0 Batch  490/575   train_loss = 6.295
Epoch   0 Batch  491/575   train_loss = 5.584
Epoch   0 Batch  492/575   train_loss = 5.026
Epoch   0 Batch  493/575   train_loss = 5.494
Epoch   0 Batch  494/575   train_loss = 5.606
Epoch   0 Batch  495/575   train_loss = 5.865
Epoch   0 Batch  496/575   train_loss = 6.067
Epoch   0 Batch  497/575   train_loss = 6.256
Epoch   0 Batch  498/575   train_loss = 5.619
Epoch   0 Batch  499/575   train_loss = 5.754
Epoch   0 Batch  500/575   train_loss = 5.829
Epoch   0 Batch  501/575   train_loss = 5.957
Epoch   0 Batch  502/575   train_loss = 5.306
Epoch   0 Batch  503/575   train_loss = 6.052
Epoch   0 Batch  504/575   train_loss = 5.739
Epoch   0 Batch  505/575   train_loss = 5.745
Epoch   0 Batch  506/575   train_loss = 6.109
Epoch   0 Batch  507/575   train_loss = 6.236
Epoch   0 Batch  508/575   train_loss = 6.087
Epoch   0 Batch  509/575   train_loss = 6.105
Epoch   0 Batch  510/575   train_loss = 5.591
Epoch   0 Batch  511/575   train_loss = 5.374
Epoch   0 Batch  512/575   train_loss = 6.308
Epoch   0 Batch  513/575   train_loss = 6.090
Epoch   0 Batch  514/575   train_loss = 5.900
Epoch   0 Batch  515/575   train_loss = 6.078
Epoch   0 Batch  516/575   train_loss = 6.209
Epoch   0 Batch  517/575   train_loss = 5.819
Epoch   0 Batch  518/575   train_loss = 5.843
Epoch   0 Batch  519/575   train_loss = 5.765
Epoch   0 Batch  520/575   train_loss = 5.005
Epoch   0 Batch  521/575   train_loss = 5.705
Epoch   0 Batch  522/575   train_loss = 5.701
Epoch   0 Batch  523/575   train_loss = 6.660
Epoch   0 Batch  524/575   train_loss = 7.998
Epoch   0 Batch  525/575   train_loss = 5.665
Epoch   0 Batch  526/575   train_loss = 5.749
Epoch   0 Batch  527/575   train_loss = 5.957
Epoch   0 Batch  528/575   train_loss = 5.585
Epoch   0 Batch  529/575   train_loss = 5.867
Epoch   0 Batch  530/575   train_loss = 6.140
Epoch   0 Batch  531/575   train_loss = 5.985
Epoch   0 Batch  532/575   train_loss = 5.644
Epoch   0 Batch  533/575   train_loss = 5.727
Epoch   0 Batch  534/575   train_loss = 5.993
Epoch   0 Batch  535/575   train_loss = 6.565
Epoch   0 Batch  536/575   train_loss = 6.189
Epoch   0 Batch  537/575   train_loss = 5.427
Epoch   0 Batch  538/575   train_loss = 5.925
Epoch   0 Batch  539/575   train_loss = 5.600
Epoch   0 Batch  540/575   train_loss = 6.072
Epoch   0 Batch  541/575   train_loss = 6.411
Epoch   0 Batch  542/575   train_loss = 6.090
Epoch   0 Batch  543/575   train_loss = 6.441
Epoch   0 Batch  544/575   train_loss = 5.912
Epoch   0 Batch  545/575   train_loss = 6.311
Epoch   0 Batch  546/575   train_loss = 6.089
Epoch   0 Batch  547/575   train_loss = 6.087
Epoch   0 Batch  548/575   train_loss = 6.011
Epoch   0 Batch  549/575   train_loss = 5.667
Epoch   0 Batch  550/575   train_loss = 5.871
Epoch   0 Batch  551/575   train_loss = 5.735
Epoch   0 Batch  552/575   train_loss = 6.085
Epoch   0 Batch  553/575   train_loss = 5.868
Epoch   0 Batch  554/575   train_loss = 6.006
Epoch   0 Batch  555/575   train_loss = 6.321
Epoch   0 Batch  556/575   train_loss = 5.839
Epoch   0 Batch  557/575   train_loss = 5.359
Epoch   0 Batch  558/575   train_loss = 5.815
Epoch   0 Batch  559/575   train_loss = 5.900
Epoch   0 Batch  560/575   train_loss = 5.606
Epoch   0 Batch  561/575   train_loss = 5.754
Epoch   0 Batch  562/575   train_loss = 5.368
Epoch   0 Batch  563/575   train_loss = 5.911
Epoch   0 Batch  564/575   train_loss = 5.366
Epoch   0 Batch  565/575   train_loss = 5.279
Epoch   0 Batch  566/575   train_loss = 5.538
Epoch   0 Batch  567/575   train_loss = 5.247
Epoch   0 Batch  568/575   train_loss = 5.471
Epoch   0 Batch  569/575   train_loss = 5.575
Epoch   0 Batch  570/575   train_loss = 5.337
Epoch   0 Batch  571/575   train_loss = 5.496
Epoch   0 Batch  572/575   train_loss = 4.862
Epoch   0 Batch  573/575   train_loss = 5.261
Epoch   0 Batch  574/575   train_loss = 6.081
Epoch   1 Batch    0/575   train_loss = 5.779
Epoch   1 Batch    1/575   train_loss = 5.658
Epoch   1 Batch    2/575   train_loss = 5.722
Epoch   1 Batch    3/575   train_loss = 5.462
Epoch   1 Batch    4/575   train_loss = 5.333
Epoch   1 Batch    5/575   train_loss = 5.334
Epoch   1 Batch    6/575   train_loss = 5.317
Epoch   1 Batch    7/575   train_loss = 5.674
Epoch   1 Batch    8/575   train_loss = 5.585
Epoch   1 Batch    9/575   train_loss = 5.600
Epoch   1 Batch   10/575   train_loss = 5.047
Epoch   1 Batch   11/575   train_loss = 5.497
Epoch   1 Batch   12/575   train_loss = 5.610
Epoch   1 Batch   13/575   train_loss = 5.688
Epoch   1 Batch   14/575   train_loss = 6.018
Epoch   1 Batch   15/575   train_loss = 5.865
Epoch   1 Batch   16/575   train_loss = 5.789
Epoch   1 Batch   17/575   train_loss = 4.941
Epoch   1 Batch   18/575   train_loss = 5.867
Epoch   1 Batch   19/575   train_loss = 5.752
Epoch   1 Batch   20/575   train_loss = 5.395
Epoch   1 Batch   21/575   train_loss = 5.266
Epoch   1 Batch   22/575   train_loss = 6.079
Epoch   1 Batch   23/575   train_loss = 5.731
Epoch   1 Batch   24/575   train_loss = 5.446
Epoch   1 Batch   25/575   train_loss = 5.667
Epoch   1 Batch   26/575   train_loss = 5.787
Epoch   1 Batch   27/575   train_loss = 5.723
Epoch   1 Batch   28/575   train_loss = 5.098
Epoch   1 Batch   29/575   train_loss = 5.271
Epoch   1 Batch   30/575   train_loss = 6.057
Epoch   1 Batch   31/575   train_loss = 6.350
Epoch   1 Batch   32/575   train_loss = 5.552
Epoch   1 Batch   33/575   train_loss = 5.871
Epoch   1 Batch   34/575   train_loss = 5.335
Epoch   1 Batch   35/575   train_loss = 5.401
Epoch   1 Batch   36/575   train_loss = 5.620
Epoch   1 Batch   37/575   train_loss = 4.901
Epoch   1 Batch   38/575   train_loss = 5.574
Epoch   1 Batch   39/575   train_loss = 4.954
Epoch   1 Batch   40/575   train_loss = 4.881
Epoch   1 Batch   41/575   train_loss = 6.530
Epoch   1 Batch   42/575   train_loss = 5.513
Epoch   1 Batch   43/575   train_loss = 5.661
Epoch   1 Batch   44/575   train_loss = 5.490
Epoch   1 Batch   45/575   train_loss = 5.319
Epoch   1 Batch   46/575   train_loss = 5.338
Epoch   1 Batch   47/575   train_loss = 5.491
Epoch   1 Batch   48/575   train_loss = 4.802
Epoch   1 Batch   49/575   train_loss = 4.962
Epoch   1 Batch   50/575   train_loss = 5.380
Epoch   1 Batch   51/575   train_loss = 5.195
Epoch   1 Batch   52/575   train_loss = 5.215
Epoch   1 Batch   53/575   train_loss = 5.173
Epoch   1 Batch   54/575   train_loss = 5.679
Epoch   1 Batch   55/575   train_loss = 5.776
Epoch   1 Batch   56/575   train_loss = 5.230
Epoch   1 Batch   57/575   train_loss = 5.522
Epoch   1 Batch   58/575   train_loss = 5.130
Epoch   1 Batch   59/575   train_loss = 4.952
Epoch   1 Batch   60/575   train_loss = 5.614
Epoch   1 Batch   61/575   train_loss = 5.495
Epoch   1 Batch   62/575   train_loss = 5.228
Epoch   1 Batch   63/575   train_loss = 5.810
Epoch   1 Batch   64/575   train_loss = 5.723
Epoch   1 Batch   65/575   train_loss = 5.367
Epoch   1 Batch   66/575   train_loss = 5.258
Epoch   1 Batch   67/575   train_loss = 5.089
Epoch   1 Batch   68/575   train_loss = 5.304
Epoch   1 Batch   69/575   train_loss = 4.930
Epoch   1 Batch   70/575   train_loss = 5.555
Epoch   1 Batch   71/575   train_loss = 5.226
Epoch   1 Batch   72/575   train_loss = 5.704
Epoch   1 Batch   73/575   train_loss = 5.640
Epoch   1 Batch   74/575   train_loss = 5.986
Epoch   1 Batch   75/575   train_loss = 5.565
Epoch   1 Batch   76/575   train_loss = 5.922
Epoch   1 Batch   77/575   train_loss = 5.870
Epoch   1 Batch   78/575   train_loss = 5.709
Epoch   1 Batch   79/575   train_loss = 5.618
Epoch   1 Batch   80/575   train_loss = 5.350
Epoch   1 Batch   81/575   train_loss = 5.352
Epoch   1 Batch   82/575   train_loss = 5.163
Epoch   1 Batch   83/575   train_loss = 5.240
Epoch   1 Batch   84/575   train_loss = 5.463
Epoch   1 Batch   85/575   train_loss = 6.006
Epoch   1 Batch   86/575   train_loss = 5.363
Epoch   1 Batch   87/575   train_loss = 5.909
Epoch   1 Batch   88/575   train_loss = 4.809
Epoch   1 Batch   89/575   train_loss = 5.274
Epoch   1 Batch   90/575   train_loss = 5.450
Epoch   1 Batch   91/575   train_loss = 5.535
Epoch   1 Batch   92/575   train_loss = 6.144
Epoch   1 Batch   93/575   train_loss = 5.632
Epoch   1 Batch   94/575   train_loss = 5.156
Epoch   1 Batch   95/575   train_loss = 5.557
Epoch   1 Batch   96/575   train_loss = 5.587
Epoch   1 Batch   97/575   train_loss = 5.711
Epoch   1 Batch   98/575   train_loss = 5.363
Epoch   1 Batch   99/575   train_loss = 6.153
Epoch   1 Batch  100/575   train_loss = 5.911
Epoch   1 Batch  101/575   train_loss = 5.337
Epoch   1 Batch  102/575   train_loss = 5.174
Epoch   1 Batch  103/575   train_loss = 5.905
Epoch   1 Batch  104/575   train_loss = 5.501
Epoch   1 Batch  105/575   train_loss = 5.630
Epoch   1 Batch  106/575   train_loss = 5.404
Epoch   1 Batch  107/575   train_loss = 5.185
Epoch   1 Batch  108/575   train_loss = 5.696
Epoch   1 Batch  109/575   train_loss = 5.516
Epoch   1 Batch  110/575   train_loss = 4.743
Epoch   1 Batch  111/575   train_loss = 5.417
Epoch   1 Batch  112/575   train_loss = 5.663
Epoch   1 Batch  113/575   train_loss = 6.073
Epoch   1 Batch  114/575   train_loss = 5.715
Epoch   1 Batch  115/575   train_loss = 5.197
Epoch   1 Batch  116/575   train_loss = 5.620
Epoch   1 Batch  117/575   train_loss = 5.124
Epoch   1 Batch  118/575   train_loss = 5.717
Epoch   1 Batch  119/575   train_loss = 6.119
Epoch   1 Batch  120/575   train_loss = 5.625
Epoch   1 Batch  121/575   train_loss = 5.736
Epoch   1 Batch  122/575   train_loss = 5.882
Epoch   1 Batch  123/575   train_loss = 5.513
Epoch   1 Batch  124/575   train_loss = 5.839
Epoch   1 Batch  125/575   train_loss = 5.917
Epoch   1 Batch  126/575   train_loss = 5.695
Epoch   1 Batch  127/575   train_loss = 5.043
Epoch   1 Batch  128/575   train_loss = 5.246
Epoch   1 Batch  129/575   train_loss = 5.473
Epoch   1 Batch  130/575   train_loss = 5.629
Epoch   1 Batch  131/575   train_loss = 4.981
Epoch   1 Batch  132/575   train_loss = 5.341
Epoch   1 Batch  133/575   train_loss = 5.528
Epoch   1 Batch  134/575   train_loss = 5.457
Epoch   1 Batch  135/575   train_loss = 5.193
Epoch   1 Batch  136/575   train_loss = 6.585
Epoch   1 Batch  137/575   train_loss = 5.494
Epoch   1 Batch  138/575   train_loss = 6.063
Epoch   1 Batch  139/575   train_loss = 5.953
Epoch   1 Batch  140/575   train_loss = 5.965
Epoch   1 Batch  141/575   train_loss = 6.182
Epoch   1 Batch  142/575   train_loss = 6.842
Epoch   1 Batch  143/575   train_loss = 5.724
Epoch   1 Batch  144/575   train_loss = 5.277
Epoch   1 Batch  145/575   train_loss = 5.424
Epoch   1 Batch  146/575   train_loss = 5.415
Epoch   1 Batch  147/575   train_loss = 5.311
Epoch   1 Batch  148/575   train_loss = 4.905
Epoch   1 Batch  149/575   train_loss = 5.573
Epoch   1 Batch  150/575   train_loss = 5.802
Epoch   1 Batch  151/575   train_loss = 5.446
Epoch   1 Batch  152/575   train_loss = 5.259
Epoch   1 Batch  153/575   train_loss = 4.974
Epoch   1 Batch  154/575   train_loss = 5.005
Epoch   1 Batch  155/575   train_loss = 5.592
Epoch   1 Batch  156/575   train_loss = 5.409
Epoch   1 Batch  157/575   train_loss = 5.581
Epoch   1 Batch  158/575   train_loss = 5.472
Epoch   1 Batch  159/575   train_loss = 5.861
Epoch   1 Batch  160/575   train_loss = 5.253
Epoch   1 Batch  161/575   train_loss = 5.848
Epoch   1 Batch  162/575   train_loss = 5.837
Epoch   1 Batch  163/575   train_loss = 5.454
Epoch   1 Batch  164/575   train_loss = 5.827
Epoch   1 Batch  165/575   train_loss = 5.724
Epoch   1 Batch  166/575   train_loss = 5.198
Epoch   1 Batch  167/575   train_loss = 5.313
Epoch   1 Batch  168/575   train_loss = 5.640
Epoch   1 Batch  169/575   train_loss = 5.305
Epoch   1 Batch  170/575   train_loss = 5.715
Epoch   1 Batch  171/575   train_loss = 5.386
Epoch   1 Batch  172/575   train_loss = 5.803
Epoch   1 Batch  173/575   train_loss = 5.673
Epoch   1 Batch  174/575   train_loss = 5.995
Epoch   1 Batch  175/575   train_loss = 5.770
Epoch   1 Batch  176/575   train_loss = 5.682
Epoch   1 Batch  177/575   train_loss = 5.825
Epoch   1 Batch  178/575   train_loss = 5.622
Epoch   1 Batch  179/575   train_loss = 5.453
Epoch   1 Batch  180/575   train_loss = 5.411
Epoch   1 Batch  181/575   train_loss = 5.819
Epoch   1 Batch  182/575   train_loss = 5.413
Epoch   1 Batch  183/575   train_loss = 5.928
Epoch   1 Batch  184/575   train_loss = 5.137
Epoch   1 Batch  185/575   train_loss = 5.513
Epoch   1 Batch  186/575   train_loss = 5.823
Epoch   1 Batch  187/575   train_loss = 5.260
Epoch   1 Batch  188/575   train_loss = 5.459
Epoch   1 Batch  189/575   train_loss = 5.262
Epoch   1 Batch  190/575   train_loss = 5.553
Epoch   1 Batch  191/575   train_loss = 6.076
Epoch   1 Batch  192/575   train_loss = 5.785
Epoch   1 Batch  193/575   train_loss = 5.531
Epoch   1 Batch  194/575   train_loss = 5.663
Epoch   1 Batch  195/575   train_loss = 5.309
Epoch   1 Batch  196/575   train_loss = 5.191
Epoch   1 Batch  197/575   train_loss = 5.185
Epoch   1 Batch  198/575   train_loss = 5.817
Epoch   1 Batch  199/575   train_loss = 5.052
Epoch   1 Batch  200/575   train_loss = 5.278
Epoch   1 Batch  201/575   train_loss = 5.489
Epoch   1 Batch  202/575   train_loss = 4.958
Epoch   1 Batch  203/575   train_loss = 5.329
Epoch   1 Batch  204/575   train_loss = 5.382
Epoch   1 Batch  205/575   train_loss = 5.241
Epoch   1 Batch  206/575   train_loss = 5.576
Epoch   1 Batch  207/575   train_loss = 5.131
Epoch   1 Batch  208/575   train_loss = 4.917
Epoch   1 Batch  209/575   train_loss = 5.187
Epoch   1 Batch  210/575   train_loss = 5.390
Epoch   1 Batch  211/575   train_loss = 6.207
Epoch   1 Batch  212/575   train_loss = 5.766
Epoch   1 Batch  213/575   train_loss = 5.599
Epoch   1 Batch  214/575   train_loss = 5.298
Epoch   1 Batch  215/575   train_loss = 4.580
Epoch   1 Batch  216/575   train_loss = 5.315
Epoch   1 Batch  217/575   train_loss = 5.002
Epoch   1 Batch  218/575   train_loss = 5.571
Epoch   1 Batch  219/575   train_loss = 5.382
Epoch   1 Batch  220/575   train_loss = 4.915
Epoch   1 Batch  221/575   train_loss = 5.646
Epoch   1 Batch  222/575   train_loss = 5.644
Epoch   1 Batch  223/575   train_loss = 5.703
Epoch   1 Batch  224/575   train_loss = 5.095
Epoch   1 Batch  225/575   train_loss = 5.401
Epoch   1 Batch  226/575   train_loss = 5.763
Epoch   1 Batch  227/575   train_loss = 5.794
Epoch   1 Batch  228/575   train_loss = 5.772
Epoch   1 Batch  229/575   train_loss = 4.623
Epoch   1 Batch  230/575   train_loss = 4.808
Epoch   1 Batch  231/575   train_loss = 5.341
Epoch   1 Batch  232/575   train_loss = 5.292
Epoch   1 Batch  233/575   train_loss = 5.521
Epoch   1 Batch  234/575   train_loss = 5.512
Epoch   1 Batch  235/575   train_loss = 5.128
Epoch   1 Batch  236/575   train_loss = 4.699
Epoch   1 Batch  237/575   train_loss = 5.210
Epoch   1 Batch  238/575   train_loss = 5.205
Epoch   1 Batch  239/575   train_loss = 5.507
Epoch   1 Batch  240/575   train_loss = 5.643
Epoch   1 Batch  241/575   train_loss = 5.976
Epoch   1 Batch  242/575   train_loss = 5.200
Epoch   1 Batch  243/575   train_loss = 5.541
Epoch   1 Batch  244/575   train_loss = 5.340
Epoch   1 Batch  245/575   train_loss = 5.524
Epoch   1 Batch  246/575   train_loss = 5.809
Epoch   1 Batch  247/575   train_loss = 5.151
Epoch   1 Batch  248/575   train_loss = 5.526
Epoch   1 Batch  249/575   train_loss = 5.537
Epoch   1 Batch  250/575   train_loss = 5.163
Epoch   1 Batch  251/575   train_loss = 5.722
Epoch   1 Batch  252/575   train_loss = 5.657
Epoch   1 Batch  253/575   train_loss = 5.343
Epoch   1 Batch  254/575   train_loss = 5.067
Epoch   1 Batch  255/575   train_loss = 5.610
Epoch   1 Batch  256/575   train_loss = 5.270
Epoch   1 Batch  257/575   train_loss = 5.446
Epoch   1 Batch  258/575   train_loss = 5.740
Epoch   1 Batch  259/575   train_loss = 5.034
Epoch   1 Batch  260/575   train_loss = 5.084
Epoch   1 Batch  261/575   train_loss = 6.105
Epoch   1 Batch  262/575   train_loss = 5.754
Epoch   1 Batch  263/575   train_loss = 5.395
Epoch   1 Batch  264/575   train_loss = 4.910
Epoch   1 Batch  265/575   train_loss = 4.634
Epoch   1 Batch  266/575   train_loss = 4.987
Epoch   1 Batch  267/575   train_loss = 5.369
Epoch   1 Batch  268/575   train_loss = 5.475
Epoch   1 Batch  269/575   train_loss = 5.416
Epoch   1 Batch  270/575   train_loss = 5.905
Epoch   1 Batch  271/575   train_loss = 5.132
Epoch   1 Batch  272/575   train_loss = 5.726
Epoch   1 Batch  273/575   train_loss = 5.572
Epoch   1 Batch  274/575   train_loss = 5.492
Epoch   1 Batch  275/575   train_loss = 5.537
Epoch   1 Batch  276/575   train_loss = 5.994
Epoch   1 Batch  277/575   train_loss = 4.907
Epoch   1 Batch  278/575   train_loss = 5.303
Epoch   1 Batch  279/575   train_loss = 5.426
Epoch   1 Batch  280/575   train_loss = 5.915
Epoch   1 Batch  281/575   train_loss = 5.072
Epoch   1 Batch  282/575   train_loss = 5.368
Epoch   1 Batch  283/575   train_loss = 5.739
Epoch   1 Batch  284/575   train_loss = 5.828
Epoch   1 Batch  285/575   train_loss = 5.233
Epoch   1 Batch  286/575   train_loss = 5.472
Epoch   1 Batch  287/575   train_loss = 5.616
Epoch   1 Batch  288/575   train_loss = 5.412
Epoch   1 Batch  289/575   train_loss = 5.560
Epoch   1 Batch  290/575   train_loss = 5.710
Epoch   1 Batch  291/575   train_loss = 6.285
Epoch   1 Batch  292/575   train_loss = 5.769
Epoch   1 Batch  293/575   train_loss = 6.115
Epoch   1 Batch  294/575   train_loss = 5.789
Epoch   1 Batch  295/575   train_loss = 5.322
Epoch   1 Batch  296/575   train_loss = 5.300
Epoch   1 Batch  297/575   train_loss = 5.469
Epoch   1 Batch  298/575   train_loss = 5.659
Epoch   1 Batch  299/575   train_loss = 5.561
Epoch   1 Batch  300/575   train_loss = 5.320
Epoch   1 Batch  301/575   train_loss = 5.220
Epoch   1 Batch  302/575   train_loss = 5.741
Epoch   1 Batch  303/575   train_loss = 5.129
Epoch   1 Batch  304/575   train_loss = 5.197
Epoch   1 Batch  305/575   train_loss = 5.242
Epoch   1 Batch  306/575   train_loss = 5.698
Epoch   1 Batch  307/575   train_loss = 5.703
Epoch   1 Batch  308/575   train_loss = 5.683
Epoch   1 Batch  309/575   train_loss = 5.754
Epoch   1 Batch  310/575   train_loss = 5.626
Epoch   1 Batch  311/575   train_loss = 5.080
Epoch   1 Batch  312/575   train_loss = 5.632
Epoch   1 Batch  313/575   train_loss = 5.973
Epoch   1 Batch  314/575   train_loss = 5.680
Epoch   1 Batch  315/575   train_loss = 6.042
Epoch   1 Batch  316/575   train_loss = 5.425
Epoch   1 Batch  317/575   train_loss = 5.008
Epoch   1 Batch  318/575   train_loss = 4.804
Epoch   1 Batch  319/575   train_loss = 5.453
Epoch   1 Batch  320/575   train_loss = 5.120
Epoch   1 Batch  321/575   train_loss = 5.982
Epoch   1 Batch  322/575   train_loss = 5.423
Epoch   1 Batch  323/575   train_loss = 5.749
Epoch   1 Batch  324/575   train_loss = 5.297
Epoch   1 Batch  325/575   train_loss = 5.474
Epoch   1 Batch  326/575   train_loss = 5.268
Epoch   1 Batch  327/575   train_loss = 5.785
Epoch   1 Batch  328/575   train_loss = 5.660
Epoch   1 Batch  329/575   train_loss = 5.925
Epoch   1 Batch  330/575   train_loss = 5.560
Epoch   1 Batch  331/575   train_loss = 6.064
Epoch   1 Batch  332/575   train_loss = 5.744
Epoch   1 Batch  333/575   train_loss = 5.774
Epoch   1 Batch  334/575   train_loss = 5.245
Epoch   1 Batch  335/575   train_loss = 5.268
Epoch   1 Batch  336/575   train_loss = 5.567
Epoch   1 Batch  337/575   train_loss = 5.408
Epoch   1 Batch  338/575   train_loss = 5.193
Epoch   1 Batch  339/575   train_loss = 5.561
Epoch   1 Batch  340/575   train_loss = 5.338
Epoch   1 Batch  341/575   train_loss = 5.324
Epoch   1 Batch  342/575   train_loss = 5.085
Epoch   1 Batch  343/575   train_loss = 5.622
Epoch   1 Batch  344/575   train_loss = 5.607
Epoch   1 Batch  345/575   train_loss = 5.182
Epoch   1 Batch  346/575   train_loss = 5.991
Epoch   1 Batch  347/575   train_loss = 5.202
Epoch   1 Batch  348/575   train_loss = 5.190
Epoch   1 Batch  349/575   train_loss = 4.936
Epoch   1 Batch  350/575   train_loss = 5.571
Epoch   1 Batch  351/575   train_loss = 5.903
Epoch   1 Batch  352/575   train_loss = 5.695
Epoch   1 Batch  353/575   train_loss = 5.592
Epoch   1 Batch  354/575   train_loss = 5.341
Epoch   1 Batch  355/575   train_loss = 5.926
Epoch   1 Batch  356/575   train_loss = 5.471
Epoch   1 Batch  357/575   train_loss = 5.321
Epoch   1 Batch  358/575   train_loss = 5.656
Epoch   1 Batch  359/575   train_loss = 6.011
Epoch   1 Batch  360/575   train_loss = 5.005
Epoch   1 Batch  361/575   train_loss = 5.757
Epoch   1 Batch  362/575   train_loss = 5.398
Epoch   1 Batch  363/575   train_loss = 5.485
Epoch   1 Batch  364/575   train_loss = 5.037
Epoch   1 Batch  365/575   train_loss = 5.596
Epoch   1 Batch  366/575   train_loss = 5.113
Epoch   1 Batch  367/575   train_loss = 5.498
Epoch   1 Batch  368/575   train_loss = 6.026
Epoch   1 Batch  369/575   train_loss = 5.750
Epoch   1 Batch  370/575   train_loss = 5.756
Epoch   1 Batch  371/575   train_loss = 5.798
Epoch   1 Batch  372/575   train_loss = 5.354
Epoch   1 Batch  373/575   train_loss = 5.678
Epoch   1 Batch  374/575   train_loss = 5.008
Epoch   1 Batch  375/575   train_loss = 5.190
Epoch   1 Batch  376/575   train_loss = 5.507
Epoch   1 Batch  377/575   train_loss = 5.831
Epoch   1 Batch  378/575   train_loss = 5.828
Epoch   1 Batch  379/575   train_loss = 5.452
Epoch   1 Batch  380/575   train_loss = 5.046
Epoch   1 Batch  381/575   train_loss = 5.442
Epoch   1 Batch  382/575   train_loss = 5.673
Epoch   1 Batch  383/575   train_loss = 5.309
Epoch   1 Batch  384/575   train_loss = 5.597
Epoch   1 Batch  385/575   train_loss = 5.185
Epoch   1 Batch  386/575   train_loss = 5.144
Epoch   1 Batch  387/575   train_loss = 5.865
Epoch   1 Batch  388/575   train_loss = 5.329
Epoch   1 Batch  389/575   train_loss = 5.211
Epoch   1 Batch  390/575   train_loss = 5.554
Epoch   1 Batch  391/575   train_loss = 5.826
Epoch   1 Batch  392/575   train_loss = 5.355
Epoch   1 Batch  393/575   train_loss = 5.425
Epoch   1 Batch  394/575   train_loss = 5.732
Epoch   1 Batch  395/575   train_loss = 4.825
Epoch   1 Batch  396/575   train_loss = 5.407
Epoch   1 Batch  397/575   train_loss = 5.757
Epoch   1 Batch  398/575   train_loss = 5.738
Epoch   1 Batch  399/575   train_loss = 5.897
Epoch   1 Batch  400/575   train_loss = 5.657
Epoch   1 Batch  401/575   train_loss = 5.089
Epoch   1 Batch  402/575   train_loss = 5.395
Epoch   1 Batch  403/575   train_loss = 5.603
Epoch   1 Batch  404/575   train_loss = 5.825
Epoch   1 Batch  405/575   train_loss = 5.754
Epoch   1 Batch  406/575   train_loss = 5.166
Epoch   1 Batch  407/575   train_loss = 5.431
Epoch   1 Batch  408/575   train_loss = 5.546
Epoch   1 Batch  409/575   train_loss = 5.331
Epoch   1 Batch  410/575   train_loss = 5.360
Epoch   1 Batch  411/575   train_loss = 5.390
Epoch   1 Batch  412/575   train_loss = 5.969
Epoch   1 Batch  413/575   train_loss = 5.942
Epoch   1 Batch  414/575   train_loss = 5.704
Epoch   1 Batch  415/575   train_loss = 6.085
Epoch   1 Batch  416/575   train_loss = 5.431
Epoch   1 Batch  417/575   train_loss = 5.249
Epoch   1 Batch  418/575   train_loss = 5.384
Epoch   1 Batch  419/575   train_loss = 5.403
Epoch   1 Batch  420/575   train_loss = 5.445
Epoch   1 Batch  421/575   train_loss = 5.981
Epoch   1 Batch  422/575   train_loss = 5.566
Epoch   1 Batch  423/575   train_loss = 6.225
Epoch   1 Batch  424/575   train_loss = 6.200
Epoch   1 Batch  425/575   train_loss = 5.863
Epoch   1 Batch  426/575   train_loss = 5.613
Epoch   1 Batch  427/575   train_loss = 5.463
Epoch   1 Batch  428/575   train_loss = 5.624
Epoch   1 Batch  429/575   train_loss = 5.175
Epoch   1 Batch  430/575   train_loss = 5.498
Epoch   1 Batch  431/575   train_loss = 5.471
Epoch   1 Batch  432/575   train_loss = 5.933
Epoch   1 Batch  433/575   train_loss = 5.887
Epoch   1 Batch  434/575   train_loss = 5.688
Epoch   1 Batch  435/575   train_loss = 5.694
Epoch   1 Batch  436/575   train_loss = 5.204
Epoch   1 Batch  437/575   train_loss = 5.652
Epoch   1 Batch  438/575   train_loss = 5.816
Epoch   1 Batch  439/575   train_loss = 5.567
Epoch   1 Batch  440/575   train_loss = 5.709
Epoch   1 Batch  441/575   train_loss = 5.579
Epoch   1 Batch  442/575   train_loss = 5.592
Epoch   1 Batch  443/575   train_loss = 5.590
Epoch   1 Batch  444/575   train_loss = 5.685
Epoch   1 Batch  445/575   train_loss = 5.424
Epoch   1 Batch  446/575   train_loss = 5.315
Epoch   1 Batch  447/575   train_loss = 5.729
Epoch   1 Batch  448/575   train_loss = 5.424
Epoch   1 Batch  449/575   train_loss = 5.654
Epoch   1 Batch  450/575   train_loss = 6.286
Epoch   1 Batch  451/575   train_loss = 6.060
Epoch   1 Batch  452/575   train_loss = 6.176
Epoch   1 Batch  453/575   train_loss = 5.709
Epoch   1 Batch  454/575   train_loss = 5.950
Epoch   1 Batch  455/575   train_loss = 5.340
Epoch   1 Batch  456/575   train_loss = 6.004
Epoch   1 Batch  457/575   train_loss = 5.241
Epoch   1 Batch  458/575   train_loss = 5.911
Epoch   1 Batch  459/575   train_loss = 5.901
Epoch   1 Batch  460/575   train_loss = 5.673
Epoch   1 Batch  461/575   train_loss = 5.910
Epoch   1 Batch  462/575   train_loss = 5.465
Epoch   1 Batch  463/575   train_loss = 5.430
Epoch   1 Batch  464/575   train_loss = 5.146
Epoch   1 Batch  465/575   train_loss = 5.449
Epoch   1 Batch  466/575   train_loss = 5.365
Epoch   1 Batch  467/575   train_loss = 4.999
Epoch   1 Batch  468/575   train_loss = 5.273
Epoch   1 Batch  469/575   train_loss = 5.801
Epoch   1 Batch  470/575   train_loss = 6.064
Epoch   1 Batch  471/575   train_loss = 5.345
Epoch   1 Batch  472/575   train_loss = 5.808
Epoch   1 Batch  473/575   train_loss = 5.539
Epoch   1 Batch  474/575   train_loss = 5.603
Epoch   1 Batch  475/575   train_loss = 5.354
Epoch   1 Batch  476/575   train_loss = 5.437
Epoch   1 Batch  477/575   train_loss = 5.917
Epoch   1 Batch  478/575   train_loss = 6.053
Epoch   1 Batch  479/575   train_loss = 5.605
Epoch   1 Batch  480/575   train_loss = 5.856
Epoch   1 Batch  481/575   train_loss = 5.839
Epoch   1 Batch  482/575   train_loss = 4.964
Epoch   1 Batch  483/575   train_loss = 6.433
Epoch   1 Batch  484/575   train_loss = 5.623
Epoch   1 Batch  485/575   train_loss = 5.839
Epoch   1 Batch  486/575   train_loss = 5.733
Epoch   1 Batch  487/575   train_loss = 5.691
Epoch   1 Batch  488/575   train_loss = 5.620
Epoch   1 Batch  489/575   train_loss = 5.827
Epoch   1 Batch  490/575   train_loss = 5.891
Epoch   1 Batch  491/575   train_loss = 5.210
Epoch   1 Batch  492/575   train_loss = 4.780
Epoch   1 Batch  493/575   train_loss = 5.058
Epoch   1 Batch  494/575   train_loss = 5.256
Epoch   1 Batch  495/575   train_loss = 5.484
Epoch   1 Batch  496/575   train_loss = 5.671
Epoch   1 Batch  497/575   train_loss = 5.872
Epoch   1 Batch  498/575   train_loss = 5.255
Epoch   1 Batch  499/575   train_loss = 5.286
Epoch   1 Batch  500/575   train_loss = 5.433
Epoch   1 Batch  501/575   train_loss = 5.505
Epoch   1 Batch  502/575   train_loss = 4.945
Epoch   1 Batch  503/575   train_loss = 5.672
Epoch   1 Batch  504/575   train_loss = 5.125
Epoch   1 Batch  505/575   train_loss = 5.410
Epoch   1 Batch  506/575   train_loss = 5.731
Epoch   1 Batch  507/575   train_loss = 5.884
Epoch   1 Batch  508/575   train_loss = 5.703
Epoch   1 Batch  509/575   train_loss = 5.643
Epoch   1 Batch  510/575   train_loss = 5.081
Epoch   1 Batch  511/575   train_loss = 4.997
Epoch   1 Batch  512/575   train_loss = 5.921
Epoch   1 Batch  513/575   train_loss = 5.697
Epoch   1 Batch  514/575   train_loss = 5.487
Epoch   1 Batch  515/575   train_loss = 5.671
Epoch   1 Batch  516/575   train_loss = 5.871
Epoch   1 Batch  517/575   train_loss = 5.340
Epoch   1 Batch  518/575   train_loss = 5.434
Epoch   1 Batch  519/575   train_loss = 5.328
Epoch   1 Batch  520/575   train_loss = 4.673
Epoch   1 Batch  521/575   train_loss = 5.299
Epoch   1 Batch  522/575   train_loss = 5.253
Epoch   1 Batch  523/575   train_loss = 6.111
Epoch   1 Batch  524/575   train_loss = 7.232
Epoch   1 Batch  525/575   train_loss = 5.377
Epoch   1 Batch  526/575   train_loss = 5.331
Epoch   1 Batch  527/575   train_loss = 5.599
Epoch   1 Batch  528/575   train_loss = 5.273
Epoch   1 Batch  529/575   train_loss = 5.556
Epoch   1 Batch  530/575   train_loss = 5.713
Epoch   1 Batch  531/575   train_loss = 5.665
Epoch   1 Batch  532/575   train_loss = 5.324
Epoch   1 Batch  533/575   train_loss = 5.328
Epoch   1 Batch  534/575   train_loss = 5.443
Epoch   1 Batch  535/575   train_loss = 5.994
Epoch   1 Batch  536/575   train_loss = 5.672
Epoch   1 Batch  537/575   train_loss = 5.030
Epoch   1 Batch  538/575   train_loss = 5.549
Epoch   1 Batch  539/575   train_loss = 5.203
Epoch   1 Batch  540/575   train_loss = 5.660
Epoch   1 Batch  541/575   train_loss = 6.085
Epoch   1 Batch  542/575   train_loss = 5.639
Epoch   1 Batch  543/575   train_loss = 5.918
Epoch   1 Batch  544/575   train_loss = 5.567
Epoch   1 Batch  545/575   train_loss = 5.871
Epoch   1 Batch  546/575   train_loss = 5.718
Epoch   1 Batch  547/575   train_loss = 5.702
Epoch   1 Batch  548/575   train_loss = 5.682
Epoch   1 Batch  549/575   train_loss = 5.301
Epoch   1 Batch  550/575   train_loss = 5.406
Epoch   1 Batch  551/575   train_loss = 5.376
Epoch   1 Batch  552/575   train_loss = 5.593
Epoch   1 Batch  553/575   train_loss = 5.574
Epoch   1 Batch  554/575   train_loss = 5.554
Epoch   1 Batch  555/575   train_loss = 5.851
Epoch   1 Batch  556/575   train_loss = 5.397
Epoch   1 Batch  557/575   train_loss = 4.994
Epoch   1 Batch  558/575   train_loss = 5.445
Epoch   1 Batch  559/575   train_loss = 5.546
Epoch   1 Batch  560/575   train_loss = 5.099
Epoch   1 Batch  561/575   train_loss = 5.409
Epoch   1 Batch  562/575   train_loss = 4.965
Epoch   1 Batch  563/575   train_loss = 5.525
Epoch   1 Batch  564/575   train_loss = 5.021
Epoch   1 Batch  565/575   train_loss = 4.938
Epoch   1 Batch  566/575   train_loss = 5.207
Epoch   1 Batch  567/575   train_loss = 4.906
Epoch   1 Batch  568/575   train_loss = 5.200
Epoch   1 Batch  569/575   train_loss = 5.333
Epoch   1 Batch  570/575   train_loss = 5.019
Epoch   1 Batch  571/575   train_loss = 5.057
Epoch   1 Batch  572/575   train_loss = 4.533
Epoch   1 Batch  573/575   train_loss = 5.001
Epoch   1 Batch  574/575   train_loss = 5.729
Epoch   2 Batch    0/575   train_loss = 5.376
Epoch   2 Batch    1/575   train_loss = 5.202
Epoch   2 Batch    2/575   train_loss = 5.373
Epoch   2 Batch    3/575   train_loss = 5.123
Epoch   2 Batch    4/575   train_loss = 5.027
Epoch   2 Batch    5/575   train_loss = 5.024
Epoch   2 Batch    6/575   train_loss = 4.941
Epoch   2 Batch    7/575   train_loss = 5.330
Epoch   2 Batch    8/575   train_loss = 5.221
Epoch   2 Batch    9/575   train_loss = 5.352
Epoch   2 Batch   10/575   train_loss = 4.750
Epoch   2 Batch   11/575   train_loss = 5.127
Epoch   2 Batch   12/575   train_loss = 5.224
Epoch   2 Batch   13/575   train_loss = 5.448
Epoch   2 Batch   14/575   train_loss = 5.660
Epoch   2 Batch   15/575   train_loss = 5.508
Epoch   2 Batch   16/575   train_loss = 5.454
Epoch   2 Batch   17/575   train_loss = 4.622
Epoch   2 Batch   18/575   train_loss = 5.697
Epoch   2 Batch   19/575   train_loss = 5.404
Epoch   2 Batch   20/575   train_loss = 4.997
Epoch   2 Batch   21/575   train_loss = 4.988
Epoch   2 Batch   22/575   train_loss = 5.812
Epoch   2 Batch   23/575   train_loss = 5.445
Epoch   2 Batch   24/575   train_loss = 5.243
Epoch   2 Batch   25/575   train_loss = 5.395
Epoch   2 Batch   26/575   train_loss = 5.547
Epoch   2 Batch   27/575   train_loss = 5.480
Epoch   2 Batch   28/575   train_loss = 4.834
Epoch   2 Batch   29/575   train_loss = 5.013
Epoch   2 Batch   30/575   train_loss = 5.839
Epoch   2 Batch   31/575   train_loss = 6.113
Epoch   2 Batch   32/575   train_loss = 5.305
Epoch   2 Batch   33/575   train_loss = 5.649
Epoch   2 Batch   34/575   train_loss = 5.191
Epoch   2 Batch   35/575   train_loss = 5.168
Epoch   2 Batch   36/575   train_loss = 5.403
Epoch   2 Batch   37/575   train_loss = 4.694
Epoch   2 Batch   38/575   train_loss = 5.422
Epoch   2 Batch   39/575   train_loss = 4.748
Epoch   2 Batch   40/575   train_loss = 4.626
Epoch   2 Batch   41/575   train_loss = 6.329
Epoch   2 Batch   42/575   train_loss = 5.331
Epoch   2 Batch   43/575   train_loss = 5.425
Epoch   2 Batch   44/575   train_loss = 5.211
Epoch   2 Batch   45/575   train_loss = 5.109
Epoch   2 Batch   46/575   train_loss = 5.092
Epoch   2 Batch   47/575   train_loss = 5.294
Epoch   2 Batch   48/575   train_loss = 4.583
Epoch   2 Batch   49/575   train_loss = 4.801
Epoch   2 Batch   50/575   train_loss = 5.092
Epoch   2 Batch   51/575   train_loss = 4.957
Epoch   2 Batch   52/575   train_loss = 4.965
Epoch   2 Batch   53/575   train_loss = 4.894
Epoch   2 Batch   54/575   train_loss = 5.422
Epoch   2 Batch   55/575   train_loss = 5.594
Epoch   2 Batch   56/575   train_loss = 4.977
Epoch   2 Batch   57/575   train_loss = 5.261
Epoch   2 Batch   58/575   train_loss = 4.902
Epoch   2 Batch   59/575   train_loss = 4.704
Epoch   2 Batch   60/575   train_loss = 5.385
Epoch   2 Batch   61/575   train_loss = 5.291
Epoch   2 Batch   62/575   train_loss = 4.952
Epoch   2 Batch   63/575   train_loss = 5.592
Epoch   2 Batch   64/575   train_loss = 5.495
Epoch   2 Batch   65/575   train_loss = 5.094
Epoch   2 Batch   66/575   train_loss = 5.040
Epoch   2 Batch   67/575   train_loss = 4.826
Epoch   2 Batch   68/575   train_loss = 5.029
Epoch   2 Batch   69/575   train_loss = 4.639
Epoch   2 Batch   70/575   train_loss = 5.286
Epoch   2 Batch   71/575   train_loss = 4.908
Epoch   2 Batch   72/575   train_loss = 5.485
Epoch   2 Batch   73/575   train_loss = 5.448
Epoch   2 Batch   74/575   train_loss = 5.764
Epoch   2 Batch   75/575   train_loss = 5.325
Epoch   2 Batch   76/575   train_loss = 5.683
Epoch   2 Batch   77/575   train_loss = 5.669
Epoch   2 Batch   78/575   train_loss = 5.455
Epoch   2 Batch   79/575   train_loss = 5.382
Epoch   2 Batch   80/575   train_loss = 5.137
Epoch   2 Batch   81/575   train_loss = 5.125
Epoch   2 Batch   82/575   train_loss = 4.904
Epoch   2 Batch   83/575   train_loss = 5.022
Epoch   2 Batch   84/575   train_loss = 5.215
Epoch   2 Batch   85/575   train_loss = 5.796
Epoch   2 Batch   86/575   train_loss = 5.127
Epoch   2 Batch   87/575   train_loss = 5.689
Epoch   2 Batch   88/575   train_loss = 4.553
Epoch   2 Batch   89/575   train_loss = 4.942
Epoch   2 Batch   90/575   train_loss = 5.119
Epoch   2 Batch   91/575   train_loss = 5.281
Epoch   2 Batch   92/575   train_loss = 5.884
Epoch   2 Batch   93/575   train_loss = 5.401
Epoch   2 Batch   94/575   train_loss = 4.910
Epoch   2 Batch   95/575   train_loss = 5.302
Epoch   2 Batch   96/575   train_loss = 5.320
Epoch   2 Batch   97/575   train_loss = 5.457
Epoch   2 Batch   98/575   train_loss = 5.125
Epoch   2 Batch   99/575   train_loss = 5.845
Epoch   2 Batch  100/575   train_loss = 5.591
Epoch   2 Batch  101/575   train_loss = 5.071
Epoch   2 Batch  102/575   train_loss = 4.881
Epoch   2 Batch  103/575   train_loss = 5.660
Epoch   2 Batch  104/575   train_loss = 5.293
Epoch   2 Batch  105/575   train_loss = 5.416
Epoch   2 Batch  106/575   train_loss = 5.160
Epoch   2 Batch  107/575   train_loss = 4.894
Epoch   2 Batch  108/575   train_loss = 5.454
Epoch   2 Batch  109/575   train_loss = 5.220
Epoch   2 Batch  110/575   train_loss = 4.408
Epoch   2 Batch  111/575   train_loss = 5.139
Epoch   2 Batch  112/575   train_loss = 5.384
Epoch   2 Batch  113/575   train_loss = 5.839
Epoch   2 Batch  114/575   train_loss = 5.448
Epoch   2 Batch  115/575   train_loss = 4.917
Epoch   2 Batch  116/575   train_loss = 5.388
Epoch   2 Batch  117/575   train_loss = 4.874
Epoch   2 Batch  118/575   train_loss = 5.411
Epoch   2 Batch  119/575   train_loss = 5.925
Epoch   2 Batch  120/575   train_loss = 5.381
Epoch   2 Batch  121/575   train_loss = 5.468
Epoch   2 Batch  122/575   train_loss = 5.626
Epoch   2 Batch  123/575   train_loss = 5.300
Epoch   2 Batch  124/575   train_loss = 5.586
Epoch   2 Batch  125/575   train_loss = 5.588
Epoch   2 Batch  126/575   train_loss = 5.394
Epoch   2 Batch  127/575   train_loss = 4.740
Epoch   2 Batch  128/575   train_loss = 4.999
Epoch   2 Batch  129/575   train_loss = 5.128
Epoch   2 Batch  130/575   train_loss = 5.461
Epoch   2 Batch  131/575   train_loss = 4.707
Epoch   2 Batch  132/575   train_loss = 5.036
Epoch   2 Batch  133/575   train_loss = 5.252
Epoch   2 Batch  134/575   train_loss = 5.151
Epoch   2 Batch  135/575   train_loss = 4.836
Epoch   2 Batch  136/575   train_loss = 6.334
Epoch   2 Batch  137/575   train_loss = 5.235
Epoch   2 Batch  138/575   train_loss = 5.816
Epoch   2 Batch  139/575   train_loss = 5.638
Epoch   2 Batch  140/575   train_loss = 5.606
Epoch   2 Batch  141/575   train_loss = 5.889
Epoch   2 Batch  142/575   train_loss = 6.455
Epoch   2 Batch  143/575   train_loss = 5.445
Epoch   2 Batch  144/575   train_loss = 4.982
Epoch   2 Batch  145/575   train_loss = 5.131
Epoch   2 Batch  146/575   train_loss = 5.086
Epoch   2 Batch  147/575   train_loss = 5.062
Epoch   2 Batch  148/575   train_loss = 4.645
Epoch   2 Batch  149/575   train_loss = 5.392
Epoch   2 Batch  150/575   train_loss = 5.624
Epoch   2 Batch  151/575   train_loss = 5.100
Epoch   2 Batch  152/575   train_loss = 4.919
Epoch   2 Batch  153/575   train_loss = 4.544
Epoch   2 Batch  154/575   train_loss = 4.631
Epoch   2 Batch  155/575   train_loss = 5.326
Epoch   2 Batch  156/575   train_loss = 5.142
Epoch   2 Batch  157/575   train_loss = 5.285
Epoch   2 Batch  158/575   train_loss = 5.244
Epoch   2 Batch  159/575   train_loss = 5.574
Epoch   2 Batch  160/575   train_loss = 4.967
Epoch   2 Batch  161/575   train_loss = 5.631
Epoch   2 Batch  162/575   train_loss = 5.513
Epoch   2 Batch  163/575   train_loss = 5.132
Epoch   2 Batch  164/575   train_loss = 5.466
Epoch   2 Batch  165/575   train_loss = 5.417
Epoch   2 Batch  166/575   train_loss = 4.955
Epoch   2 Batch  167/575   train_loss = 5.053
Epoch   2 Batch  168/575   train_loss = 5.405
Epoch   2 Batch  169/575   train_loss = 5.011
Epoch   2 Batch  170/575   train_loss = 5.424
Epoch   2 Batch  171/575   train_loss = 5.095
Epoch   2 Batch  172/575   train_loss = 5.420
Epoch   2 Batch  173/575   train_loss = 5.336
Epoch   2 Batch  174/575   train_loss = 5.689
Epoch   2 Batch  175/575   train_loss = 5.470
Epoch   2 Batch  176/575   train_loss = 5.384
Epoch   2 Batch  177/575   train_loss = 5.552
Epoch   2 Batch  178/575   train_loss = 5.309
Epoch   2 Batch  179/575   train_loss = 5.087
Epoch   2 Batch  180/575   train_loss = 5.138
Epoch   2 Batch  181/575   train_loss = 5.553
Epoch   2 Batch  182/575   train_loss = 5.045
Epoch   2 Batch  183/575   train_loss = 5.545
Epoch   2 Batch  184/575   train_loss = 4.709
Epoch   2 Batch  185/575   train_loss = 5.183
Epoch   2 Batch  186/575   train_loss = 5.474
Epoch   2 Batch  187/575   train_loss = 5.047
Epoch   2 Batch  188/575   train_loss = 5.138
Epoch   2 Batch  189/575   train_loss = 4.994
Epoch   2 Batch  190/575   train_loss = 5.274
Epoch   2 Batch  191/575   train_loss = 5.784
Epoch   2 Batch  192/575   train_loss = 5.541
Epoch   2 Batch  193/575   train_loss = 5.228
Epoch   2 Batch  194/575   train_loss = 5.381
Epoch   2 Batch  195/575   train_loss = 5.020
Epoch   2 Batch  196/575   train_loss = 4.955
Epoch   2 Batch  197/575   train_loss = 4.877
Epoch   2 Batch  198/575   train_loss = 5.542
Epoch   2 Batch  199/575   train_loss = 4.713
Epoch   2 Batch  200/575   train_loss = 4.974
Epoch   2 Batch  201/575   train_loss = 5.224
Epoch   2 Batch  202/575   train_loss = 4.730
Epoch   2 Batch  203/575   train_loss = 5.051
Epoch   2 Batch  204/575   train_loss = 5.080
Epoch   2 Batch  205/575   train_loss = 4.867
Epoch   2 Batch  206/575   train_loss = 5.259
Epoch   2 Batch  207/575   train_loss = 4.870
Epoch   2 Batch  208/575   train_loss = 4.666
Epoch   2 Batch  209/575   train_loss = 4.857
Epoch   2 Batch  210/575   train_loss = 5.103
Epoch   2 Batch  211/575   train_loss = 5.871
Epoch   2 Batch  212/575   train_loss = 5.424
Epoch   2 Batch  213/575   train_loss = 5.284
Epoch   2 Batch  214/575   train_loss = 5.041
Epoch   2 Batch  215/575   train_loss = 4.304
Epoch   2 Batch  216/575   train_loss = 5.007
Epoch   2 Batch  217/575   train_loss = 4.647
Epoch   2 Batch  218/575   train_loss = 5.288
Epoch   2 Batch  219/575   train_loss = 5.029
Epoch   2 Batch  220/575   train_loss = 4.548
Epoch   2 Batch  221/575   train_loss = 5.287
Epoch   2 Batch  222/575   train_loss = 5.338
Epoch   2 Batch  223/575   train_loss = 5.510
Epoch   2 Batch  224/575   train_loss = 4.765
Epoch   2 Batch  225/575   train_loss = 5.060
Epoch   2 Batch  226/575   train_loss = 5.349
Epoch   2 Batch  227/575   train_loss = 5.551
Epoch   2 Batch  228/575   train_loss = 5.447
Epoch   2 Batch  229/575   train_loss = 4.287
Epoch   2 Batch  230/575   train_loss = 4.479
Epoch   2 Batch  231/575   train_loss = 5.075
Epoch   2 Batch  232/575   train_loss = 5.079
Epoch   2 Batch  233/575   train_loss = 5.261
Epoch   2 Batch  234/575   train_loss = 5.237
Epoch   2 Batch  235/575   train_loss = 4.842
Epoch   2 Batch  236/575   train_loss = 4.470
Epoch   2 Batch  237/575   train_loss = 4.850
Epoch   2 Batch  238/575   train_loss = 4.902
Epoch   2 Batch  239/575   train_loss = 5.282
Epoch   2 Batch  240/575   train_loss = 5.351
Epoch   2 Batch  241/575   train_loss = 5.643
Epoch   2 Batch  242/575   train_loss = 4.959
Epoch   2 Batch  243/575   train_loss = 5.208
Epoch   2 Batch  244/575   train_loss = 5.119
Epoch   2 Batch  245/575   train_loss = 5.241
Epoch   2 Batch  246/575   train_loss = 5.533
Epoch   2 Batch  247/575   train_loss = 4.921
Epoch   2 Batch  248/575   train_loss = 5.288
Epoch   2 Batch  249/575   train_loss = 5.255
Epoch   2 Batch  250/575   train_loss = 4.969
Epoch   2 Batch  251/575   train_loss = 5.300
Epoch   2 Batch  252/575   train_loss = 5.437
Epoch   2 Batch  253/575   train_loss = 5.082
Epoch   2 Batch  254/575   train_loss = 4.728
Epoch   2 Batch  255/575   train_loss = 5.368
Epoch   2 Batch  256/575   train_loss = 4.977
Epoch   2 Batch  257/575   train_loss = 5.174
Epoch   2 Batch  258/575   train_loss = 5.511
Epoch   2 Batch  259/575   train_loss = 4.756
Epoch   2 Batch  260/575   train_loss = 4.761
Epoch   2 Batch  261/575   train_loss = 5.803
Epoch   2 Batch  262/575   train_loss = 5.487
Epoch   2 Batch  263/575   train_loss = 5.152
Epoch   2 Batch  264/575   train_loss = 4.651
Epoch   2 Batch  265/575   train_loss = 4.340
Epoch   2 Batch  266/575   train_loss = 4.656
Epoch   2 Batch  267/575   train_loss = 5.122
Epoch   2 Batch  268/575   train_loss = 5.157
Epoch   2 Batch  269/575   train_loss = 5.160
Epoch   2 Batch  270/575   train_loss = 5.654
Epoch   2 Batch  271/575   train_loss = 4.833
Epoch   2 Batch  272/575   train_loss = 5.431
Epoch   2 Batch  273/575   train_loss = 5.311
Epoch   2 Batch  274/575   train_loss = 5.251
Epoch   2 Batch  275/575   train_loss = 5.325
Epoch   2 Batch  276/575   train_loss = 5.682
Epoch   2 Batch  277/575   train_loss = 4.433
Epoch   2 Batch  278/575   train_loss = 5.041
Epoch   2 Batch  279/575   train_loss = 5.165
Epoch   2 Batch  280/575   train_loss = 5.522
Epoch   2 Batch  281/575   train_loss = 4.865
Epoch   2 Batch  282/575   train_loss = 5.160
Epoch   2 Batch  283/575   train_loss = 5.468
Epoch   2 Batch  284/575   train_loss = 5.625
Epoch   2 Batch  285/575   train_loss = 4.961
Epoch   2 Batch  286/575   train_loss = 5.240
Epoch   2 Batch  287/575   train_loss = 5.432
Epoch   2 Batch  288/575   train_loss = 5.144
Epoch   2 Batch  289/575   train_loss = 5.242
Epoch   2 Batch  290/575   train_loss = 5.335
Epoch   2 Batch  291/575   train_loss = 5.905
Epoch   2 Batch  292/575   train_loss = 5.594
Epoch   2 Batch  293/575   train_loss = 5.874
Epoch   2 Batch  294/575   train_loss = 5.558
Epoch   2 Batch  295/575   train_loss = 5.089
Epoch   2 Batch  296/575   train_loss = 5.041
Epoch   2 Batch  297/575   train_loss = 5.271
Epoch   2 Batch  298/575   train_loss = 5.420
Epoch   2 Batch  299/575   train_loss = 5.298
Epoch   2 Batch  300/575   train_loss = 5.067
Epoch   2 Batch  301/575   train_loss = 4.968
Epoch   2 Batch  302/575   train_loss = 5.498
Epoch   2 Batch  303/575   train_loss = 4.844
Epoch   2 Batch  304/575   train_loss = 4.947
Epoch   2 Batch  305/575   train_loss = 4.992
Epoch   2 Batch  306/575   train_loss = 5.406
Epoch   2 Batch  307/575   train_loss = 5.420
Epoch   2 Batch  308/575   train_loss = 5.367
Epoch   2 Batch  309/575   train_loss = 5.596
Epoch   2 Batch  310/575   train_loss = 5.494
Epoch   2 Batch  311/575   train_loss = 4.828
Epoch   2 Batch  312/575   train_loss = 5.414
Epoch   2 Batch  313/575   train_loss = 5.703
Epoch   2 Batch  314/575   train_loss = 5.487
Epoch   2 Batch  315/575   train_loss = 5.829
Epoch   2 Batch  316/575   train_loss = 5.152
Epoch   2 Batch  317/575   train_loss = 4.754
Epoch   2 Batch  318/575   train_loss = 4.507
Epoch   2 Batch  319/575   train_loss = 5.192
Epoch   2 Batch  320/575   train_loss = 4.849
Epoch   2 Batch  321/575   train_loss = 5.697
Epoch   2 Batch  322/575   train_loss = 5.134
Epoch   2 Batch  323/575   train_loss = 5.536
Epoch   2 Batch  324/575   train_loss = 5.027
Epoch   2 Batch  325/575   train_loss = 5.169
Epoch   2 Batch  326/575   train_loss = 5.064
Epoch   2 Batch  327/575   train_loss = 5.506
Epoch   2 Batch  328/575   train_loss = 5.338
Epoch   2 Batch  329/575   train_loss = 5.679
Epoch   2 Batch  330/575   train_loss = 5.285
Epoch   2 Batch  331/575   train_loss = 5.785
Epoch   2 Batch  332/575   train_loss = 5.524
Epoch   2 Batch  333/575   train_loss = 5.470
Epoch   2 Batch  334/575   train_loss = 5.075
Epoch   2 Batch  335/575   train_loss = 5.043
Epoch   2 Batch  336/575   train_loss = 5.309
Epoch   2 Batch  337/575   train_loss = 5.186
Epoch   2 Batch  338/575   train_loss = 4.887
Epoch   2 Batch  339/575   train_loss = 5.252
Epoch   2 Batch  340/575   train_loss = 5.076
Epoch   2 Batch  341/575   train_loss = 5.000
Epoch   2 Batch  342/575   train_loss = 4.870
Epoch   2 Batch  343/575   train_loss = 5.300
Epoch   2 Batch  344/575   train_loss = 5.333
Epoch   2 Batch  345/575   train_loss = 4.946
Epoch   2 Batch  346/575   train_loss = 5.776
Epoch   2 Batch  347/575   train_loss = 4.925
Epoch   2 Batch  348/575   train_loss = 4.915
Epoch   2 Batch  349/575   train_loss = 4.651
Epoch   2 Batch  350/575   train_loss = 5.294
Epoch   2 Batch  351/575   train_loss = 5.670
Epoch   2 Batch  352/575   train_loss = 5.460
Epoch   2 Batch  353/575   train_loss = 5.380
Epoch   2 Batch  354/575   train_loss = 5.095
Epoch   2 Batch  355/575   train_loss = 5.678
Epoch   2 Batch  356/575   train_loss = 5.228
Epoch   2 Batch  357/575   train_loss = 5.139
Epoch   2 Batch  358/575   train_loss = 5.433
Epoch   2 Batch  359/575   train_loss = 5.770
Epoch   2 Batch  360/575   train_loss = 4.724
Epoch   2 Batch  361/575   train_loss = 5.462
Epoch   2 Batch  362/575   train_loss = 5.197
Epoch   2 Batch  363/575   train_loss = 5.225
Epoch   2 Batch  364/575   train_loss = 4.786
Epoch   2 Batch  365/575   train_loss = 5.322
Epoch   2 Batch  366/575   train_loss = 4.802
Epoch   2 Batch  367/575   train_loss = 5.178
Epoch   2 Batch  368/575   train_loss = 5.791
Epoch   2 Batch  369/575   train_loss = 5.498
Epoch   2 Batch  370/575   train_loss = 5.450
Epoch   2 Batch  371/575   train_loss = 5.563
Epoch   2 Batch  372/575   train_loss = 5.106
Epoch   2 Batch  373/575   train_loss = 5.414
Epoch   2 Batch  374/575   train_loss = 4.661
Epoch   2 Batch  375/575   train_loss = 4.923
Epoch   2 Batch  376/575   train_loss = 5.278
Epoch   2 Batch  377/575   train_loss = 5.625
Epoch   2 Batch  378/575   train_loss = 5.628
Epoch   2 Batch  379/575   train_loss = 5.073
Epoch   2 Batch  380/575   train_loss = 4.766
Epoch   2 Batch  381/575   train_loss = 5.065
Epoch   2 Batch  382/575   train_loss = 5.399
Epoch   2 Batch  383/575   train_loss = 5.075
Epoch   2 Batch  384/575   train_loss = 5.247
Epoch   2 Batch  385/575   train_loss = 4.936
Epoch   2 Batch  386/575   train_loss = 4.903
Epoch   2 Batch  387/575   train_loss = 5.656
Epoch   2 Batch  388/575   train_loss = 5.023
Epoch   2 Batch  389/575   train_loss = 4.993
Epoch   2 Batch  390/575   train_loss = 5.237
Epoch   2 Batch  391/575   train_loss = 5.464
Epoch   2 Batch  392/575   train_loss = 5.115
Epoch   2 Batch  393/575   train_loss = 5.152
Epoch   2 Batch  394/575   train_loss = 5.478
Epoch   2 Batch  395/575   train_loss = 4.542
Epoch   2 Batch  396/575   train_loss = 5.011
Epoch   2 Batch  397/575   train_loss = 5.455
Epoch   2 Batch  398/575   train_loss = 5.522
Epoch   2 Batch  399/575   train_loss = 5.641
Epoch   2 Batch  400/575   train_loss = 5.432
Epoch   2 Batch  401/575   train_loss = 4.790
Epoch   2 Batch  402/575   train_loss = 5.045
Epoch   2 Batch  403/575   train_loss = 5.403
Epoch   2 Batch  404/575   train_loss = 5.494
Epoch   2 Batch  405/575   train_loss = 5.522
Epoch   2 Batch  406/575   train_loss = 4.882
Epoch   2 Batch  407/575   train_loss = 5.188
Epoch   2 Batch  408/575   train_loss = 5.254
Epoch   2 Batch  409/575   train_loss = 5.090
Epoch   2 Batch  410/575   train_loss = 4.948
Epoch   2 Batch  411/575   train_loss = 5.160
Epoch   2 Batch  412/575   train_loss = 5.772
Epoch   2 Batch  413/575   train_loss = 5.520
Epoch   2 Batch  414/575   train_loss = 5.339
Epoch   2 Batch  415/575   train_loss = 5.788
Epoch   2 Batch  416/575   train_loss = 5.129
Epoch   2 Batch  417/575   train_loss = 4.862
Epoch   2 Batch  418/575   train_loss = 5.159
Epoch   2 Batch  419/575   train_loss = 5.131
Epoch   2 Batch  420/575   train_loss = 5.149
Epoch   2 Batch  421/575   train_loss = 5.754
Epoch   2 Batch  422/575   train_loss = 5.379
Epoch   2 Batch  423/575   train_loss = 5.907
Epoch   2 Batch  424/575   train_loss = 5.920
Epoch   2 Batch  425/575   train_loss = 5.551
Epoch   2 Batch  426/575   train_loss = 5.337
Epoch   2 Batch  427/575   train_loss = 5.177
Epoch   2 Batch  428/575   train_loss = 5.301
Epoch   2 Batch  429/575   train_loss = 4.848
Epoch   2 Batch  430/575   train_loss = 5.258
Epoch   2 Batch  431/575   train_loss = 5.194
Epoch   2 Batch  432/575   train_loss = 5.610
Epoch   2 Batch  433/575   train_loss = 5.616
Epoch   2 Batch  434/575   train_loss = 5.379
Epoch   2 Batch  435/575   train_loss = 5.349
Epoch   2 Batch  436/575   train_loss = 4.928
Epoch   2 Batch  437/575   train_loss = 5.301
Epoch   2 Batch  438/575   train_loss = 5.435
Epoch   2 Batch  439/575   train_loss = 5.260
Epoch   2 Batch  440/575   train_loss = 5.495
Epoch   2 Batch  441/575   train_loss = 5.300
Epoch   2 Batch  442/575   train_loss = 5.365
Epoch   2 Batch  443/575   train_loss = 5.274
Epoch   2 Batch  444/575   train_loss = 5.465
Epoch   2 Batch  445/575   train_loss = 5.041
Epoch   2 Batch  446/575   train_loss = 4.984
Epoch   2 Batch  447/575   train_loss = 5.531
Epoch   2 Batch  448/575   train_loss = 5.199
Epoch   2 Batch  449/575   train_loss = 5.311
Epoch   2 Batch  450/575   train_loss = 5.970
Epoch   2 Batch  451/575   train_loss = 5.771
Epoch   2 Batch  452/575   train_loss = 5.903
Epoch   2 Batch  453/575   train_loss = 5.399
Epoch   2 Batch  454/575   train_loss = 5.734
Epoch   2 Batch  455/575   train_loss = 5.005
Epoch   2 Batch  456/575   train_loss = 5.713
Epoch   2 Batch  457/575   train_loss = 4.881
Epoch   2 Batch  458/575   train_loss = 5.633
Epoch   2 Batch  459/575   train_loss = 5.532
Epoch   2 Batch  460/575   train_loss = 5.296
Epoch   2 Batch  461/575   train_loss = 5.502
Epoch   2 Batch  462/575   train_loss = 5.206
Epoch   2 Batch  463/575   train_loss = 5.153
Epoch   2 Batch  464/575   train_loss = 4.955
Epoch   2 Batch  465/575   train_loss = 5.099
Epoch   2 Batch  466/575   train_loss = 5.093
Epoch   2 Batch  467/575   train_loss = 4.635
Epoch   2 Batch  468/575   train_loss = 5.001
Epoch   2 Batch  469/575   train_loss = 5.603
Epoch   2 Batch  470/575   train_loss = 5.829
Epoch   2 Batch  471/575   train_loss = 5.028
Epoch   2 Batch  472/575   train_loss = 5.508
Epoch   2 Batch  473/575   train_loss = 5.261
Epoch   2 Batch  474/575   train_loss = 5.273
Epoch   2 Batch  475/575   train_loss = 4.995
Epoch   2 Batch  476/575   train_loss = 5.187
Epoch   2 Batch  477/575   train_loss = 5.702
Epoch   2 Batch  478/575   train_loss = 5.822
Epoch   2 Batch  479/575   train_loss = 5.254
Epoch   2 Batch  480/575   train_loss = 5.490
Epoch   2 Batch  481/575   train_loss = 5.522
Epoch   2 Batch  482/575   train_loss = 4.743
Epoch   2 Batch  483/575   train_loss = 6.170
Epoch   2 Batch  484/575   train_loss = 5.310
Epoch   2 Batch  485/575   train_loss = 5.652
Epoch   2 Batch  486/575   train_loss = 5.445
Epoch   2 Batch  487/575   train_loss = 5.501
Epoch   2 Batch  488/575   train_loss = 5.296
Epoch   2 Batch  489/575   train_loss = 5.534
Epoch   2 Batch  490/575   train_loss = 5.598
Epoch   2 Batch  491/575   train_loss = 4.782
Epoch   2 Batch  492/575   train_loss = 4.531
Epoch   2 Batch  493/575   train_loss = 4.744
Epoch   2 Batch  494/575   train_loss = 4.974
Epoch   2 Batch  495/575   train_loss = 5.220
Epoch   2 Batch  496/575   train_loss = 5.367
Epoch   2 Batch  497/575   train_loss = 5.593
Epoch   2 Batch  498/575   train_loss = 5.008
Epoch   2 Batch  499/575   train_loss = 5.018
Epoch   2 Batch  500/575   train_loss = 5.209
Epoch   2 Batch  501/575   train_loss = 5.205
Epoch   2 Batch  502/575   train_loss = 4.602
Epoch   2 Batch  503/575   train_loss = 5.396
Epoch   2 Batch  504/575   train_loss = 4.814
Epoch   2 Batch  505/575   train_loss = 5.162
Epoch   2 Batch  506/575   train_loss = 5.493
Epoch   2 Batch  507/575   train_loss = 5.577
Epoch   2 Batch  508/575   train_loss = 5.437
Epoch   2 Batch  509/575   train_loss = 5.339
Epoch   2 Batch  510/575   train_loss = 4.719
Epoch   2 Batch  511/575   train_loss = 4.635
Epoch   2 Batch  512/575   train_loss = 5.660
Epoch   2 Batch  513/575   train_loss = 5.382
Epoch   2 Batch  514/575   train_loss = 5.206
Epoch   2 Batch  515/575   train_loss = 5.321
Epoch   2 Batch  516/575   train_loss = 5.580
Epoch   2 Batch  517/575   train_loss = 4.895
Epoch   2 Batch  518/575   train_loss = 5.088
Epoch   2 Batch  519/575   train_loss = 5.082
Epoch   2 Batch  520/575   train_loss = 4.341
Epoch   2 Batch  521/575   train_loss = 4.924
Epoch   2 Batch  522/575   train_loss = 4.913
Epoch   2 Batch  523/575   train_loss = 5.771
Epoch   2 Batch  524/575   train_loss = 6.837
Epoch   2 Batch  525/575   train_loss = 5.201
Epoch   2 Batch  526/575   train_loss = 5.010
Epoch   2 Batch  527/575   train_loss = 5.351
Epoch   2 Batch  528/575   train_loss = 5.025
Epoch   2 Batch  529/575   train_loss = 5.375
Epoch   2 Batch  530/575   train_loss = 5.382
Epoch   2 Batch  531/575   train_loss = 5.388
Epoch   2 Batch  532/575   train_loss = 5.035
Epoch   2 Batch  533/575   train_loss = 5.036
Epoch   2 Batch  534/575   train_loss = 5.052
Epoch   2 Batch  535/575   train_loss = 5.589
Epoch   2 Batch  536/575   train_loss = 5.238
Epoch   2 Batch  537/575   train_loss = 4.766
Epoch   2 Batch  538/575   train_loss = 5.238
Epoch   2 Batch  539/575   train_loss = 4.979
Epoch   2 Batch  540/575   train_loss = 5.347
Epoch   2 Batch  541/575   train_loss = 5.804
Epoch   2 Batch  542/575   train_loss = 5.321
Epoch   2 Batch  543/575   train_loss = 5.579
Epoch   2 Batch  544/575   train_loss = 5.318
Epoch   2 Batch  545/575   train_loss = 5.435
Epoch   2 Batch  546/575   train_loss = 5.416
Epoch   2 Batch  547/575   train_loss = 5.325
Epoch   2 Batch  548/575   train_loss = 5.393
Epoch   2 Batch  549/575   train_loss = 5.063
Epoch   2 Batch  550/575   train_loss = 5.109
Epoch   2 Batch  551/575   train_loss = 5.051
Epoch   2 Batch  552/575   train_loss = 5.292
Epoch   2 Batch  553/575   train_loss = 5.279
Epoch   2 Batch  554/575   train_loss = 5.081
Epoch   2 Batch  555/575   train_loss = 5.429
Epoch   2 Batch  556/575   train_loss = 5.031
Epoch   2 Batch  557/575   train_loss = 4.780
Epoch   2 Batch  558/575   train_loss = 5.218
Epoch   2 Batch  559/575   train_loss = 5.297
Epoch   2 Batch  560/575   train_loss = 4.774
Epoch   2 Batch  561/575   train_loss = 5.181
Epoch   2 Batch  562/575   train_loss = 4.722
Epoch   2 Batch  563/575   train_loss = 5.196
Epoch   2 Batch  564/575   train_loss = 4.787
Epoch   2 Batch  565/575   train_loss = 4.527
Epoch   2 Batch  566/575   train_loss = 4.887
Epoch   2 Batch  567/575   train_loss = 4.628
Epoch   2 Batch  568/575   train_loss = 4.869
Epoch   2 Batch  569/575   train_loss = 5.129
Epoch   2 Batch  570/575   train_loss = 4.767
Epoch   2 Batch  571/575   train_loss = 4.686
Epoch   2 Batch  572/575   train_loss = 4.298
Epoch   2 Batch  573/575   train_loss = 4.774
Epoch   2 Batch  574/575   train_loss = 5.423
Epoch   3 Batch    0/575   train_loss = 5.014
Epoch   3 Batch    1/575   train_loss = 4.951
Epoch   3 Batch    2/575   train_loss = 5.170
Epoch   3 Batch    3/575   train_loss = 4.885
Epoch   3 Batch    4/575   train_loss = 4.790
Epoch   3 Batch    5/575   train_loss = 4.821
Epoch   3 Batch    6/575   train_loss = 4.668
Epoch   3 Batch    7/575   train_loss = 5.008
Epoch   3 Batch    8/575   train_loss = 4.964
Epoch   3 Batch    9/575   train_loss = 5.138
Epoch   3 Batch   10/575   train_loss = 4.594
Epoch   3 Batch   11/575   train_loss = 4.828
Epoch   3 Batch   12/575   train_loss = 4.939
Epoch   3 Batch   13/575   train_loss = 5.171
Epoch   3 Batch   14/575   train_loss = 5.506
Epoch   3 Batch   15/575   train_loss = 5.276
Epoch   3 Batch   16/575   train_loss = 5.171
Epoch   3 Batch   17/575   train_loss = 4.396
Epoch   3 Batch   18/575   train_loss = 5.489
Epoch   3 Batch   19/575   train_loss = 5.105
Epoch   3 Batch   20/575   train_loss = 4.667
Epoch   3 Batch   21/575   train_loss = 4.775
Epoch   3 Batch   22/575   train_loss = 5.555
Epoch   3 Batch   23/575   train_loss = 5.141
Epoch   3 Batch   24/575   train_loss = 4.952
Epoch   3 Batch   25/575   train_loss = 5.119
Epoch   3 Batch   26/575   train_loss = 5.307
Epoch   3 Batch   27/575   train_loss = 5.145
Epoch   3 Batch   28/575   train_loss = 4.592
Epoch   3 Batch   29/575   train_loss = 4.736
Epoch   3 Batch   30/575   train_loss = 5.666
Epoch   3 Batch   31/575   train_loss = 5.921
Epoch   3 Batch   32/575   train_loss = 5.067
Epoch   3 Batch   33/575   train_loss = 5.400
Epoch   3 Batch   34/575   train_loss = 4.967
Epoch   3 Batch   35/575   train_loss = 4.931
Epoch   3 Batch   36/575   train_loss = 5.217
Epoch   3 Batch   37/575   train_loss = 4.447
Epoch   3 Batch   38/575   train_loss = 5.190
Epoch   3 Batch   39/575   train_loss = 4.506
Epoch   3 Batch   40/575   train_loss = 4.330
Epoch   3 Batch   41/575   train_loss = 6.195
Epoch   3 Batch   42/575   train_loss = 5.121
Epoch   3 Batch   43/575   train_loss = 5.113
Epoch   3 Batch   44/575   train_loss = 4.989
Epoch   3 Batch   45/575   train_loss = 4.894
Epoch   3 Batch   46/575   train_loss = 4.817
Epoch   3 Batch   47/575   train_loss = 5.122
Epoch   3 Batch   48/575   train_loss = 4.324
Epoch   3 Batch   49/575   train_loss = 4.586
Epoch   3 Batch   50/575   train_loss = 4.867
Epoch   3 Batch   51/575   train_loss = 4.737
Epoch   3 Batch   52/575   train_loss = 4.702
Epoch   3 Batch   53/575   train_loss = 4.485
Epoch   3 Batch   54/575   train_loss = 5.057
Epoch   3 Batch   55/575   train_loss = 5.338
Epoch   3 Batch   56/575   train_loss = 4.652
Epoch   3 Batch   57/575   train_loss = 5.004
Epoch   3 Batch   58/575   train_loss = 4.688
Epoch   3 Batch   59/575   train_loss = 4.403
Epoch   3 Batch   60/575   train_loss = 5.144
Epoch   3 Batch   61/575   train_loss = 5.041
Epoch   3 Batch   62/575   train_loss = 4.686
Epoch   3 Batch   63/575   train_loss = 5.386
Epoch   3 Batch   64/575   train_loss = 5.288
Epoch   3 Batch   65/575   train_loss = 4.778
Epoch   3 Batch   66/575   train_loss = 4.797
Epoch   3 Batch   67/575   train_loss = 4.588
Epoch   3 Batch   68/575   train_loss = 4.759
Epoch   3 Batch   69/575   train_loss = 4.406
Epoch   3 Batch   70/575   train_loss = 4.970
Epoch   3 Batch   71/575   train_loss = 4.691
Epoch   3 Batch   72/575   train_loss = 5.268
Epoch   3 Batch   73/575   train_loss = 5.252
Epoch   3 Batch   74/575   train_loss = 5.548
Epoch   3 Batch   75/575   train_loss = 5.079
Epoch   3 Batch   76/575   train_loss = 5.438
Epoch   3 Batch   77/575   train_loss = 5.501
Epoch   3 Batch   78/575   train_loss = 5.184
Epoch   3 Batch   79/575   train_loss = 5.059
Epoch   3 Batch   80/575   train_loss = 4.917
Epoch   3 Batch   81/575   train_loss = 4.887
Epoch   3 Batch   82/575   train_loss = 4.641
Epoch   3 Batch   83/575   train_loss = 4.830
Epoch   3 Batch   84/575   train_loss = 4.915
Epoch   3 Batch   85/575   train_loss = 5.615
Epoch   3 Batch   86/575   train_loss = 4.879
Epoch   3 Batch   87/575   train_loss = 5.502
Epoch   3 Batch   88/575   train_loss = 4.296
Epoch   3 Batch   89/575   train_loss = 4.590
Epoch   3 Batch   90/575   train_loss = 4.825
Epoch   3 Batch   91/575   train_loss = 5.053
Epoch   3 Batch   92/575   train_loss = 5.651
Epoch   3 Batch   93/575   train_loss = 5.149
Epoch   3 Batch   94/575   train_loss = 4.733
Epoch   3 Batch   95/575   train_loss = 5.072
Epoch   3 Batch   96/575   train_loss = 5.059
Epoch   3 Batch   97/575   train_loss = 5.206
Epoch   3 Batch   98/575   train_loss = 4.849
Epoch   3 Batch   99/575   train_loss = 5.580
Epoch   3 Batch  100/575   train_loss = 5.294
Epoch   3 Batch  101/575   train_loss = 4.816
Epoch   3 Batch  102/575   train_loss = 4.599
Epoch   3 Batch  103/575   train_loss = 5.349
Epoch   3 Batch  104/575   train_loss = 5.030
Epoch   3 Batch  105/575   train_loss = 5.199
Epoch   3 Batch  106/575   train_loss = 4.901
Epoch   3 Batch  107/575   train_loss = 4.687
Epoch   3 Batch  108/575   train_loss = 5.177
Epoch   3 Batch  109/575   train_loss = 4.971
Epoch   3 Batch  110/575   train_loss = 4.077
Epoch   3 Batch  111/575   train_loss = 4.899
Epoch   3 Batch  112/575   train_loss = 5.088
Epoch   3 Batch  113/575   train_loss = 5.630
Epoch   3 Batch  114/575   train_loss = 5.193
Epoch   3 Batch  115/575   train_loss = 4.698
Epoch   3 Batch  116/575   train_loss = 5.207
Epoch   3 Batch  117/575   train_loss = 4.567
Epoch   3 Batch  118/575   train_loss = 5.133
Epoch   3 Batch  119/575   train_loss = 5.684
Epoch   3 Batch  120/575   train_loss = 5.145
Epoch   3 Batch  121/575   train_loss = 5.272
Epoch   3 Batch  122/575   train_loss = 5.344
Epoch   3 Batch  123/575   train_loss = 5.051
Epoch   3 Batch  124/575   train_loss = 5.388
Epoch   3 Batch  125/575   train_loss = 5.288
Epoch   3 Batch  126/575   train_loss = 5.143
Epoch   3 Batch  127/575   train_loss = 4.514
Epoch   3 Batch  128/575   train_loss = 4.824
Epoch   3 Batch  129/575   train_loss = 4.904
Epoch   3 Batch  130/575   train_loss = 5.283
Epoch   3 Batch  131/575   train_loss = 4.461
Epoch   3 Batch  132/575   train_loss = 4.778
Epoch   3 Batch  133/575   train_loss = 5.031
Epoch   3 Batch  134/575   train_loss = 4.880
Epoch   3 Batch  135/575   train_loss = 4.542
Epoch   3 Batch  136/575   train_loss = 6.074
Epoch   3 Batch  137/575   train_loss = 5.048
Epoch   3 Batch  138/575   train_loss = 5.575
Epoch   3 Batch  139/575   train_loss = 5.304
Epoch   3 Batch  140/575   train_loss = 5.260
Epoch   3 Batch  141/575   train_loss = 5.593
Epoch   3 Batch  142/575   train_loss = 6.096
Epoch   3 Batch  143/575   train_loss = 5.172
Epoch   3 Batch  144/575   train_loss = 4.710
Epoch   3 Batch  145/575   train_loss = 4.777
Epoch   3 Batch  146/575   train_loss = 4.831
Epoch   3 Batch  147/575   train_loss = 4.827
Epoch   3 Batch  148/575   train_loss = 4.397
Epoch   3 Batch  149/575   train_loss = 5.170
Epoch   3 Batch  150/575   train_loss = 5.438
Epoch   3 Batch  151/575   train_loss = 4.760
Epoch   3 Batch  152/575   train_loss = 4.645
Epoch   3 Batch  153/575   train_loss = 4.177
Epoch   3 Batch  154/575   train_loss = 4.313
Epoch   3 Batch  155/575   train_loss = 5.115
Epoch   3 Batch  156/575   train_loss = 4.884
Epoch   3 Batch  157/575   train_loss = 5.058
Epoch   3 Batch  158/575   train_loss = 5.009
Epoch   3 Batch  159/575   train_loss = 5.292
Epoch   3 Batch  160/575   train_loss = 4.708
Epoch   3 Batch  161/575   train_loss = 5.453
Epoch   3 Batch  162/575   train_loss = 5.269
Epoch   3 Batch  163/575   train_loss = 4.883
Epoch   3 Batch  164/575   train_loss = 5.260
Epoch   3 Batch  165/575   train_loss = 5.174
Epoch   3 Batch  166/575   train_loss = 4.723
Epoch   3 Batch  167/575   train_loss = 4.775
Epoch   3 Batch  168/575   train_loss = 5.205
Epoch   3 Batch  169/575   train_loss = 4.781
Epoch   3 Batch  170/575   train_loss = 5.267
Epoch   3 Batch  171/575   train_loss = 4.861
Epoch   3 Batch  172/575   train_loss = 5.109
Epoch   3 Batch  173/575   train_loss = 5.117
Epoch   3 Batch  174/575   train_loss = 5.434
Epoch   3 Batch  175/575   train_loss = 5.191
Epoch   3 Batch  176/575   train_loss = 5.200
Epoch   3 Batch  177/575   train_loss = 5.399
Epoch   3 Batch  178/575   train_loss = 5.050
Epoch   3 Batch  179/575   train_loss = 4.831
Epoch   3 Batch  180/575   train_loss = 4.918
Epoch   3 Batch  181/575   train_loss = 5.228
Epoch   3 Batch  182/575   train_loss = 4.818
Epoch   3 Batch  183/575   train_loss = 5.271
Epoch   3 Batch  184/575   train_loss = 4.394
Epoch   3 Batch  185/575   train_loss = 4.918
Epoch   3 Batch  186/575   train_loss = 5.207
Epoch   3 Batch  187/575   train_loss = 4.895
Epoch   3 Batch  188/575   train_loss = 4.947
Epoch   3 Batch  189/575   train_loss = 4.826
Epoch   3 Batch  190/575   train_loss = 5.090
Epoch   3 Batch  191/575   train_loss = 5.561
Epoch   3 Batch  192/575   train_loss = 5.362
Epoch   3 Batch  193/575   train_loss = 5.012
Epoch   3 Batch  194/575   train_loss = 5.184
Epoch   3 Batch  195/575   train_loss = 4.786
Epoch   3 Batch  196/575   train_loss = 4.720
Epoch   3 Batch  197/575   train_loss = 4.666
Epoch   3 Batch  198/575   train_loss = 5.325
Epoch   3 Batch  199/575   train_loss = 4.443
Epoch   3 Batch  200/575   train_loss = 4.749
Epoch   3 Batch  201/575   train_loss = 5.016
Epoch   3 Batch  202/575   train_loss = 4.510
Epoch   3 Batch  203/575   train_loss = 4.834
Epoch   3 Batch  204/575   train_loss = 4.841
Epoch   3 Batch  205/575   train_loss = 4.605
Epoch   3 Batch  206/575   train_loss = 4.997
Epoch   3 Batch  207/575   train_loss = 4.666
Epoch   3 Batch  208/575   train_loss = 4.505
Epoch   3 Batch  209/575   train_loss = 4.610
Epoch   3 Batch  210/575   train_loss = 4.900
Epoch   3 Batch  211/575   train_loss = 5.681
Epoch   3 Batch  212/575   train_loss = 5.214
Epoch   3 Batch  213/575   train_loss = 5.093
Epoch   3 Batch  214/575   train_loss = 4.740
Epoch   3 Batch  215/575   train_loss = 4.113
Epoch   3 Batch  216/575   train_loss = 4.735
Epoch   3 Batch  217/575   train_loss = 4.434
Epoch   3 Batch  218/575   train_loss = 5.093
Epoch   3 Batch  219/575   train_loss = 4.795
Epoch   3 Batch  220/575   train_loss = 4.332
Epoch   3 Batch  221/575   train_loss = 5.084
Epoch   3 Batch  222/575   train_loss = 5.109
Epoch   3 Batch  223/575   train_loss = 5.325
Epoch   3 Batch  224/575   train_loss = 4.571
Epoch   3 Batch  225/575   train_loss = 4.801
Epoch   3 Batch  226/575   train_loss = 5.090
Epoch   3 Batch  227/575   train_loss = 5.385
Epoch   3 Batch  228/575   train_loss = 5.248
Epoch   3 Batch  229/575   train_loss = 4.094
Epoch   3 Batch  230/575   train_loss = 4.249
Epoch   3 Batch  231/575   train_loss = 4.883
Epoch   3 Batch  232/575   train_loss = 4.930
Epoch   3 Batch  233/575   train_loss = 5.069
Epoch   3 Batch  234/575   train_loss = 5.073
Epoch   3 Batch  235/575   train_loss = 4.665
Epoch   3 Batch  236/575   train_loss = 4.286
Epoch   3 Batch  237/575   train_loss = 4.625
Epoch   3 Batch  238/575   train_loss = 4.665
Epoch   3 Batch  239/575   train_loss = 5.059
Epoch   3 Batch  240/575   train_loss = 5.225
Epoch   3 Batch  241/575   train_loss = 5.367
Epoch   3 Batch  242/575   train_loss = 4.758
Epoch   3 Batch  243/575   train_loss = 4.965
Epoch   3 Batch  244/575   train_loss = 4.904
Epoch   3 Batch  245/575   train_loss = 5.026
Epoch   3 Batch  246/575   train_loss = 5.344
Epoch   3 Batch  247/575   train_loss = 4.723
Epoch   3 Batch  248/575   train_loss = 5.093
Epoch   3 Batch  249/575   train_loss = 5.005
Epoch   3 Batch  250/575   train_loss = 4.793
Epoch   3 Batch  251/575   train_loss = 5.060
Epoch   3 Batch  252/575   train_loss = 5.240
Epoch   3 Batch  253/575   train_loss = 4.923
Epoch   3 Batch  254/575   train_loss = 4.496
Epoch   3 Batch  255/575   train_loss = 5.175
Epoch   3 Batch  256/575   train_loss = 4.804
Epoch   3 Batch  257/575   train_loss = 4.973
Epoch   3 Batch  258/575   train_loss = 5.338
Epoch   3 Batch  259/575   train_loss = 4.537
Epoch   3 Batch  260/575   train_loss = 4.584
Epoch   3 Batch  261/575   train_loss = 5.564
Epoch   3 Batch  262/575   train_loss = 5.261
Epoch   3 Batch  263/575   train_loss = 4.973
Epoch   3 Batch  264/575   train_loss = 4.384
Epoch   3 Batch  265/575   train_loss = 4.152
Epoch   3 Batch  266/575   train_loss = 4.445
Epoch   3 Batch  267/575   train_loss = 4.896
Epoch   3 Batch  268/575   train_loss = 4.916
Epoch   3 Batch  269/575   train_loss = 5.012
Epoch   3 Batch  270/575   train_loss = 5.450
Epoch   3 Batch  271/575   train_loss = 4.596
Epoch   3 Batch  272/575   train_loss = 5.210
Epoch   3 Batch  273/575   train_loss = 5.123
Epoch   3 Batch  274/575   train_loss = 5.073
Epoch   3 Batch  275/575   train_loss = 5.066
Epoch   3 Batch  276/575   train_loss = 5.468
Epoch   3 Batch  277/575   train_loss = 4.143
Epoch   3 Batch  278/575   train_loss = 4.868
Epoch   3 Batch  279/575   train_loss = 4.982
Epoch   3 Batch  280/575   train_loss = 5.270
Epoch   3 Batch  281/575   train_loss = 4.725
Epoch   3 Batch  282/575   train_loss = 4.980
Epoch   3 Batch  283/575   train_loss = 5.250
Epoch   3 Batch  284/575   train_loss = 5.431
Epoch   3 Batch  285/575   train_loss = 4.753
Epoch   3 Batch  286/575   train_loss = 4.988
Epoch   3 Batch  287/575   train_loss = 5.223
Epoch   3 Batch  288/575   train_loss = 4.904
Epoch   3 Batch  289/575   train_loss = 4.968
Epoch   3 Batch  290/575   train_loss = 5.056
Epoch   3 Batch  291/575   train_loss = 5.658
Epoch   3 Batch  292/575   train_loss = 5.406
Epoch   3 Batch  293/575   train_loss = 5.646
Epoch   3 Batch  294/575   train_loss = 5.326
Epoch   3 Batch  295/575   train_loss = 4.881
Epoch   3 Batch  296/575   train_loss = 4.874
Epoch   3 Batch  297/575   train_loss = 5.085
Epoch   3 Batch  298/575   train_loss = 5.168
Epoch   3 Batch  299/575   train_loss = 5.062
Epoch   3 Batch  300/575   train_loss = 4.850
Epoch   3 Batch  301/575   train_loss = 4.747
Epoch   3 Batch  302/575   train_loss = 5.263
Epoch   3 Batch  303/575   train_loss = 4.629
Epoch   3 Batch  304/575   train_loss = 4.790
Epoch   3 Batch  305/575   train_loss = 4.813
Epoch   3 Batch  306/575   train_loss = 5.173
Epoch   3 Batch  307/575   train_loss = 5.214
Epoch   3 Batch  308/575   train_loss = 5.111
Epoch   3 Batch  309/575   train_loss = 5.409
Epoch   3 Batch  310/575   train_loss = 5.322
Epoch   3 Batch  311/575   train_loss = 4.623
Epoch   3 Batch  312/575   train_loss = 5.189
Epoch   3 Batch  313/575   train_loss = 5.504
Epoch   3 Batch  314/575   train_loss = 5.339
Epoch   3 Batch  315/575   train_loss = 5.600
Epoch   3 Batch  316/575   train_loss = 4.938
Epoch   3 Batch  317/575   train_loss = 4.533
Epoch   3 Batch  318/575   train_loss = 4.259
Epoch   3 Batch  319/575   train_loss = 4.994
Epoch   3 Batch  320/575   train_loss = 4.685
Epoch   3 Batch  321/575   train_loss = 5.461
Epoch   3 Batch  322/575   train_loss = 4.923
Epoch   3 Batch  323/575   train_loss = 5.338
Epoch   3 Batch  324/575   train_loss = 4.843
Epoch   3 Batch  325/575   train_loss = 5.006
Epoch   3 Batch  326/575   train_loss = 4.811
Epoch   3 Batch  327/575   train_loss = 5.232
Epoch   3 Batch  328/575   train_loss = 5.015
Epoch   3 Batch  329/575   train_loss = 5.404
Epoch   3 Batch  330/575   train_loss = 5.054
Epoch   3 Batch  331/575   train_loss = 5.598
Epoch   3 Batch  332/575   train_loss = 5.308
Epoch   3 Batch  333/575   train_loss = 5.218
Epoch   3 Batch  334/575   train_loss = 4.920
Epoch   3 Batch  335/575   train_loss = 4.778
Epoch   3 Batch  336/575   train_loss = 5.104
Epoch   3 Batch  337/575   train_loss = 4.998
Epoch   3 Batch  338/575   train_loss = 4.695
Epoch   3 Batch  339/575   train_loss = 5.054
Epoch   3 Batch  340/575   train_loss = 4.858
Epoch   3 Batch  341/575   train_loss = 4.830
Epoch   3 Batch  342/575   train_loss = 4.702
Epoch   3 Batch  343/575   train_loss = 5.100
Epoch   3 Batch  344/575   train_loss = 5.147
Epoch   3 Batch  345/575   train_loss = 4.804
Epoch   3 Batch  346/575   train_loss = 5.585
Epoch   3 Batch  347/575   train_loss = 4.711
Epoch   3 Batch  348/575   train_loss = 4.729
Epoch   3 Batch  349/575   train_loss = 4.484
Epoch   3 Batch  350/575   train_loss = 5.092
Epoch   3 Batch  351/575   train_loss = 5.491
Epoch   3 Batch  352/575   train_loss = 5.230
Epoch   3 Batch  353/575   train_loss = 5.195
Epoch   3 Batch  354/575   train_loss = 4.869
Epoch   3 Batch  355/575   train_loss = 5.428
Epoch   3 Batch  356/575   train_loss = 5.073
Epoch   3 Batch  357/575   train_loss = 4.975
Epoch   3 Batch  358/575   train_loss = 5.289
Epoch   3 Batch  359/575   train_loss = 5.554
Epoch   3 Batch  360/575   train_loss = 4.500
Epoch   3 Batch  361/575   train_loss = 5.237
Epoch   3 Batch  362/575   train_loss = 4.993
Epoch   3 Batch  363/575   train_loss = 5.005
Epoch   3 Batch  364/575   train_loss = 4.618
Epoch   3 Batch  365/575   train_loss = 5.111
Epoch   3 Batch  366/575   train_loss = 4.556
Epoch   3 Batch  367/575   train_loss = 4.980
Epoch   3 Batch  368/575   train_loss = 5.595
Epoch   3 Batch  369/575   train_loss = 5.295
Epoch   3 Batch  370/575   train_loss = 5.233
Epoch   3 Batch  371/575   train_loss = 5.342
Epoch   3 Batch  372/575   train_loss = 4.879
Epoch   3 Batch  373/575   train_loss = 5.247
Epoch   3 Batch  374/575   train_loss = 4.419
Epoch   3 Batch  375/575   train_loss = 4.765
Epoch   3 Batch  376/575   train_loss = 5.056
Epoch   3 Batch  377/575   train_loss = 5.440
Epoch   3 Batch  378/575   train_loss = 5.484
Epoch   3 Batch  379/575   train_loss = 4.840
Epoch   3 Batch  380/575   train_loss = 4.544
Epoch   3 Batch  381/575   train_loss = 4.832
Epoch   3 Batch  382/575   train_loss = 5.143
Epoch   3 Batch  383/575   train_loss = 4.892
Epoch   3 Batch  384/575   train_loss = 4.991
Epoch   3 Batch  385/575   train_loss = 4.726
Epoch   3 Batch  386/575   train_loss = 4.742
Epoch   3 Batch  387/575   train_loss = 5.458
Epoch   3 Batch  388/575   train_loss = 4.820
Epoch   3 Batch  389/575   train_loss = 4.846
Epoch   3 Batch  390/575   train_loss = 5.061
Epoch   3 Batch  391/575   train_loss = 5.210
Epoch   3 Batch  392/575   train_loss = 4.950
Epoch   3 Batch  393/575   train_loss = 4.975
Epoch   3 Batch  394/575   train_loss = 5.292
Epoch   3 Batch  395/575   train_loss = 4.379
Epoch   3 Batch  396/575   train_loss = 4.769
Epoch   3 Batch  397/575   train_loss = 5.209
Epoch   3 Batch  398/575   train_loss = 5.422
Epoch   3 Batch  399/575   train_loss = 5.421
Epoch   3 Batch  400/575   train_loss = 5.280
Epoch   3 Batch  401/575   train_loss = 4.597
Epoch   3 Batch  402/575   train_loss = 4.775
Epoch   3 Batch  403/575   train_loss = 5.198
Epoch   3 Batch  404/575   train_loss = 5.281
Epoch   3 Batch  405/575   train_loss = 5.332
Epoch   3 Batch  406/575   train_loss = 4.695
Epoch   3 Batch  407/575   train_loss = 5.041
Epoch   3 Batch  408/575   train_loss = 5.058
Epoch   3 Batch  409/575   train_loss = 4.915
Epoch   3 Batch  410/575   train_loss = 4.762
Epoch   3 Batch  411/575   train_loss = 4.984
Epoch   3 Batch  412/575   train_loss = 5.633
Epoch   3 Batch  413/575   train_loss = 5.287
Epoch   3 Batch  414/575   train_loss = 5.039
Epoch   3 Batch  415/575   train_loss = 5.529
Epoch   3 Batch  416/575   train_loss = 4.906
Epoch   3 Batch  417/575   train_loss = 4.599
Epoch   3 Batch  418/575   train_loss = 4.984
Epoch   3 Batch  419/575   train_loss = 4.945
Epoch   3 Batch  420/575   train_loss = 4.849
Epoch   3 Batch  421/575   train_loss = 5.514
Epoch   3 Batch  422/575   train_loss = 5.183
Epoch   3 Batch  423/575   train_loss = 5.618
Epoch   3 Batch  424/575   train_loss = 5.667
Epoch   3 Batch  425/575   train_loss = 5.340
Epoch   3 Batch  426/575   train_loss = 5.146
Epoch   3 Batch  427/575   train_loss = 4.976
Epoch   3 Batch  428/575   train_loss = 5.012
Epoch   3 Batch  429/575   train_loss = 4.682
Epoch   3 Batch  430/575   train_loss = 5.065
Epoch   3 Batch  431/575   train_loss = 4.958
Epoch   3 Batch  432/575   train_loss = 5.403
Epoch   3 Batch  433/575   train_loss = 5.375
Epoch   3 Batch  434/575   train_loss = 5.197
Epoch   3 Batch  435/575   train_loss = 5.077
Epoch   3 Batch  436/575   train_loss = 4.756
Epoch   3 Batch  437/575   train_loss = 5.054
Epoch   3 Batch  438/575   train_loss = 5.239
Epoch   3 Batch  439/575   train_loss = 5.079
Epoch   3 Batch  440/575   train_loss = 5.296
Epoch   3 Batch  441/575   train_loss = 5.064
Epoch   3 Batch  442/575   train_loss = 5.178
Epoch   3 Batch  443/575   train_loss = 5.105
Epoch   3 Batch  444/575   train_loss = 5.238
Epoch   3 Batch  445/575   train_loss = 4.841
Epoch   3 Batch  446/575   train_loss = 4.738
Epoch   3 Batch  447/575   train_loss = 5.310
Epoch   3 Batch  448/575   train_loss = 5.043
Epoch   3 Batch  449/575   train_loss = 5.123
Epoch   3 Batch  450/575   train_loss = 5.754
Epoch   3 Batch  451/575   train_loss = 5.587
Epoch   3 Batch  452/575   train_loss = 5.673
Epoch   3 Batch  453/575   train_loss = 5.161
Epoch   3 Batch  454/575   train_loss = 5.520
Epoch   3 Batch  455/575   train_loss = 4.796
Epoch   3 Batch  456/575   train_loss = 5.531
Epoch   3 Batch  457/575   train_loss = 4.703
Epoch   3 Batch  458/575   train_loss = 5.439
Epoch   3 Batch  459/575   train_loss = 5.272
Epoch   3 Batch  460/575   train_loss = 5.018
Epoch   3 Batch  461/575   train_loss = 5.217
Epoch   3 Batch  462/575   train_loss = 4.990
Epoch   3 Batch  463/575   train_loss = 4.975
Epoch   3 Batch  464/575   train_loss = 4.805
Epoch   3 Batch  465/575   train_loss = 4.907
Epoch   3 Batch  466/575   train_loss = 4.918
Epoch   3 Batch  467/575   train_loss = 4.437
Epoch   3 Batch  468/575   train_loss = 4.848
Epoch   3 Batch  469/575   train_loss = 5.406
Epoch   3 Batch  470/575   train_loss = 5.645
Epoch   3 Batch  471/575   train_loss = 4.856
Epoch   3 Batch  472/575   train_loss = 5.292
Epoch   3 Batch  473/575   train_loss = 5.117
Epoch   3 Batch  474/575   train_loss = 5.090
Epoch   3 Batch  475/575   train_loss = 4.837
Epoch   3 Batch  476/575   train_loss = 5.017
Epoch   3 Batch  477/575   train_loss = 5.565
Epoch   3 Batch  478/575   train_loss = 5.622
Epoch   3 Batch  479/575   train_loss = 4.996
Epoch   3 Batch  480/575   train_loss = 5.267
Epoch   3 Batch  481/575   train_loss = 5.308
Epoch   3 Batch  482/575   train_loss = 4.586
Epoch   3 Batch  483/575   train_loss = 5.979
Epoch   3 Batch  484/575   train_loss = 5.064
Epoch   3 Batch  485/575   train_loss = 5.554
Epoch   3 Batch  486/575   train_loss = 5.191
Epoch   3 Batch  487/575   train_loss = 5.366
Epoch   3 Batch  488/575   train_loss = 5.086
Epoch   3 Batch  489/575   train_loss = 5.337
Epoch   3 Batch  490/575   train_loss = 5.366
Epoch   3 Batch  491/575   train_loss = 4.560
Epoch   3 Batch  492/575   train_loss = 4.396
Epoch   3 Batch  493/575   train_loss = 4.581
Epoch   3 Batch  494/575   train_loss = 4.811
Epoch   3 Batch  495/575   train_loss = 5.025
Epoch   3 Batch  496/575   train_loss = 5.153
Epoch   3 Batch  497/575   train_loss = 5.391
Epoch   3 Batch  498/575   train_loss = 4.824
Epoch   3 Batch  499/575   train_loss = 4.846
Epoch   3 Batch  500/575   train_loss = 5.091
Epoch   3 Batch  501/575   train_loss = 5.021
Epoch   3 Batch  502/575   train_loss = 4.416
Epoch   3 Batch  503/575   train_loss = 5.225
Epoch   3 Batch  504/575   train_loss = 4.604
Epoch   3 Batch  505/575   train_loss = 4.954
Epoch   3 Batch  506/575   train_loss = 5.329
Epoch   3 Batch  507/575   train_loss = 5.373
Epoch   3 Batch  508/575   train_loss = 5.282
Epoch   3 Batch  509/575   train_loss = 5.112
Epoch   3 Batch  510/575   train_loss = 4.486
Epoch   3 Batch  511/575   train_loss = 4.480
Epoch   3 Batch  512/575   train_loss = 5.473
Epoch   3 Batch  513/575   train_loss = 5.186
Epoch   3 Batch  514/575   train_loss = 5.008
Epoch   3 Batch  515/575   train_loss = 5.113
Epoch   3 Batch  516/575   train_loss = 5.394
Epoch   3 Batch  517/575   train_loss = 4.691
Epoch   3 Batch  518/575   train_loss = 4.843
Epoch   3 Batch  519/575   train_loss = 4.875
Epoch   3 Batch  520/575   train_loss = 4.182
Epoch   3 Batch  521/575   train_loss = 4.676
Epoch   3 Batch  522/575   train_loss = 4.748
Epoch   3 Batch  523/575   train_loss = 5.559
Epoch   3 Batch  524/575   train_loss = 6.546
Epoch   3 Batch  525/575   train_loss = 5.069
Epoch   3 Batch  526/575   train_loss = 4.802
Epoch   3 Batch  527/575   train_loss = 5.217
Epoch   3 Batch  528/575   train_loss = 4.815
Epoch   3 Batch  529/575   train_loss = 5.241
Epoch   3 Batch  530/575   train_loss = 5.146
Epoch   3 Batch  531/575   train_loss = 5.196
Epoch   3 Batch  532/575   train_loss = 4.831
Epoch   3 Batch  533/575   train_loss = 4.846
Epoch   3 Batch  534/575   train_loss = 4.850
Epoch   3 Batch  535/575   train_loss = 5.320
Epoch   3 Batch  536/575   train_loss = 5.067
Epoch   3 Batch  537/575   train_loss = 4.624
Epoch   3 Batch  538/575   train_loss = 5.007
Epoch   3 Batch  539/575   train_loss = 4.829
Epoch   3 Batch  540/575   train_loss = 5.134
Epoch   3 Batch  541/575   train_loss = 5.601
Epoch   3 Batch  542/575   train_loss = 5.098
Epoch   3 Batch  543/575   train_loss = 5.349
Epoch   3 Batch  544/575   train_loss = 5.062
Epoch   3 Batch  545/575   train_loss = 5.175
Epoch   3 Batch  546/575   train_loss = 5.147
Epoch   3 Batch  547/575   train_loss = 5.074
Epoch   3 Batch  548/575   train_loss = 5.175
Epoch   3 Batch  549/575   train_loss = 4.876
Epoch   3 Batch  550/575   train_loss = 4.899
Epoch   3 Batch  551/575   train_loss = 4.856
Epoch   3 Batch  552/575   train_loss = 5.067
Epoch   3 Batch  553/575   train_loss = 5.160
Epoch   3 Batch  554/575   train_loss = 4.829
Epoch   3 Batch  555/575   train_loss = 5.155
Epoch   3 Batch  556/575   train_loss = 4.789
Epoch   3 Batch  557/575   train_loss = 4.603
Epoch   3 Batch  558/575   train_loss = 5.011
Epoch   3 Batch  559/575   train_loss = 5.122
Epoch   3 Batch  560/575   train_loss = 4.541
Epoch   3 Batch  561/575   train_loss = 4.999
Epoch   3 Batch  562/575   train_loss = 4.517
Epoch   3 Batch  563/575   train_loss = 4.990
Epoch   3 Batch  564/575   train_loss = 4.611
Epoch   3 Batch  565/575   train_loss = 4.323
Epoch   3 Batch  566/575   train_loss = 4.717
Epoch   3 Batch  567/575   train_loss = 4.488
Epoch   3 Batch  568/575   train_loss = 4.695
Epoch   3 Batch  569/575   train_loss = 5.005
Epoch   3 Batch  570/575   train_loss = 4.607
Epoch   3 Batch  571/575   train_loss = 4.485
Epoch   3 Batch  572/575   train_loss = 4.131
Epoch   3 Batch  573/575   train_loss = 4.587
Epoch   3 Batch  574/575   train_loss = 5.200
Epoch   4 Batch    0/575   train_loss = 4.793
Epoch   4 Batch    1/575   train_loss = 4.778
Epoch   4 Batch    2/575   train_loss = 5.032
Epoch   4 Batch    3/575   train_loss = 4.715
Epoch   4 Batch    4/575   train_loss = 4.632
Epoch   4 Batch    5/575   train_loss = 4.636
Epoch   4 Batch    6/575   train_loss = 4.500
Epoch   4 Batch    7/575   train_loss = 4.812
Epoch   4 Batch    8/575   train_loss = 4.813
Epoch   4 Batch    9/575   train_loss = 4.991
Epoch   4 Batch   10/575   train_loss = 4.474
Epoch   4 Batch   11/575   train_loss = 4.652
Epoch   4 Batch   12/575   train_loss = 4.771
Epoch   4 Batch   13/575   train_loss = 5.009
Epoch   4 Batch   14/575   train_loss = 5.399
Epoch   4 Batch   15/575   train_loss = 5.122
Epoch   4 Batch   16/575   train_loss = 4.970
Epoch   4 Batch   17/575   train_loss = 4.271
Epoch   4 Batch   18/575   train_loss = 5.325
Epoch   4 Batch   19/575   train_loss = 4.925
Epoch   4 Batch   20/575   train_loss = 4.433
Epoch   4 Batch   21/575   train_loss = 4.660
Epoch   4 Batch   22/575   train_loss = 5.404
Epoch   4 Batch   23/575   train_loss = 4.922
Epoch   4 Batch   24/575   train_loss = 4.780
Epoch   4 Batch   25/575   train_loss = 4.956
Epoch   4 Batch   26/575   train_loss = 5.139
Epoch   4 Batch   27/575   train_loss = 4.985
Epoch   4 Batch   28/575   train_loss = 4.438
Epoch   4 Batch   29/575   train_loss = 4.598
Epoch   4 Batch   30/575   train_loss = 5.469
Epoch   4 Batch   31/575   train_loss = 5.719
Epoch   4 Batch   32/575   train_loss = 4.913
Epoch   4 Batch   33/575   train_loss = 5.248
Epoch   4 Batch   34/575   train_loss = 4.819
Epoch   4 Batch   35/575   train_loss = 4.724
Epoch   4 Batch   36/575   train_loss = 5.091
Epoch   4 Batch   37/575   train_loss = 4.271
Epoch   4 Batch   38/575   train_loss = 5.015
Epoch   4 Batch   39/575   train_loss = 4.348
Epoch   4 Batch   40/575   train_loss = 4.151
Epoch   4 Batch   41/575   train_loss = 6.115
Epoch   4 Batch   42/575   train_loss = 4.966
Epoch   4 Batch   43/575   train_loss = 4.934
Epoch   4 Batch   44/575   train_loss = 4.854
Epoch   4 Batch   45/575   train_loss = 4.693
Epoch   4 Batch   46/575   train_loss = 4.671
Epoch   4 Batch   47/575   train_loss = 5.037
Epoch   4 Batch   48/575   train_loss = 4.200
Epoch   4 Batch   49/575   train_loss = 4.461
Epoch   4 Batch   50/575   train_loss = 4.713
Epoch   4 Batch   51/575   train_loss = 4.580
Epoch   4 Batch   52/575   train_loss = 4.560
Epoch   4 Batch   53/575   train_loss = 4.329
Epoch   4 Batch   54/575   train_loss = 4.877
Epoch   4 Batch   55/575   train_loss = 5.164
Epoch   4 Batch   56/575   train_loss = 4.496
Epoch   4 Batch   57/575   train_loss = 4.855
Epoch   4 Batch   58/575   train_loss = 4.531
Epoch   4 Batch   59/575   train_loss = 4.273
Epoch   4 Batch   60/575   train_loss = 4.985
Epoch   4 Batch   61/575   train_loss = 4.893
Epoch   4 Batch   62/575   train_loss = 4.478
Epoch   4 Batch   63/575   train_loss = 5.265
Epoch   4 Batch   64/575   train_loss = 5.120
Epoch   4 Batch   65/575   train_loss = 4.611
Epoch   4 Batch   66/575   train_loss = 4.610
Epoch   4 Batch   67/575   train_loss = 4.465
Epoch   4 Batch   68/575   train_loss = 4.586
Epoch   4 Batch   69/575   train_loss = 4.256
Epoch   4 Batch   70/575   train_loss = 4.815
Epoch   4 Batch   71/575   train_loss = 4.537
Epoch   4 Batch   72/575   train_loss = 5.120
Epoch   4 Batch   73/575   train_loss = 5.124
Epoch   4 Batch   74/575   train_loss = 5.370
Epoch   4 Batch   75/575   train_loss = 4.923
Epoch   4 Batch   76/575   train_loss = 5.271
Epoch   4 Batch   77/575   train_loss = 5.331
Epoch   4 Batch   78/575   train_loss = 5.028
Epoch   4 Batch   79/575   train_loss = 4.881
Epoch   4 Batch   80/575   train_loss = 4.755
Epoch   4 Batch   81/575   train_loss = 4.708
Epoch   4 Batch   82/575   train_loss = 4.473
Epoch   4 Batch   83/575   train_loss = 4.697
Epoch   4 Batch   84/575   train_loss = 4.756
Epoch   4 Batch   85/575   train_loss = 5.484
Epoch   4 Batch   86/575   train_loss = 4.703
Epoch   4 Batch   87/575   train_loss = 5.342
Epoch   4 Batch   88/575   train_loss = 4.154
Epoch   4 Batch   89/575   train_loss = 4.398
Epoch   4 Batch   90/575   train_loss = 4.649
Epoch   4 Batch   91/575   train_loss = 4.890
Epoch   4 Batch   92/575   train_loss = 5.443
Epoch   4 Batch   93/575   train_loss = 4.995
Epoch   4 Batch   94/575   train_loss = 4.540
Epoch   4 Batch   95/575   train_loss = 4.933
Epoch   4 Batch   96/575   train_loss = 4.908
Epoch   4 Batch   97/575   train_loss = 5.000
Epoch   4 Batch   98/575   train_loss = 4.687
Epoch   4 Batch   99/575   train_loss = 5.398
Epoch   4 Batch  100/575   train_loss = 5.094
Epoch   4 Batch  101/575   train_loss = 4.673
Epoch   4 Batch  102/575   train_loss = 4.466
Epoch   4 Batch  103/575   train_loss = 5.127
Epoch   4 Batch  104/575   train_loss = 4.862
Epoch   4 Batch  105/575   train_loss = 5.036
Epoch   4 Batch  106/575   train_loss = 4.721
Epoch   4 Batch  107/575   train_loss = 4.549
Epoch   4 Batch  108/575   train_loss = 5.011
Epoch   4 Batch  109/575   train_loss = 4.752
Epoch   4 Batch  110/575   train_loss = 3.899
Epoch   4 Batch  111/575   train_loss = 4.737
Epoch   4 Batch  112/575   train_loss = 4.929
Epoch   4 Batch  113/575   train_loss = 5.488
Epoch   4 Batch  114/575   train_loss = 5.054
Epoch   4 Batch  115/575   train_loss = 4.567
Epoch   4 Batch  116/575   train_loss = 5.073
Epoch   4 Batch  117/575   train_loss = 4.409
Epoch   4 Batch  118/575   train_loss = 4.963
Epoch   4 Batch  119/575   train_loss = 5.476
Epoch   4 Batch  120/575   train_loss = 4.981
Epoch   4 Batch  121/575   train_loss = 5.090
Epoch   4 Batch  122/575   train_loss = 5.112
Epoch   4 Batch  123/575   train_loss = 4.867
Epoch   4 Batch  124/575   train_loss = 5.240
Epoch   4 Batch  125/575   train_loss = 5.074
Epoch   4 Batch  126/575   train_loss = 4.941
Epoch   4 Batch  127/575   train_loss = 4.350
Epoch   4 Batch  128/575   train_loss = 4.712
Epoch   4 Batch  129/575   train_loss = 4.746
Epoch   4 Batch  130/575   train_loss = 5.120
Epoch   4 Batch  131/575   train_loss = 4.289
Epoch   4 Batch  132/575   train_loss = 4.622
Epoch   4 Batch  133/575   train_loss = 4.868
Epoch   4 Batch  134/575   train_loss = 4.726
Epoch   4 Batch  135/575   train_loss = 4.393
Epoch   4 Batch  136/575   train_loss = 5.847
Epoch   4 Batch  137/575   train_loss = 4.909
Epoch   4 Batch  138/575   train_loss = 5.383
Epoch   4 Batch  139/575   train_loss = 5.102
Epoch   4 Batch  140/575   train_loss = 5.035
Epoch   4 Batch  141/575   train_loss = 5.377
Epoch   4 Batch  142/575   train_loss = 5.752
Epoch   4 Batch  143/575   train_loss = 5.024
Epoch   4 Batch  144/575   train_loss = 4.577
Epoch   4 Batch  145/575   train_loss = 4.611
Epoch   4 Batch  146/575   train_loss = 4.633
Epoch   4 Batch  147/575   train_loss = 4.681
Epoch   4 Batch  148/575   train_loss = 4.233
Epoch   4 Batch  149/575   train_loss = 4.952
Epoch   4 Batch  150/575   train_loss = 5.259
Epoch   4 Batch  151/575   train_loss = 4.552
Epoch   4 Batch  152/575   train_loss = 4.472
Epoch   4 Batch  153/575   train_loss = 3.996
Epoch   4 Batch  154/575   train_loss = 4.160
Epoch   4 Batch  155/575   train_loss = 4.935
Epoch   4 Batch  156/575   train_loss = 4.745
Epoch   4 Batch  157/575   train_loss = 4.921
Epoch   4 Batch  158/575   train_loss = 4.844
Epoch   4 Batch  159/575   train_loss = 5.073
Epoch   4 Batch  160/575   train_loss = 4.541
Epoch   4 Batch  161/575   train_loss = 5.263
Epoch   4 Batch  162/575   train_loss = 5.071
Epoch   4 Batch  163/575   train_loss = 4.742
Epoch   4 Batch  164/575   train_loss = 5.122
Epoch   4 Batch  165/575   train_loss = 5.010
Epoch   4 Batch  166/575   train_loss = 4.562
Epoch   4 Batch  167/575   train_loss = 4.600
Epoch   4 Batch  168/575   train_loss = 5.048
Epoch   4 Batch  169/575   train_loss = 4.617
Epoch   4 Batch  170/575   train_loss = 5.120
Epoch   4 Batch  171/575   train_loss = 4.697
Epoch   4 Batch  172/575   train_loss = 4.945
Epoch   4 Batch  173/575   train_loss = 4.911
Epoch   4 Batch  174/575   train_loss = 5.230
Epoch   4 Batch  175/575   train_loss = 4.967
Epoch   4 Batch  176/575   train_loss = 5.014
Epoch   4 Batch  177/575   train_loss = 5.168
Epoch   4 Batch  178/575   train_loss = 4.855
Epoch   4 Batch  179/575   train_loss = 4.622
Epoch   4 Batch  180/575   train_loss = 4.725
Epoch   4 Batch  181/575   train_loss = 4.971
Epoch   4 Batch  182/575   train_loss = 4.669
Epoch   4 Batch  183/575   train_loss = 5.078
Epoch   4 Batch  184/575   train_loss = 4.207
Epoch   4 Batch  185/575   train_loss = 4.725
Epoch   4 Batch  186/575   train_loss = 5.022
Epoch   4 Batch  187/575   train_loss = 4.746
Epoch   4 Batch  188/575   train_loss = 4.806
Epoch   4 Batch  189/575   train_loss = 4.698
Epoch   4 Batch  190/575   train_loss = 4.895
Epoch   4 Batch  191/575   train_loss = 5.353
Epoch   4 Batch  192/575   train_loss = 5.180
Epoch   4 Batch  193/575   train_loss = 4.835
Epoch   4 Batch  194/575   train_loss = 4.995
Epoch   4 Batch  195/575   train_loss = 4.594
Epoch   4 Batch  196/575   train_loss = 4.582
Epoch   4 Batch  197/575   train_loss = 4.531
Epoch   4 Batch  198/575   train_loss = 5.170
Epoch   4 Batch  199/575   train_loss = 4.283
Epoch   4 Batch  200/575   train_loss = 4.576
Epoch   4 Batch  201/575   train_loss = 4.851
Epoch   4 Batch  202/575   train_loss = 4.385
Epoch   4 Batch  203/575   train_loss = 4.686
Epoch   4 Batch  204/575   train_loss = 4.682
Epoch   4 Batch  205/575   train_loss = 4.405
Epoch   4 Batch  206/575   train_loss = 4.821
Epoch   4 Batch  207/575   train_loss = 4.545
Epoch   4 Batch  208/575   train_loss = 4.374
Epoch   4 Batch  209/575   train_loss = 4.466
Epoch   4 Batch  210/575   train_loss = 4.755
Epoch   4 Batch  211/575   train_loss = 5.484
Epoch   4 Batch  212/575   train_loss = 5.031
Epoch   4 Batch  213/575   train_loss = 4.920
Epoch   4 Batch  214/575   train_loss = 4.540
Epoch   4 Batch  215/575   train_loss = 4.004
Epoch   4 Batch  216/575   train_loss = 4.547
Epoch   4 Batch  217/575   train_loss = 4.268
Epoch   4 Batch  218/575   train_loss = 4.940
Epoch   4 Batch  219/575   train_loss = 4.647
Epoch   4 Batch  220/575   train_loss = 4.198
Epoch   4 Batch  221/575   train_loss = 4.885
Epoch   4 Batch  222/575   train_loss = 4.914
Epoch   4 Batch  223/575   train_loss = 5.143
Epoch   4 Batch  224/575   train_loss = 4.417
Epoch   4 Batch  225/575   train_loss = 4.622
Epoch   4 Batch  226/575   train_loss = 4.911
Epoch   4 Batch  227/575   train_loss = 5.222
Epoch   4 Batch  228/575   train_loss = 5.088
Epoch   4 Batch  229/575   train_loss = 3.972
Epoch   4 Batch  230/575   train_loss = 4.146
Epoch   4 Batch  231/575   train_loss = 4.724
Epoch   4 Batch  232/575   train_loss = 4.834
Epoch   4 Batch  233/575   train_loss = 4.915
Epoch   4 Batch  234/575   train_loss = 4.942
Epoch   4 Batch  235/575   train_loss = 4.530
Epoch   4 Batch  236/575   train_loss = 4.180
Epoch   4 Batch  237/575   train_loss = 4.481
Epoch   4 Batch  238/575   train_loss = 4.528
Epoch   4 Batch  239/575   train_loss = 4.868
Epoch   4 Batch  240/575   train_loss = 5.094
Epoch   4 Batch  241/575   train_loss = 5.178
Epoch   4 Batch  242/575   train_loss = 4.617
Epoch   4 Batch  243/575   train_loss = 4.816
Epoch   4 Batch  244/575   train_loss = 4.765
Epoch   4 Batch  245/575   train_loss = 4.892
Epoch   4 Batch  246/575   train_loss = 5.193
Epoch   4 Batch  247/575   train_loss = 4.601
Epoch   4 Batch  248/575   train_loss = 4.951
Epoch   4 Batch  249/575   train_loss = 4.835
Epoch   4 Batch  250/575   train_loss = 4.625
Epoch   4 Batch  251/575   train_loss = 4.892
Epoch   4 Batch  252/575   train_loss = 5.102
Epoch   4 Batch  253/575   train_loss = 4.776
Epoch   4 Batch  254/575   train_loss = 4.338
Epoch   4 Batch  255/575   train_loss = 5.026
Epoch   4 Batch  256/575   train_loss = 4.646
Epoch   4 Batch  257/575   train_loss = 4.813
Epoch   4 Batch  258/575   train_loss = 5.181
Epoch   4 Batch  259/575   train_loss = 4.363
Epoch   4 Batch  260/575   train_loss = 4.471
Epoch   4 Batch  261/575   train_loss = 5.407
Epoch   4 Batch  262/575   train_loss = 5.069
Epoch   4 Batch  263/575   train_loss = 4.863
Epoch   4 Batch  264/575   train_loss = 4.209
Epoch   4 Batch  265/575   train_loss = 4.038
Epoch   4 Batch  266/575   train_loss = 4.265
Epoch   4 Batch  267/575   train_loss = 4.735
Epoch   4 Batch  268/575   train_loss = 4.753
Epoch   4 Batch  269/575   train_loss = 4.888
Epoch   4 Batch  270/575   train_loss = 5.289
Epoch   4 Batch  271/575   train_loss = 4.442
Epoch   4 Batch  272/575   train_loss = 5.028
Epoch   4 Batch  273/575   train_loss = 4.969
Epoch   4 Batch  274/575   train_loss = 4.933
Epoch   4 Batch  275/575   train_loss = 4.858
Epoch   4 Batch  276/575   train_loss = 5.340
Epoch   4 Batch  277/575   train_loss = 4.016
Epoch   4 Batch  278/575   train_loss = 4.758
Epoch   4 Batch  279/575   train_loss = 4.866
Epoch   4 Batch  280/575   train_loss = 5.116
Epoch   4 Batch  281/575   train_loss = 4.582
Epoch   4 Batch  282/575   train_loss = 4.833
Epoch   4 Batch  283/575   train_loss = 5.091
Epoch   4 Batch  284/575   train_loss = 5.289
Epoch   4 Batch  285/575   train_loss = 4.587
Epoch   4 Batch  286/575   train_loss = 4.847
Epoch   4 Batch  287/575   train_loss = 5.054
Epoch   4 Batch  288/575   train_loss = 4.747
Epoch   4 Batch  289/575   train_loss = 4.790
Epoch   4 Batch  290/575   train_loss = 4.871
Epoch   4 Batch  291/575   train_loss = 5.475
Epoch   4 Batch  292/575   train_loss = 5.266
Epoch   4 Batch  293/575   train_loss = 5.502
Epoch   4 Batch  294/575   train_loss = 5.151
Epoch   4 Batch  295/575   train_loss = 4.717
Epoch   4 Batch  296/575   train_loss = 4.770
Epoch   4 Batch  297/575   train_loss = 4.909
Epoch   4 Batch  298/575   train_loss = 5.005
Epoch   4 Batch  299/575   train_loss = 4.926
Epoch   4 Batch  300/575   train_loss = 4.736
Epoch   4 Batch  301/575   train_loss = 4.628
Epoch   4 Batch  302/575   train_loss = 5.098
Epoch   4 Batch  303/575   train_loss = 4.480
Epoch   4 Batch  304/575   train_loss = 4.655
Epoch   4 Batch  305/575   train_loss = 4.664
Epoch   4 Batch  306/575   train_loss = 4.991
Epoch   4 Batch  307/575   train_loss = 5.043
Epoch   4 Batch  308/575   train_loss = 4.951
Epoch   4 Batch  309/575   train_loss = 5.208
Epoch   4 Batch  310/575   train_loss = 5.179
Epoch   4 Batch  311/575   train_loss = 4.473
Epoch   4 Batch  312/575   train_loss = 4.998
Epoch   4 Batch  313/575   train_loss = 5.344
Epoch   4 Batch  314/575   train_loss = 5.207
Epoch   4 Batch  315/575   train_loss = 5.428
Epoch   4 Batch  316/575   train_loss = 4.770
Epoch   4 Batch  317/575   train_loss = 4.404
Epoch   4 Batch  318/575   train_loss = 4.115
Epoch   4 Batch  319/575   train_loss = 4.833
Epoch   4 Batch  320/575   train_loss = 4.582
Epoch   4 Batch  321/575   train_loss = 5.268
Epoch   4 Batch  322/575   train_loss = 4.767
Epoch   4 Batch  323/575   train_loss = 5.209
Epoch   4 Batch  324/575   train_loss = 4.716
Epoch   4 Batch  325/575   train_loss = 4.901
Epoch   4 Batch  326/575   train_loss = 4.649
Epoch   4 Batch  327/575   train_loss = 5.047
Epoch   4 Batch  328/575   train_loss = 4.774
Epoch   4 Batch  329/575   train_loss = 5.261
Epoch   4 Batch  330/575   train_loss = 4.892
Epoch   4 Batch  331/575   train_loss = 5.430
Epoch   4 Batch  332/575   train_loss = 5.118
Epoch   4 Batch  333/575   train_loss = 5.018
Epoch   4 Batch  334/575   train_loss = 4.806
Epoch   4 Batch  335/575   train_loss = 4.585
Epoch   4 Batch  336/575   train_loss = 4.933
Epoch   4 Batch  337/575   train_loss = 4.853
Epoch   4 Batch  338/575   train_loss = 4.579
Epoch   4 Batch  339/575   train_loss = 4.910
Epoch   4 Batch  340/575   train_loss = 4.698
Epoch   4 Batch  341/575   train_loss = 4.662
Epoch   4 Batch  342/575   train_loss = 4.560
Epoch   4 Batch  343/575   train_loss = 4.981
Epoch   4 Batch  344/575   train_loss = 5.041
Epoch   4 Batch  345/575   train_loss = 4.664
Epoch   4 Batch  346/575   train_loss = 5.425
Epoch   4 Batch  347/575   train_loss = 4.553
Epoch   4 Batch  348/575   train_loss = 4.579
Epoch   4 Batch  349/575   train_loss = 4.347
Epoch   4 Batch  350/575   train_loss = 4.966
Epoch   4 Batch  351/575   train_loss = 5.329
Epoch   4 Batch  352/575   train_loss = 5.099
Epoch   4 Batch  353/575   train_loss = 5.052
Epoch   4 Batch  354/575   train_loss = 4.713
Epoch   4 Batch  355/575   train_loss = 5.269
Epoch   4 Batch  356/575   train_loss = 4.963
Epoch   4 Batch  357/575   train_loss = 4.864
Epoch   4 Batch  358/575   train_loss = 5.169
Epoch   4 Batch  359/575   train_loss = 5.397
Epoch   4 Batch  360/575   train_loss = 4.393
Epoch   4 Batch  361/575   train_loss = 5.062
Epoch   4 Batch  362/575   train_loss = 4.818
Epoch   4 Batch  363/575   train_loss = 4.852
Epoch   4 Batch  364/575   train_loss = 4.510
Epoch   4 Batch  365/575   train_loss = 4.984
Epoch   4 Batch  366/575   train_loss = 4.432
Epoch   4 Batch  367/575   train_loss = 4.798
Epoch   4 Batch  368/575   train_loss = 5.465
Epoch   4 Batch  369/575   train_loss = 5.150
Epoch   4 Batch  370/575   train_loss = 5.065
Epoch   4 Batch  371/575   train_loss = 5.182
Epoch   4 Batch  372/575   train_loss = 4.699
Epoch   4 Batch  373/575   train_loss = 5.114
Epoch   4 Batch  374/575   train_loss = 4.277
Epoch   4 Batch  375/575   train_loss = 4.624
Epoch   4 Batch  376/575   train_loss = 4.927
Epoch   4 Batch  377/575   train_loss = 5.302
Epoch   4 Batch  378/575   train_loss = 5.381
Epoch   4 Batch  379/575   train_loss = 4.697
Epoch   4 Batch  380/575   train_loss = 4.410
Epoch   4 Batch  381/575   train_loss = 4.670
Epoch   4 Batch  382/575   train_loss = 4.951
Epoch   4 Batch  383/575   train_loss = 4.718
Epoch   4 Batch  384/575   train_loss = 4.847
Epoch   4 Batch  385/575   train_loss = 4.623
Epoch   4 Batch  386/575   train_loss = 4.613
Epoch   4 Batch  387/575   train_loss = 5.326
Epoch   4 Batch  388/575   train_loss = 4.712
Epoch   4 Batch  389/575   train_loss = 4.714
Epoch   4 Batch  390/575   train_loss = 4.964
Epoch   4 Batch  391/575   train_loss = 5.038
Epoch   4 Batch  392/575   train_loss = 4.850
Epoch   4 Batch  393/575   train_loss = 4.869
Epoch   4 Batch  394/575   train_loss = 5.174
Epoch   4 Batch  395/575   train_loss = 4.253
Epoch   4 Batch  396/575   train_loss = 4.592
Epoch   4 Batch  397/575   train_loss = 5.015
Epoch   4 Batch  398/575   train_loss = 5.326
Epoch   4 Batch  399/575   train_loss = 5.288
Epoch   4 Batch  400/575   train_loss = 5.162
Epoch   4 Batch  401/575   train_loss = 4.482
Epoch   4 Batch  402/575   train_loss = 4.601
Epoch   4 Batch  403/575   train_loss = 5.035
Epoch   4 Batch  404/575   train_loss = 5.104
Epoch   4 Batch  405/575   train_loss = 5.135
Epoch   4 Batch  406/575   train_loss = 4.563
Epoch   4 Batch  407/575   train_loss = 4.927
Epoch   4 Batch  408/575   train_loss = 4.855
Epoch   4 Batch  409/575   train_loss = 4.797
Epoch   4 Batch  410/575   train_loss = 4.628
Epoch   4 Batch  411/575   train_loss = 4.856
Epoch   4 Batch  412/575   train_loss = 5.479
Epoch   4 Batch  413/575   train_loss = 5.109
Epoch   4 Batch  414/575   train_loss = 4.805
Epoch   4 Batch  415/575   train_loss = 5.334
Epoch   4 Batch  416/575   train_loss = 4.769
Epoch   4 Batch  417/575   train_loss = 4.423
Epoch   4 Batch  418/575   train_loss = 4.873
Epoch   4 Batch  419/575   train_loss = 4.785
Epoch   4 Batch  420/575   train_loss = 4.658
Epoch   4 Batch  421/575   train_loss = 5.347
Epoch   4 Batch  422/575   train_loss = 5.034
Epoch   4 Batch  423/575   train_loss = 5.426
Epoch   4 Batch  424/575   train_loss = 5.458
Epoch   4 Batch  425/575   train_loss = 5.162
Epoch   4 Batch  426/575   train_loss = 4.996
Epoch   4 Batch  427/575   train_loss = 4.828
Epoch   4 Batch  428/575   train_loss = 4.830
Epoch   4 Batch  429/575   train_loss = 4.576
Epoch   4 Batch  430/575   train_loss = 4.921
Epoch   4 Batch  431/575   train_loss = 4.826
Epoch   4 Batch  432/575   train_loss = 5.273
Epoch   4 Batch  433/575   train_loss = 5.211
Epoch   4 Batch  434/575   train_loss = 5.047
Epoch   4 Batch  435/575   train_loss = 4.885
Epoch   4 Batch  436/575   train_loss = 4.601
Epoch   4 Batch  437/575   train_loss = 4.855
Epoch   4 Batch  438/575   train_loss = 5.093
Epoch   4 Batch  439/575   train_loss = 4.923
Epoch   4 Batch  440/575   train_loss = 5.147
Epoch   4 Batch  441/575   train_loss = 4.890
Epoch   4 Batch  442/575   train_loss = 5.040
Epoch   4 Batch  443/575   train_loss = 5.004
Epoch   4 Batch  444/575   train_loss = 5.075
Epoch   4 Batch  445/575   train_loss = 4.660
Epoch   4 Batch  446/575   train_loss = 4.583
Epoch   4 Batch  447/575   train_loss = 5.115
Epoch   4 Batch  448/575   train_loss = 4.928
Epoch   4 Batch  449/575   train_loss = 4.956
Epoch   4 Batch  450/575   train_loss = 5.529
Epoch   4 Batch  451/575   train_loss = 5.423
Epoch   4 Batch  452/575   train_loss = 5.502
Epoch   4 Batch  453/575   train_loss = 4.989
Epoch   4 Batch  454/575   train_loss = 5.354
Epoch   4 Batch  455/575   train_loss = 4.641
Epoch   4 Batch  456/575   train_loss = 5.362
Epoch   4 Batch  457/575   train_loss = 4.539
Epoch   4 Batch  458/575   train_loss = 5.262
Epoch   4 Batch  459/575   train_loss = 5.048
Epoch   4 Batch  460/575   train_loss = 4.803
Epoch   4 Batch  461/575   train_loss = 4.998
Epoch   4 Batch  462/575   train_loss = 4.856
Epoch   4 Batch  463/575   train_loss = 4.781
Epoch   4 Batch  464/575   train_loss = 4.643
Epoch   4 Batch  465/575   train_loss = 4.778
Epoch   4 Batch  466/575   train_loss = 4.782
Epoch   4 Batch  467/575   train_loss = 4.254
Epoch   4 Batch  468/575   train_loss = 4.719
Epoch   4 Batch  469/575   train_loss = 5.236
Epoch   4 Batch  470/575   train_loss = 5.478
Epoch   4 Batch  471/575   train_loss = 4.716
Epoch   4 Batch  472/575   train_loss = 5.156
Epoch   4 Batch  473/575   train_loss = 4.987
Epoch   4 Batch  474/575   train_loss = 4.985
Epoch   4 Batch  475/575   train_loss = 4.707
Epoch   4 Batch  476/575   train_loss = 4.867
Epoch   4 Batch  477/575   train_loss = 5.416
Epoch   4 Batch  478/575   train_loss = 5.484
Epoch   4 Batch  479/575   train_loss = 4.809
Epoch   4 Batch  480/575   train_loss = 5.103
Epoch   4 Batch  481/575   train_loss = 5.157
Epoch   4 Batch  482/575   train_loss = 4.439
Epoch   4 Batch  483/575   train_loss = 5.785
Epoch   4 Batch  484/575   train_loss = 4.906
Epoch   4 Batch  485/575   train_loss = 5.447
Epoch   4 Batch  486/575   train_loss = 4.993
Epoch   4 Batch  487/575   train_loss = 5.225
Epoch   4 Batch  488/575   train_loss = 4.934
Epoch   4 Batch  489/575   train_loss = 5.182
Epoch   4 Batch  490/575   train_loss = 5.184
Epoch   4 Batch  491/575   train_loss = 4.414
Epoch   4 Batch  492/575   train_loss = 4.293
Epoch   4 Batch  493/575   train_loss = 4.441
Epoch   4 Batch  494/575   train_loss = 4.700
Epoch   4 Batch  495/575   train_loss = 4.862
Epoch   4 Batch  496/575   train_loss = 5.001
Epoch   4 Batch  497/575   train_loss = 5.204
Epoch   4 Batch  498/575   train_loss = 4.722
Epoch   4 Batch  499/575   train_loss = 4.695
Epoch   4 Batch  500/575   train_loss = 4.978
Epoch   4 Batch  501/575   train_loss = 4.905
Epoch   4 Batch  502/575   train_loss = 4.288
Epoch   4 Batch  503/575   train_loss = 5.099
Epoch   4 Batch  504/575   train_loss = 4.429
Epoch   4 Batch  505/575   train_loss = 4.797
Epoch   4 Batch  506/575   train_loss = 5.173
Epoch   4 Batch  507/575   train_loss = 5.218
Epoch   4 Batch  508/575   train_loss = 5.175
Epoch   4 Batch  509/575   train_loss = 4.933
Epoch   4 Batch  510/575   train_loss = 4.312
Epoch   4 Batch  511/575   train_loss = 4.355
Epoch   4 Batch  512/575   train_loss = 5.292
Epoch   4 Batch  513/575   train_loss = 5.019
Epoch   4 Batch  514/575   train_loss = 4.827
Epoch   4 Batch  515/575   train_loss = 4.946
Epoch   4 Batch  516/575   train_loss = 5.247
Epoch   4 Batch  517/575   train_loss = 4.505
Epoch   4 Batch  518/575   train_loss = 4.631
Epoch   4 Batch  519/575   train_loss = 4.760
Epoch   4 Batch  520/575   train_loss = 4.079
Epoch   4 Batch  521/575   train_loss = 4.511
Epoch   4 Batch  522/575   train_loss = 4.614
Epoch   4 Batch  523/575   train_loss = 5.364
Epoch   4 Batch  524/575   train_loss = 6.247
Epoch   4 Batch  525/575   train_loss = 4.954
Epoch   4 Batch  526/575   train_loss = 4.642
Epoch   4 Batch  527/575   train_loss = 5.113
Epoch   4 Batch  528/575   train_loss = 4.666
Epoch   4 Batch  529/575   train_loss = 5.150
Epoch   4 Batch  530/575   train_loss = 4.983
Epoch   4 Batch  531/575   train_loss = 5.058
Epoch   4 Batch  532/575   train_loss = 4.682
Epoch   4 Batch  533/575   train_loss = 4.672
Epoch   4 Batch  534/575   train_loss = 4.701
Epoch   4 Batch  535/575   train_loss = 5.087
Epoch   4 Batch  536/575   train_loss = 4.820
Epoch   4 Batch  537/575   train_loss = 4.497
Epoch   4 Batch  538/575   train_loss = 4.856
Epoch   4 Batch  539/575   train_loss = 4.697
Epoch   4 Batch  540/575   train_loss = 4.963
Epoch   4 Batch  541/575   train_loss = 5.448
Epoch   4 Batch  542/575   train_loss = 4.919
Epoch   4 Batch  543/575   train_loss = 5.126
Epoch   4 Batch  544/575   train_loss = 4.879
Epoch   4 Batch  545/575   train_loss = 4.953
Epoch   4 Batch  546/575   train_loss = 4.942
Epoch   4 Batch  547/575   train_loss = 4.919
Epoch   4 Batch  548/575   train_loss = 5.001
Epoch   4 Batch  549/575   train_loss = 4.747
Epoch   4 Batch  550/575   train_loss = 4.719
Epoch   4 Batch  551/575   train_loss = 4.688
Epoch   4 Batch  552/575   train_loss = 4.897
Epoch   4 Batch  553/575   train_loss = 5.034
Epoch   4 Batch  554/575   train_loss = 4.644
Epoch   4 Batch  555/575   train_loss = 4.935
Epoch   4 Batch  556/575   train_loss = 4.608
Epoch   4 Batch  557/575   train_loss = 4.488
Epoch   4 Batch  558/575   train_loss = 4.863
Epoch   4 Batch  559/575   train_loss = 4.990
Epoch   4 Batch  560/575   train_loss = 4.396
Epoch   4 Batch  561/575   train_loss = 4.836
Epoch   4 Batch  562/575   train_loss = 4.351
Epoch   4 Batch  563/575   train_loss = 4.827
Epoch   4 Batch  564/575   train_loss = 4.495
Epoch   4 Batch  565/575   train_loss = 4.101
Epoch   4 Batch  566/575   train_loss = 4.538
Epoch   4 Batch  567/575   train_loss = 4.386
Epoch   4 Batch  568/575   train_loss = 4.555
Epoch   4 Batch  569/575   train_loss = 4.890
Epoch   4 Batch  570/575   train_loss = 4.451
Epoch   4 Batch  571/575   train_loss = 4.327
Epoch   4 Batch  572/575   train_loss = 4.007
Epoch   4 Batch  573/575   train_loss = 4.431
Epoch   4 Batch  574/575   train_loss = 5.044
Epoch   5 Batch    0/575   train_loss = 4.653
Epoch   5 Batch    1/575   train_loss = 4.633
Epoch   5 Batch    2/575   train_loss = 4.873
Epoch   5 Batch    3/575   train_loss = 4.602
Epoch   5 Batch    4/575   train_loss = 4.518
Epoch   5 Batch    5/575   train_loss = 4.474
Epoch   5 Batch    6/575   train_loss = 4.376
Epoch   5 Batch    7/575   train_loss = 4.685
Epoch   5 Batch    8/575   train_loss = 4.684
Epoch   5 Batch    9/575   train_loss = 4.861
Epoch   5 Batch   10/575   train_loss = 4.349
Epoch   5 Batch   11/575   train_loss = 4.514
Epoch   5 Batch   12/575   train_loss = 4.643
Epoch   5 Batch   13/575   train_loss = 4.830
Epoch   5 Batch   14/575   train_loss = 5.281
Epoch   5 Batch   15/575   train_loss = 4.986
Epoch   5 Batch   16/575   train_loss = 4.790
Epoch   5 Batch   17/575   train_loss = 4.161
Epoch   5 Batch   18/575   train_loss = 5.133
Epoch   5 Batch   19/575   train_loss = 4.781
Epoch   5 Batch   20/575   train_loss = 4.244
Epoch   5 Batch   21/575   train_loss = 4.582
Epoch   5 Batch   22/575   train_loss = 5.252
Epoch   5 Batch   23/575   train_loss = 4.766
Epoch   5 Batch   24/575   train_loss = 4.662
Epoch   5 Batch   25/575   train_loss = 4.822
Epoch   5 Batch   26/575   train_loss = 5.014
Epoch   5 Batch   27/575   train_loss = 4.799
Epoch   5 Batch   28/575   train_loss = 4.303
Epoch   5 Batch   29/575   train_loss = 4.487
Epoch   5 Batch   30/575   train_loss = 5.261
Epoch   5 Batch   31/575   train_loss = 5.547
Epoch   5 Batch   32/575   train_loss = 4.810
Epoch   5 Batch   33/575   train_loss = 5.101
Epoch   5 Batch   34/575   train_loss = 4.686
Epoch   5 Batch   35/575   train_loss = 4.574
Epoch   5 Batch   36/575   train_loss = 4.978
Epoch   5 Batch   37/575   train_loss = 4.108
Epoch   5 Batch   38/575   train_loss = 4.859
Epoch   5 Batch   39/575   train_loss = 4.204
Epoch   5 Batch   40/575   train_loss = 4.013
Epoch   5 Batch   41/575   train_loss = 5.959
Epoch   5 Batch   42/575   train_loss = 4.837
Epoch   5 Batch   43/575   train_loss = 4.780
Epoch   5 Batch   44/575   train_loss = 4.704
Epoch   5 Batch   45/575   train_loss = 4.529
Epoch   5 Batch   46/575   train_loss = 4.524
Epoch   5 Batch   47/575   train_loss = 4.927
Epoch   5 Batch   48/575   train_loss = 4.078
Epoch   5 Batch   49/575   train_loss = 4.356
Epoch   5 Batch   50/575   train_loss = 4.583
Epoch   5 Batch   51/575   train_loss = 4.458
Epoch   5 Batch   52/575   train_loss = 4.448
Epoch   5 Batch   53/575   train_loss = 4.204
Epoch   5 Batch   54/575   train_loss = 4.710
Epoch   5 Batch   55/575   train_loss = 5.017
Epoch   5 Batch   56/575   train_loss = 4.368
Epoch   5 Batch   57/575   train_loss = 4.716
Epoch   5 Batch   58/575   train_loss = 4.372
Epoch   5 Batch   59/575   train_loss = 4.171
Epoch   5 Batch   60/575   train_loss = 4.843
Epoch   5 Batch   61/575   train_loss = 4.801
Epoch   5 Batch   62/575   train_loss = 4.315
Epoch   5 Batch   63/575   train_loss = 5.109
Epoch   5 Batch   64/575   train_loss = 4.996
Epoch   5 Batch   65/575   train_loss = 4.507
Epoch   5 Batch   66/575   train_loss = 4.466
Epoch   5 Batch   67/575   train_loss = 4.372
Epoch   5 Batch   68/575   train_loss = 4.453
Epoch   5 Batch   69/575   train_loss = 4.155
Epoch   5 Batch   70/575   train_loss = 4.653
Epoch   5 Batch   71/575   train_loss = 4.405
Epoch   5 Batch   72/575   train_loss = 5.007
Epoch   5 Batch   73/575   train_loss = 5.022
Epoch   5 Batch   74/575   train_loss = 5.201
Epoch   5 Batch   75/575   train_loss = 4.793
Epoch   5 Batch   76/575   train_loss = 5.113
Epoch   5 Batch   77/575   train_loss = 5.165
Epoch   5 Batch   78/575   train_loss = 4.888
Epoch   5 Batch   79/575   train_loss = 4.701
Epoch   5 Batch   80/575   train_loss = 4.629
Epoch   5 Batch   81/575   train_loss = 4.553
Epoch   5 Batch   82/575   train_loss = 4.312
Epoch   5 Batch   83/575   train_loss = 4.586
Epoch   5 Batch   84/575   train_loss = 4.603
Epoch   5 Batch   85/575   train_loss = 5.327
Epoch   5 Batch   86/575   train_loss = 4.581
Epoch   5 Batch   87/575   train_loss = 5.199
Epoch   5 Batch   88/575   train_loss = 4.022
Epoch   5 Batch   89/575   train_loss = 4.252
Epoch   5 Batch   90/575   train_loss = 4.470
Epoch   5 Batch   91/575   train_loss = 4.740
Epoch   5 Batch   92/575   train_loss = 5.264
Epoch   5 Batch   93/575   train_loss = 4.838
Epoch   5 Batch   94/575   train_loss = 4.364
Epoch   5 Batch   95/575   train_loss = 4.761
Epoch   5 Batch   96/575   train_loss = 4.759
Epoch   5 Batch   97/575   train_loss = 4.857
Epoch   5 Batch   98/575   train_loss = 4.567
Epoch   5 Batch   99/575   train_loss = 5.219
Epoch   5 Batch  100/575   train_loss = 4.940
Epoch   5 Batch  101/575   train_loss = 4.541
Epoch   5 Batch  102/575   train_loss = 4.329
Epoch   5 Batch  103/575   train_loss = 4.950
Epoch   5 Batch  104/575   train_loss = 4.689
Epoch   5 Batch  105/575   train_loss = 4.865
Epoch   5 Batch  106/575   train_loss = 4.558
Epoch   5 Batch  107/575   train_loss = 4.411
Epoch   5 Batch  108/575   train_loss = 4.857
Epoch   5 Batch  109/575   train_loss = 4.588
Epoch   5 Batch  110/575   train_loss = 3.752
Epoch   5 Batch  111/575   train_loss = 4.621
Epoch   5 Batch  112/575   train_loss = 4.796
Epoch   5 Batch  113/575   train_loss = 5.334
Epoch   5 Batch  114/575   train_loss = 4.954
Epoch   5 Batch  115/575   train_loss = 4.479
Epoch   5 Batch  116/575   train_loss = 4.942
Epoch   5 Batch  117/575   train_loss = 4.284
Epoch   5 Batch  118/575   train_loss = 4.797
Epoch   5 Batch  119/575   train_loss = 5.312
Epoch   5 Batch  120/575   train_loss = 4.823
Epoch   5 Batch  121/575   train_loss = 4.930
Epoch   5 Batch  122/575   train_loss = 4.933
Epoch   5 Batch  123/575   train_loss = 4.690
Epoch   5 Batch  124/575   train_loss = 5.124
Epoch   5 Batch  125/575   train_loss = 4.906
Epoch   5 Batch  126/575   train_loss = 4.779
Epoch   5 Batch  127/575   train_loss = 4.222
Epoch   5 Batch  128/575   train_loss = 4.630
Epoch   5 Batch  129/575   train_loss = 4.622
Epoch   5 Batch  130/575   train_loss = 4.966
Epoch   5 Batch  131/575   train_loss = 4.143
Epoch   5 Batch  132/575   train_loss = 4.515
Epoch   5 Batch  133/575   train_loss = 4.735
Epoch   5 Batch  134/575   train_loss = 4.580
Epoch   5 Batch  135/575   train_loss = 4.269
Epoch   5 Batch  136/575   train_loss = 5.671
Epoch   5 Batch  137/575   train_loss = 4.813
Epoch   5 Batch  138/575   train_loss = 5.227
Epoch   5 Batch  139/575   train_loss = 4.935
Epoch   5 Batch  140/575   train_loss = 4.870
Epoch   5 Batch  141/575   train_loss = 5.203
Epoch   5 Batch  142/575   train_loss = 5.500
Epoch   5 Batch  143/575   train_loss = 4.902
Epoch   5 Batch  144/575   train_loss = 4.452
Epoch   5 Batch  145/575   train_loss = 4.466
Epoch   5 Batch  146/575   train_loss = 4.464
Epoch   5 Batch  147/575   train_loss = 4.582
Epoch   5 Batch  148/575   train_loss = 4.106
Epoch   5 Batch  149/575   train_loss = 4.795
Epoch   5 Batch  150/575   train_loss = 5.096
Epoch   5 Batch  151/575   train_loss = 4.370
Epoch   5 Batch  152/575   train_loss = 4.315
Epoch   5 Batch  153/575   train_loss = 3.876
Epoch   5 Batch  154/575   train_loss = 4.037
Epoch   5 Batch  155/575   train_loss = 4.799
Epoch   5 Batch  156/575   train_loss = 4.608
Epoch   5 Batch  157/575   train_loss = 4.784
Epoch   5 Batch  158/575   train_loss = 4.700
Epoch   5 Batch  159/575   train_loss = 4.899
Epoch   5 Batch  160/575   train_loss = 4.416
Epoch   5 Batch  161/575   train_loss = 5.076
Epoch   5 Batch  162/575   train_loss = 4.905
Epoch   5 Batch  163/575   train_loss = 4.636
Epoch   5 Batch  164/575   train_loss = 4.974
Epoch   5 Batch  165/575   train_loss = 4.836
Epoch   5 Batch  166/575   train_loss = 4.407
Epoch   5 Batch  167/575   train_loss = 4.467
Epoch   5 Batch  168/575   train_loss = 4.884
Epoch   5 Batch  169/575   train_loss = 4.477
Epoch   5 Batch  170/575   train_loss = 4.973
Epoch   5 Batch  171/575   train_loss = 4.527
Epoch   5 Batch  172/575   train_loss = 4.803
Epoch   5 Batch  173/575   train_loss = 4.775
Epoch   5 Batch  174/575   train_loss = 5.056
Epoch   5 Batch  175/575   train_loss = 4.782
Epoch   5 Batch  176/575   train_loss = 4.850
Epoch   5 Batch  177/575   train_loss = 4.951
Epoch   5 Batch  178/575   train_loss = 4.696
Epoch   5 Batch  179/575   train_loss = 4.460
Epoch   5 Batch  180/575   train_loss = 4.550
Epoch   5 Batch  181/575   train_loss = 4.781
Epoch   5 Batch  182/575   train_loss = 4.545
Epoch   5 Batch  183/575   train_loss = 4.944
Epoch   5 Batch  184/575   train_loss = 4.056
Epoch   5 Batch  185/575   train_loss = 4.594
Epoch   5 Batch  186/575   train_loss = 4.863
Epoch   5 Batch  187/575   train_loss = 4.641
Epoch   5 Batch  188/575   train_loss = 4.651
Epoch   5 Batch  189/575   train_loss = 4.581
Epoch   5 Batch  190/575   train_loss = 4.721
Epoch   5 Batch  191/575   train_loss = 5.185
Epoch   5 Batch  192/575   train_loss = 5.012
Epoch   5 Batch  193/575   train_loss = 4.693
Epoch   5 Batch  194/575   train_loss = 4.837
Epoch   5 Batch  195/575   train_loss = 4.447
Epoch   5 Batch  196/575   train_loss = 4.468
Epoch   5 Batch  197/575   train_loss = 4.421
Epoch   5 Batch  198/575   train_loss = 4.999
Epoch   5 Batch  199/575   train_loss = 4.156
Epoch   5 Batch  200/575   train_loss = 4.448
Epoch   5 Batch  201/575   train_loss = 4.726
Epoch   5 Batch  202/575   train_loss = 4.308
Epoch   5 Batch  203/575   train_loss = 4.567
Epoch   5 Batch  204/575   train_loss = 4.544
Epoch   5 Batch  205/575   train_loss = 4.263
Epoch   5 Batch  206/575   train_loss = 4.664
Epoch   5 Batch  207/575   train_loss = 4.436
Epoch   5 Batch  208/575   train_loss = 4.251
Epoch   5 Batch  209/575   train_loss = 4.342
Epoch   5 Batch  210/575   train_loss = 4.673
Epoch   5 Batch  211/575   train_loss = 5.318
Epoch   5 Batch  212/575   train_loss = 4.905
Epoch   5 Batch  213/575   train_loss = 4.748
Epoch   5 Batch  214/575   train_loss = 4.385
Epoch   5 Batch  215/575   train_loss = 3.927
Epoch   5 Batch  216/575   train_loss = 4.394
Epoch   5 Batch  217/575   train_loss = 4.119
Epoch   5 Batch  218/575   train_loss = 4.806
Epoch   5 Batch  219/575   train_loss = 4.486
Epoch   5 Batch  220/575   train_loss = 4.079
Epoch   5 Batch  221/575   train_loss = 4.702
Epoch   5 Batch  222/575   train_loss = 4.743
Epoch   5 Batch  223/575   train_loss = 4.993
Epoch   5 Batch  224/575   train_loss = 4.284
Epoch   5 Batch  225/575   train_loss = 4.447
Epoch   5 Batch  226/575   train_loss = 4.754
Epoch   5 Batch  227/575   train_loss = 5.088
Epoch   5 Batch  228/575   train_loss = 4.929
Epoch   5 Batch  229/575   train_loss = 3.880
Epoch   5 Batch  230/575   train_loss = 4.054
Epoch   5 Batch  231/575   train_loss = 4.582
Epoch   5 Batch  232/575   train_loss = 4.717
Epoch   5 Batch  233/575   train_loss = 4.738
Epoch   5 Batch  234/575   train_loss = 4.795
Epoch   5 Batch  235/575   train_loss = 4.420
Epoch   5 Batch  236/575   train_loss = 4.045
Epoch   5 Batch  237/575   train_loss = 4.360
Epoch   5 Batch  238/575   train_loss = 4.403
Epoch   5 Batch  239/575   train_loss = 4.687
Epoch   5 Batch  240/575   train_loss = 4.950
Epoch   5 Batch  241/575   train_loss = 5.015
Epoch   5 Batch  242/575   train_loss = 4.499
Epoch   5 Batch  243/575   train_loss = 4.677
Epoch   5 Batch  244/575   train_loss = 4.589
Epoch   5 Batch  245/575   train_loss = 4.760
Epoch   5 Batch  246/575   train_loss = 5.001
Epoch   5 Batch  247/575   train_loss = 4.503
Epoch   5 Batch  248/575   train_loss = 4.790
Epoch   5 Batch  249/575   train_loss = 4.685
Epoch   5 Batch  250/575   train_loss = 4.495
Epoch   5 Batch  251/575   train_loss = 4.729
Epoch   5 Batch  252/575   train_loss = 4.949
Epoch   5 Batch  253/575   train_loss = 4.626
Epoch   5 Batch  254/575   train_loss = 4.205
Epoch   5 Batch  255/575   train_loss = 4.874
Epoch   5 Batch  256/575   train_loss = 4.512
Epoch   5 Batch  257/575   train_loss = 4.672
Epoch   5 Batch  258/575   train_loss = 5.039
Epoch   5 Batch  259/575   train_loss = 4.204
Epoch   5 Batch  260/575   train_loss = 4.364
Epoch   5 Batch  261/575   train_loss = 5.211
Epoch   5 Batch  262/575   train_loss = 4.895
Epoch   5 Batch  263/575   train_loss = 4.777
Epoch   5 Batch  264/575   train_loss = 4.046
Epoch   5 Batch  265/575   train_loss = 3.943
Epoch   5 Batch  266/575   train_loss = 4.111
Epoch   5 Batch  267/575   train_loss = 4.574
Epoch   5 Batch  268/575   train_loss = 4.613
Epoch   5 Batch  269/575   train_loss = 4.774
Epoch   5 Batch  270/575   train_loss = 5.151
Epoch   5 Batch  271/575   train_loss = 4.320
Epoch   5 Batch  272/575   train_loss = 4.855
Epoch   5 Batch  273/575   train_loss = 4.836
Epoch   5 Batch  274/575   train_loss = 4.803
Epoch   5 Batch  275/575   train_loss = 4.661
Epoch   5 Batch  276/575   train_loss = 5.195
Epoch   5 Batch  277/575   train_loss = 3.914
Epoch   5 Batch  278/575   train_loss = 4.677
Epoch   5 Batch  279/575   train_loss = 4.782
Epoch   5 Batch  280/575   train_loss = 4.973
Epoch   5 Batch  281/575   train_loss = 4.459
Epoch   5 Batch  282/575   train_loss = 4.717
Epoch   5 Batch  283/575   train_loss = 4.962
Epoch   5 Batch  284/575   train_loss = 5.159
Epoch   5 Batch  285/575   train_loss = 4.437
Epoch   5 Batch  286/575   train_loss = 4.717
Epoch   5 Batch  287/575   train_loss = 4.898
Epoch   5 Batch  288/575   train_loss = 4.618
Epoch   5 Batch  289/575   train_loss = 4.646
Epoch   5 Batch  290/575   train_loss = 4.731
Epoch   5 Batch  291/575   train_loss = 5.306
Epoch   5 Batch  292/575   train_loss = 5.196
Epoch   5 Batch  293/575   train_loss = 5.387
Epoch   5 Batch  294/575   train_loss = 5.015
Epoch   5 Batch  295/575   train_loss = 4.571
Epoch   5 Batch  296/575   train_loss = 4.675
Epoch   5 Batch  297/575   train_loss = 4.767
Epoch   5 Batch  298/575   train_loss = 4.871
Epoch   5 Batch  299/575   train_loss = 4.790
Epoch   5 Batch  300/575   train_loss = 4.632
Epoch   5 Batch  301/575   train_loss = 4.506
Epoch   5 Batch  302/575   train_loss = 4.953
Epoch   5 Batch  303/575   train_loss = 4.364
Epoch   5 Batch  304/575   train_loss = 4.520
Epoch   5 Batch  305/575   train_loss = 4.518
Epoch   5 Batch  306/575   train_loss = 4.827
Epoch   5 Batch  307/575   train_loss = 4.878
Epoch   5 Batch  308/575   train_loss = 4.792
Epoch   5 Batch  309/575   train_loss = 5.034
Epoch   5 Batch  310/575   train_loss = 5.060
Epoch   5 Batch  311/575   train_loss = 4.353
Epoch   5 Batch  312/575   train_loss = 4.817
Epoch   5 Batch  313/575   train_loss = 5.159
Epoch   5 Batch  314/575   train_loss = 5.075
Epoch   5 Batch  315/575   train_loss = 5.256
Epoch   5 Batch  316/575   train_loss = 4.608
Epoch   5 Batch  317/575   train_loss = 4.269
Epoch   5 Batch  318/575   train_loss = 3.976
Epoch   5 Batch  319/575   train_loss = 4.692
Epoch   5 Batch  320/575   train_loss = 4.487
Epoch   5 Batch  321/575   train_loss = 5.078
Epoch   5 Batch  322/575   train_loss = 4.622
Epoch   5 Batch  323/575   train_loss = 5.087
Epoch   5 Batch  324/575   train_loss = 4.590
Epoch   5 Batch  325/575   train_loss = 4.758
Epoch   5 Batch  326/575   train_loss = 4.511
Epoch   5 Batch  327/575   train_loss = 4.904
Epoch   5 Batch  328/575   train_loss = 4.575
Epoch   5 Batch  329/575   train_loss = 5.154
Epoch   5 Batch  330/575   train_loss = 4.745
Epoch   5 Batch  331/575   train_loss = 5.272
Epoch   5 Batch  332/575   train_loss = 4.940
Epoch   5 Batch  333/575   train_loss = 4.839
Epoch   5 Batch  334/575   train_loss = 4.661
Epoch   5 Batch  335/575   train_loss = 4.417
Epoch   5 Batch  336/575   train_loss = 4.786
Epoch   5 Batch  337/575   train_loss = 4.691
Epoch   5 Batch  338/575   train_loss = 4.465
Epoch   5 Batch  339/575   train_loss = 4.772
Epoch   5 Batch  340/575   train_loss = 4.578
Epoch   5 Batch  341/575   train_loss = 4.568
Epoch   5 Batch  342/575   train_loss = 4.420
Epoch   5 Batch  343/575   train_loss = 4.876
Epoch   5 Batch  344/575   train_loss = 4.912
Epoch   5 Batch  345/575   train_loss = 4.538
Epoch   5 Batch  346/575   train_loss = 5.279
Epoch   5 Batch  347/575   train_loss = 4.396
Epoch   5 Batch  348/575   train_loss = 4.429
Epoch   5 Batch  349/575   train_loss = 4.217
Epoch   5 Batch  350/575   train_loss = 4.833
Epoch   5 Batch  351/575   train_loss = 5.181
Epoch   5 Batch  352/575   train_loss = 4.992
Epoch   5 Batch  353/575   train_loss = 4.911
Epoch   5 Batch  354/575   train_loss = 4.553
Epoch   5 Batch  355/575   train_loss = 5.141
Epoch   5 Batch  356/575   train_loss = 4.855
Epoch   5 Batch  357/575   train_loss = 4.778
Epoch   5 Batch  358/575   train_loss = 5.017
Epoch   5 Batch  359/575   train_loss = 5.241
Epoch   5 Batch  360/575   train_loss = 4.283
Epoch   5 Batch  361/575   train_loss = 4.871
Epoch   5 Batch  362/575   train_loss = 4.657
Epoch   5 Batch  363/575   train_loss = 4.708
Epoch   5 Batch  364/575   train_loss = 4.411
Epoch   5 Batch  365/575   train_loss = 4.863
Epoch   5 Batch  366/575   train_loss = 4.296
Epoch   5 Batch  367/575   train_loss = 4.623
Epoch   5 Batch  368/575   train_loss = 5.328
Epoch   5 Batch  369/575   train_loss = 5.028
Epoch   5 Batch  370/575   train_loss = 4.908
Epoch   5 Batch  371/575   train_loss = 5.000
Epoch   5 Batch  372/575   train_loss = 4.538
Epoch   5 Batch  373/575   train_loss = 5.005
Epoch   5 Batch  374/575   train_loss = 4.140
Epoch   5 Batch  375/575   train_loss = 4.499
Epoch   5 Batch  376/575   train_loss = 4.819
Epoch   5 Batch  377/575   train_loss = 5.153
Epoch   5 Batch  378/575   train_loss = 5.263
Epoch   5 Batch  379/575   train_loss = 4.590
Epoch   5 Batch  380/575   train_loss = 4.297
Epoch   5 Batch  381/575   train_loss = 4.508
Epoch   5 Batch  382/575   train_loss = 4.786
Epoch   5 Batch  383/575   train_loss = 4.576
Epoch   5 Batch  384/575   train_loss = 4.739
Epoch   5 Batch  385/575   train_loss = 4.541
Epoch   5 Batch  386/575   train_loss = 4.491
Epoch   5 Batch  387/575   train_loss = 5.185
Epoch   5 Batch  388/575   train_loss = 4.629
Epoch   5 Batch  389/575   train_loss = 4.590
Epoch   5 Batch  390/575   train_loss = 4.845
Epoch   5 Batch  391/575   train_loss = 4.888
Epoch   5 Batch  392/575   train_loss = 4.766
Epoch   5 Batch  393/575   train_loss = 4.775
Epoch   5 Batch  394/575   train_loss = 5.038
Epoch   5 Batch  395/575   train_loss = 4.118
Epoch   5 Batch  396/575   train_loss = 4.428
Epoch   5 Batch  397/575   train_loss = 4.829
Epoch   5 Batch  398/575   train_loss = 5.241
Epoch   5 Batch  399/575   train_loss = 5.159
Epoch   5 Batch  400/575   train_loss = 5.008
Epoch   5 Batch  401/575   train_loss = 4.357
Epoch   5 Batch  402/575   train_loss = 4.456
Epoch   5 Batch  403/575   train_loss = 4.877
Epoch   5 Batch  404/575   train_loss = 4.917
Epoch   5 Batch  405/575   train_loss = 4.971
Epoch   5 Batch  406/575   train_loss = 4.442
Epoch   5 Batch  407/575   train_loss = 4.816
Epoch   5 Batch  408/575   train_loss = 4.679
Epoch   5 Batch  409/575   train_loss = 4.701
Epoch   5 Batch  410/575   train_loss = 4.498
Epoch   5 Batch  411/575   train_loss = 4.795
Epoch   5 Batch  412/575   train_loss = 5.337
Epoch   5 Batch  413/575   train_loss = 4.969
Epoch   5 Batch  414/575   train_loss = 4.618
Epoch   5 Batch  415/575   train_loss = 5.131
Epoch   5 Batch  416/575   train_loss = 4.639
Epoch   5 Batch  417/575   train_loss = 4.304
Epoch   5 Batch  418/575   train_loss = 4.753
Epoch   5 Batch  419/575   train_loss = 4.628
Epoch   5 Batch  420/575   train_loss = 4.503
Epoch   5 Batch  421/575   train_loss = 5.195
Epoch   5 Batch  422/575   train_loss = 4.921
Epoch   5 Batch  423/575   train_loss = 5.290
Epoch   5 Batch  424/575   train_loss = 5.290
Epoch   5 Batch  425/575   train_loss = 4.978
Epoch   5 Batch  426/575   train_loss = 4.842
Epoch   5 Batch  427/575   train_loss = 4.741
Epoch   5 Batch  428/575   train_loss = 4.686
Epoch   5 Batch  429/575   train_loss = 4.486
Epoch   5 Batch  430/575   train_loss = 4.822
Epoch   5 Batch  431/575   train_loss = 4.683
Epoch   5 Batch  432/575   train_loss = 5.096
Epoch   5 Batch  433/575   train_loss = 5.063
Epoch   5 Batch  434/575   train_loss = 4.915
Epoch   5 Batch  435/575   train_loss = 4.700
Epoch   5 Batch  436/575   train_loss = 4.473
Epoch   5 Batch  437/575   train_loss = 4.689
Epoch   5 Batch  438/575   train_loss = 4.945
Epoch   5 Batch  439/575   train_loss = 4.813
Epoch   5 Batch  440/575   train_loss = 5.036
Epoch   5 Batch  441/575   train_loss = 4.740
Epoch   5 Batch  442/575   train_loss = 4.905
Epoch   5 Batch  443/575   train_loss = 4.877
Epoch   5 Batch  444/575   train_loss = 4.929
Epoch   5 Batch  445/575   train_loss = 4.490
Epoch   5 Batch  446/575   train_loss = 4.454
Epoch   5 Batch  447/575   train_loss = 4.976
Epoch   5 Batch  448/575   train_loss = 4.807
Epoch   5 Batch  449/575   train_loss = 4.793
Epoch   5 Batch  450/575   train_loss = 5.340
Epoch   5 Batch  451/575   train_loss = 5.278
Epoch   5 Batch  452/575   train_loss = 5.322
Epoch   5 Batch  453/575   train_loss = 4.849
Epoch   5 Batch  454/575   train_loss = 5.206
Epoch   5 Batch  455/575   train_loss = 4.485
Epoch   5 Batch  456/575   train_loss = 5.174
Epoch   5 Batch  457/575   train_loss = 4.377
Epoch   5 Batch  458/575   train_loss = 5.132
Epoch   5 Batch  459/575   train_loss = 4.879
Epoch   5 Batch  460/575   train_loss = 4.625
Epoch   5 Batch  461/575   train_loss = 4.808
Epoch   5 Batch  462/575   train_loss = 4.737
Epoch   5 Batch  463/575   train_loss = 4.602
Epoch   5 Batch  464/575   train_loss = 4.509
Epoch   5 Batch  465/575   train_loss = 4.659
Epoch   5 Batch  466/575   train_loss = 4.669
Epoch   5 Batch  467/575   train_loss = 4.075
Epoch   5 Batch  468/575   train_loss = 4.609
Epoch   5 Batch  469/575   train_loss = 5.083
Epoch   5 Batch  470/575   train_loss = 5.309
Epoch   5 Batch  471/575   train_loss = 4.573
Epoch   5 Batch  472/575   train_loss = 5.017
Epoch   5 Batch  473/575   train_loss = 4.867
Epoch   5 Batch  474/575   train_loss = 4.858
Epoch   5 Batch  475/575   train_loss = 4.559
Epoch   5 Batch  476/575   train_loss = 4.721
Epoch   5 Batch  477/575   train_loss = 5.281
Epoch   5 Batch  478/575   train_loss = 5.345
Epoch   5 Batch  479/575   train_loss = 4.634
Epoch   5 Batch  480/575   train_loss = 4.938
Epoch   5 Batch  481/575   train_loss = 5.011
Epoch   5 Batch  482/575   train_loss = 4.303
Epoch   5 Batch  483/575   train_loss = 5.557
Epoch   5 Batch  484/575   train_loss = 4.734
Epoch   5 Batch  485/575   train_loss = 5.318
Epoch   5 Batch  486/575   train_loss = 4.836
Epoch   5 Batch  487/575   train_loss = 5.077
Epoch   5 Batch  488/575   train_loss = 4.788
Epoch   5 Batch  489/575   train_loss = 5.020
Epoch   5 Batch  490/575   train_loss = 5.015
Epoch   5 Batch  491/575   train_loss = 4.286
Epoch   5 Batch  492/575   train_loss = 4.214
Epoch   5 Batch  493/575   train_loss = 4.323
Epoch   5 Batch  494/575   train_loss = 4.617
Epoch   5 Batch  495/575   train_loss = 4.720
Epoch   5 Batch  496/575   train_loss = 4.862
Epoch   5 Batch  497/575   train_loss = 5.027
Epoch   5 Batch  498/575   train_loss = 4.586
Epoch   5 Batch  499/575   train_loss = 4.557
Epoch   5 Batch  500/575   train_loss = 4.860
Epoch   5 Batch  501/575   train_loss = 4.808
Epoch   5 Batch  502/575   train_loss = 4.156
Epoch   5 Batch  503/575   train_loss = 4.998
Epoch   5 Batch  504/575   train_loss = 4.277
Epoch   5 Batch  505/575   train_loss = 4.666
Epoch   5 Batch  506/575   train_loss = 5.010
Epoch   5 Batch  507/575   train_loss = 5.079
Epoch   5 Batch  508/575   train_loss = 5.080
Epoch   5 Batch  509/575   train_loss = 4.781
Epoch   5 Batch  510/575   train_loss = 4.183
Epoch   5 Batch  511/575   train_loss = 4.245
Epoch   5 Batch  512/575   train_loss = 5.129
Epoch   5 Batch  513/575   train_loss = 4.853
Epoch   5 Batch  514/575   train_loss = 4.689
Epoch   5 Batch  515/575   train_loss = 4.783
Epoch   5 Batch  516/575   train_loss = 5.095
Epoch   5 Batch  517/575   train_loss = 4.325
Epoch   5 Batch  518/575   train_loss = 4.487
Epoch   5 Batch  519/575   train_loss = 4.663
Epoch   5 Batch  520/575   train_loss = 3.990
Epoch   5 Batch  521/575   train_loss = 4.393
Epoch   5 Batch  522/575   train_loss = 4.513
Epoch   5 Batch  523/575   train_loss = 5.156
Epoch   5 Batch  524/575   train_loss = 5.914
Epoch   5 Batch  525/575   train_loss = 4.870
Epoch   5 Batch  526/575   train_loss = 4.495
Epoch   5 Batch  527/575   train_loss = 5.012
Epoch   5 Batch  528/575   train_loss = 4.536
Epoch   5 Batch  529/575   train_loss = 5.048
Epoch   5 Batch  530/575   train_loss = 4.838
Epoch   5 Batch  531/575   train_loss = 4.925
Epoch   5 Batch  532/575   train_loss = 4.550
Epoch   5 Batch  533/575   train_loss = 4.502
Epoch   5 Batch  534/575   train_loss = 4.556
Epoch   5 Batch  535/575   train_loss = 4.898
Epoch   5 Batch  536/575   train_loss = 4.638
Epoch   5 Batch  537/575   train_loss = 4.376
Epoch   5 Batch  538/575   train_loss = 4.720
Epoch   5 Batch  539/575   train_loss = 4.570
Epoch   5 Batch  540/575   train_loss = 4.819
Epoch   5 Batch  541/575   train_loss = 5.285
Epoch   5 Batch  542/575   train_loss = 4.770
Epoch   5 Batch  543/575   train_loss = 4.968
Epoch   5 Batch  544/575   train_loss = 4.718
Epoch   5 Batch  545/575   train_loss = 4.775
Epoch   5 Batch  546/575   train_loss = 4.773
Epoch   5 Batch  547/575   train_loss = 4.770
Epoch   5 Batch  548/575   train_loss = 4.837
Epoch   5 Batch  549/575   train_loss = 4.620
Epoch   5 Batch  550/575   train_loss = 4.547
Epoch   5 Batch  551/575   train_loss = 4.533
Epoch   5 Batch  552/575   train_loss = 4.759
Epoch   5 Batch  553/575   train_loss = 4.932
Epoch   5 Batch  554/575   train_loss = 4.483
Epoch   5 Batch  555/575   train_loss = 4.761
Epoch   5 Batch  556/575   train_loss = 4.466
Epoch   5 Batch  557/575   train_loss = 4.378
Epoch   5 Batch  558/575   train_loss = 4.735
Epoch   5 Batch  559/575   train_loss = 4.884
Epoch   5 Batch  560/575   train_loss = 4.284
Epoch   5 Batch  561/575   train_loss = 4.690
Epoch   5 Batch  562/575   train_loss = 4.221
Epoch   5 Batch  563/575   train_loss = 4.666
Epoch   5 Batch  564/575   train_loss = 4.368
Epoch   5 Batch  565/575   train_loss = 3.920
Epoch   5 Batch  566/575   train_loss = 4.393
Epoch   5 Batch  567/575   train_loss = 4.329
Epoch   5 Batch  568/575   train_loss = 4.464
Epoch   5 Batch  569/575   train_loss = 4.754
Epoch   5 Batch  570/575   train_loss = 4.326
Epoch   5 Batch  571/575   train_loss = 4.164
Epoch   5 Batch  572/575   train_loss = 3.905
Epoch   5 Batch  573/575   train_loss = 4.262
Epoch   5 Batch  574/575   train_loss = 4.881
Epoch   6 Batch    0/575   train_loss = 4.539
Epoch   6 Batch    1/575   train_loss = 4.505
Epoch   6 Batch    2/575   train_loss = 4.712
Epoch   6 Batch    3/575   train_loss = 4.462
Epoch   6 Batch    4/575   train_loss = 4.393
Epoch   6 Batch    5/575   train_loss = 4.328
Epoch   6 Batch    6/575   train_loss = 4.223
Epoch   6 Batch    7/575   train_loss = 4.552
Epoch   6 Batch    8/575   train_loss = 4.543
Epoch   6 Batch    9/575   train_loss = 4.742
Epoch   6 Batch   10/575   train_loss = 4.238
Epoch   6 Batch   11/575   train_loss = 4.368
Epoch   6 Batch   12/575   train_loss = 4.522
Epoch   6 Batch   13/575   train_loss = 4.699
Epoch   6 Batch   14/575   train_loss = 5.146
Epoch   6 Batch   15/575   train_loss = 4.833
Epoch   6 Batch   16/575   train_loss = 4.674
Epoch   6 Batch   17/575   train_loss = 4.016
Epoch   6 Batch   18/575   train_loss = 5.015
Epoch   6 Batch   19/575   train_loss = 4.666
Epoch   6 Batch   20/575   train_loss = 4.087
Epoch   6 Batch   21/575   train_loss = 4.502
Epoch   6 Batch   22/575   train_loss = 5.107
Epoch   6 Batch   23/575   train_loss = 4.635
Epoch   6 Batch   24/575   train_loss = 4.544
Epoch   6 Batch   25/575   train_loss = 4.707
Epoch   6 Batch   26/575   train_loss = 4.915
Epoch   6 Batch   27/575   train_loss = 4.653
Epoch   6 Batch   28/575   train_loss = 4.184
Epoch   6 Batch   29/575   train_loss = 4.366
Epoch   6 Batch   30/575   train_loss = 5.083
Epoch   6 Batch   31/575   train_loss = 5.413
Epoch   6 Batch   32/575   train_loss = 4.693
Epoch   6 Batch   33/575   train_loss = 4.988
Epoch   6 Batch   34/575   train_loss = 4.577
Epoch   6 Batch   35/575   train_loss = 4.402
Epoch   6 Batch   36/575   train_loss = 4.890
Epoch   6 Batch   37/575   train_loss = 3.973
Epoch   6 Batch   38/575   train_loss = 4.738
Epoch   6 Batch   39/575   train_loss = 4.085
Epoch   6 Batch   40/575   train_loss = 3.896
Epoch   6 Batch   41/575   train_loss = 5.826
Epoch   6 Batch   42/575   train_loss = 4.717
Epoch   6 Batch   43/575   train_loss = 4.652
Epoch   6 Batch   44/575   train_loss = 4.554
Epoch   6 Batch   45/575   train_loss = 4.405
Epoch   6 Batch   46/575   train_loss = 4.388
Epoch   6 Batch   47/575   train_loss = 4.822
Epoch   6 Batch   48/575   train_loss = 3.982
Epoch   6 Batch   49/575   train_loss = 4.253
Epoch   6 Batch   50/575   train_loss = 4.470
Epoch   6 Batch   51/575   train_loss = 4.363
Epoch   6 Batch   52/575   train_loss = 4.378
Epoch   6 Batch   53/575   train_loss = 4.061
Epoch   6 Batch   54/575   train_loss = 4.557
Epoch   6 Batch   55/575   train_loss = 4.878
Epoch   6 Batch   56/575   train_loss = 4.241
Epoch   6 Batch   57/575   train_loss = 4.629
Epoch   6 Batch   58/575   train_loss = 4.236
Epoch   6 Batch   59/575   train_loss = 4.094
Epoch   6 Batch   60/575   train_loss = 4.682
Epoch   6 Batch   61/575   train_loss = 4.685
Epoch   6 Batch   62/575   train_loss = 4.158
Epoch   6 Batch   63/575   train_loss = 4.964
Epoch   6 Batch   64/575   train_loss = 4.861
Epoch   6 Batch   65/575   train_loss = 4.384
Epoch   6 Batch   66/575   train_loss = 4.355
Epoch   6 Batch   67/575   train_loss = 4.276
Epoch   6 Batch   68/575   train_loss = 4.317
Epoch   6 Batch   69/575   train_loss = 4.062
Epoch   6 Batch   70/575   train_loss = 4.522
Epoch   6 Batch   71/575   train_loss = 4.280
Epoch   6 Batch   72/575   train_loss = 4.861
Epoch   6 Batch   73/575   train_loss = 4.873
Epoch   6 Batch   74/575   train_loss = 5.005
Epoch   6 Batch   75/575   train_loss = 4.641
Epoch   6 Batch   76/575   train_loss = 4.942
Epoch   6 Batch   77/575   train_loss = 5.047
Epoch   6 Batch   78/575   train_loss = 4.773
Epoch   6 Batch   79/575   train_loss = 4.544
Epoch   6 Batch   80/575   train_loss = 4.495
Epoch   6 Batch   81/575   train_loss = 4.426
Epoch   6 Batch   82/575   train_loss = 4.187
Epoch   6 Batch   83/575   train_loss = 4.501
Epoch   6 Batch   84/575   train_loss = 4.487
Epoch   6 Batch   85/575   train_loss = 5.137
Epoch   6 Batch   86/575   train_loss = 4.436
Epoch   6 Batch   87/575   train_loss = 5.071
Epoch   6 Batch   88/575   train_loss = 3.888
Epoch   6 Batch   89/575   train_loss = 4.131
Epoch   6 Batch   90/575   train_loss = 4.328
Epoch   6 Batch   91/575   train_loss = 4.590
Epoch   6 Batch   92/575   train_loss = 5.099
Epoch   6 Batch   93/575   train_loss = 4.704
Epoch   6 Batch   94/575   train_loss = 4.235
Epoch   6 Batch   95/575   train_loss = 4.601
Epoch   6 Batch   96/575   train_loss = 4.631
Epoch   6 Batch   97/575   train_loss = 4.717
Epoch   6 Batch   98/575   train_loss = 4.464
Epoch   6 Batch   99/575   train_loss = 5.063
Epoch   6 Batch  100/575   train_loss = 4.796
Epoch   6 Batch  101/575   train_loss = 4.392
Epoch   6 Batch  102/575   train_loss = 4.213
Epoch   6 Batch  103/575   train_loss = 4.765
Epoch   6 Batch  104/575   train_loss = 4.564
Epoch   6 Batch  105/575   train_loss = 4.712
Epoch   6 Batch  106/575   train_loss = 4.394
Epoch   6 Batch  107/575   train_loss = 4.274
Epoch   6 Batch  108/575   train_loss = 4.705
Epoch   6 Batch  109/575   train_loss = 4.438
Epoch   6 Batch  110/575   train_loss = 3.593
Epoch   6 Batch  111/575   train_loss = 4.500
Epoch   6 Batch  112/575   train_loss = 4.639
Epoch   6 Batch  113/575   train_loss = 5.168
Epoch   6 Batch  114/575   train_loss = 4.849
Epoch   6 Batch  115/575   train_loss = 4.373
Epoch   6 Batch  116/575   train_loss = 4.798
Epoch   6 Batch  117/575   train_loss = 4.180
Epoch   6 Batch  118/575   train_loss = 4.622
Epoch   6 Batch  119/575   train_loss = 5.129
Epoch   6 Batch  120/575   train_loss = 4.699
Epoch   6 Batch  121/575   train_loss = 4.767
Epoch   6 Batch  122/575   train_loss = 4.769
Epoch   6 Batch  123/575   train_loss = 4.522
Epoch   6 Batch  124/575   train_loss = 4.963
Epoch   6 Batch  125/575   train_loss = 4.742
Epoch   6 Batch  126/575   train_loss = 4.592
Epoch   6 Batch  127/575   train_loss = 4.082
Epoch   6 Batch  128/575   train_loss = 4.554
Epoch   6 Batch  129/575   train_loss = 4.522
Epoch   6 Batch  130/575   train_loss = 4.812
Epoch   6 Batch  131/575   train_loss = 4.026
Epoch   6 Batch  132/575   train_loss = 4.421
Epoch   6 Batch  133/575   train_loss = 4.612
Epoch   6 Batch  134/575   train_loss = 4.462
Epoch   6 Batch  135/575   train_loss = 4.140
Epoch   6 Batch  136/575   train_loss = 5.489
Epoch   6 Batch  137/575   train_loss = 4.727
Epoch   6 Batch  138/575   train_loss = 5.084
Epoch   6 Batch  139/575   train_loss = 4.744
Epoch   6 Batch  140/575   train_loss = 4.712
Epoch   6 Batch  141/575   train_loss = 5.022
Epoch   6 Batch  142/575   train_loss = 5.266
Epoch   6 Batch  143/575   train_loss = 4.772
Epoch   6 Batch  144/575   train_loss = 4.333
Epoch   6 Batch  145/575   train_loss = 4.303
Epoch   6 Batch  146/575   train_loss = 4.311
Epoch   6 Batch  147/575   train_loss = 4.478
Epoch   6 Batch  148/575   train_loss = 3.987
Epoch   6 Batch  149/575   train_loss = 4.671
Epoch   6 Batch  150/575   train_loss = 4.927
Epoch   6 Batch  151/575   train_loss = 4.216
Epoch   6 Batch  152/575   train_loss = 4.193
Epoch   6 Batch  153/575   train_loss = 3.731
Epoch   6 Batch  154/575   train_loss = 3.908
Epoch   6 Batch  155/575   train_loss = 4.637
Epoch   6 Batch  156/575   train_loss = 4.495
Epoch   6 Batch  157/575   train_loss = 4.634
Epoch   6 Batch  158/575   train_loss = 4.587
Epoch   6 Batch  159/575   train_loss = 4.746
Epoch   6 Batch  160/575   train_loss = 4.320
Epoch   6 Batch  161/575   train_loss = 4.908
Epoch   6 Batch  162/575   train_loss = 4.748
Epoch   6 Batch  163/575   train_loss = 4.506
Epoch   6 Batch  164/575   train_loss = 4.831
Epoch   6 Batch  165/575   train_loss = 4.682
Epoch   6 Batch  166/575   train_loss = 4.286
Epoch   6 Batch  167/575   train_loss = 4.333
Epoch   6 Batch  168/575   train_loss = 4.739
Epoch   6 Batch  169/575   train_loss = 4.349
Epoch   6 Batch  170/575   train_loss = 4.818
Epoch   6 Batch  171/575   train_loss = 4.396
Epoch   6 Batch  172/575   train_loss = 4.640
Epoch   6 Batch  173/575   train_loss = 4.623
Epoch   6 Batch  174/575   train_loss = 4.865
Epoch   6 Batch  175/575   train_loss = 4.636
Epoch   6 Batch  176/575   train_loss = 4.704
Epoch   6 Batch  177/575   train_loss = 4.767
Epoch   6 Batch  178/575   train_loss = 4.552
Epoch   6 Batch  179/575   train_loss = 4.305
Epoch   6 Batch  180/575   train_loss = 4.386
Epoch   6 Batch  181/575   train_loss = 4.609
Epoch   6 Batch  182/575   train_loss = 4.416
Epoch   6 Batch  183/575   train_loss = 4.813
Epoch   6 Batch  184/575   train_loss = 3.929
Epoch   6 Batch  185/575   train_loss = 4.474
Epoch   6 Batch  186/575   train_loss = 4.672
Epoch   6 Batch  187/575   train_loss = 4.520
Epoch   6 Batch  188/575   train_loss = 4.499
Epoch   6 Batch  189/575   train_loss = 4.498
Epoch   6 Batch  190/575   train_loss = 4.548
Epoch   6 Batch  191/575   train_loss = 5.003
Epoch   6 Batch  192/575   train_loss = 4.852
Epoch   6 Batch  193/575   train_loss = 4.559
Epoch   6 Batch  194/575   train_loss = 4.685
Epoch   6 Batch  195/575   train_loss = 4.312
Epoch   6 Batch  196/575   train_loss = 4.377
Epoch   6 Batch  197/575   train_loss = 4.303
Epoch   6 Batch  198/575   train_loss = 4.844
Epoch   6 Batch  199/575   train_loss = 4.030
Epoch   6 Batch  200/575   train_loss = 4.312
Epoch   6 Batch  201/575   train_loss = 4.571
Epoch   6 Batch  202/575   train_loss = 4.209
Epoch   6 Batch  203/575   train_loss = 4.453
Epoch   6 Batch  204/575   train_loss = 4.397
Epoch   6 Batch  205/575   train_loss = 4.142
Epoch   6 Batch  206/575   train_loss = 4.491
Epoch   6 Batch  207/575   train_loss = 4.296
Epoch   6 Batch  208/575   train_loss = 4.155
Epoch   6 Batch  209/575   train_loss = 4.222
Epoch   6 Batch  210/575   train_loss = 4.600
Epoch   6 Batch  211/575   train_loss = 5.149
Epoch   6 Batch  212/575   train_loss = 4.778
Epoch   6 Batch  213/575   train_loss = 4.594
Epoch   6 Batch  214/575   train_loss = 4.275
Epoch   6 Batch  215/575   train_loss = 3.827
Epoch   6 Batch  216/575   train_loss = 4.248
Epoch   6 Batch  217/575   train_loss = 3.996
Epoch   6 Batch  218/575   train_loss = 4.673
Epoch   6 Batch  219/575   train_loss = 4.347
Epoch   6 Batch  220/575   train_loss = 3.947
Epoch   6 Batch  221/575   train_loss = 4.514
Epoch   6 Batch  222/575   train_loss = 4.596
Epoch   6 Batch  223/575   train_loss = 4.853
Epoch   6 Batch  224/575   train_loss = 4.175
Epoch   6 Batch  225/575   train_loss = 4.306
Epoch   6 Batch  226/575   train_loss = 4.640
Epoch   6 Batch  227/575   train_loss = 4.949
Epoch   6 Batch  228/575   train_loss = 4.777
Epoch   6 Batch  229/575   train_loss = 3.797
Epoch   6 Batch  230/575   train_loss = 3.974
Epoch   6 Batch  231/575   train_loss = 4.459
Epoch   6 Batch  232/575   train_loss = 4.595
Epoch   6 Batch  233/575   train_loss = 4.575
Epoch   6 Batch  234/575   train_loss = 4.675
Epoch   6 Batch  235/575   train_loss = 4.334
Epoch   6 Batch  236/575   train_loss = 3.930
Epoch   6 Batch  237/575   train_loss = 4.229
Epoch   6 Batch  238/575   train_loss = 4.247
Epoch   6 Batch  239/575   train_loss = 4.549
Epoch   6 Batch  240/575   train_loss = 4.819
Epoch   6 Batch  241/575   train_loss = 4.874
Epoch   6 Batch  242/575   train_loss = 4.364
Epoch   6 Batch  243/575   train_loss = 4.575
Epoch   6 Batch  244/575   train_loss = 4.443
Epoch   6 Batch  245/575   train_loss = 4.641
Epoch   6 Batch  246/575   train_loss = 4.861
Epoch   6 Batch  247/575   train_loss = 4.411
Epoch   6 Batch  248/575   train_loss = 4.673
Epoch   6 Batch  249/575   train_loss = 4.544
Epoch   6 Batch  250/575   train_loss = 4.372
Epoch   6 Batch  251/575   train_loss = 4.605
Epoch   6 Batch  252/575   train_loss = 4.851
Epoch   6 Batch  253/575   train_loss = 4.489
Epoch   6 Batch  254/575   train_loss = 4.092
Epoch   6 Batch  255/575   train_loss = 4.746
Epoch   6 Batch  256/575   train_loss = 4.404
Epoch   6 Batch  257/575   train_loss = 4.532
Epoch   6 Batch  258/575   train_loss = 4.909
Epoch   6 Batch  259/575   train_loss = 4.068
Epoch   6 Batch  260/575   train_loss = 4.258
Epoch   6 Batch  261/575   train_loss = 5.040
Epoch   6 Batch  262/575   train_loss = 4.742
Epoch   6 Batch  263/575   train_loss = 4.677
Epoch   6 Batch  264/575   train_loss = 3.899
Epoch   6 Batch  265/575   train_loss = 3.842
Epoch   6 Batch  266/575   train_loss = 3.965
Epoch   6 Batch  267/575   train_loss = 4.444
Epoch   6 Batch  268/575   train_loss = 4.470
Epoch   6 Batch  269/575   train_loss = 4.635
Epoch   6 Batch  270/575   train_loss = 5.022
Epoch   6 Batch  271/575   train_loss = 4.212
Epoch   6 Batch  272/575   train_loss = 4.709
Epoch   6 Batch  273/575   train_loss = 4.713
Epoch   6 Batch  274/575   train_loss = 4.701
Epoch   6 Batch  275/575   train_loss = 4.513
Epoch   6 Batch  276/575   train_loss = 5.060
Epoch   6 Batch  277/575   train_loss = 3.810
Epoch   6 Batch  278/575   train_loss = 4.576
Epoch   6 Batch  279/575   train_loss = 4.676
Epoch   6 Batch  280/575   train_loss = 4.786
Epoch   6 Batch  281/575   train_loss = 4.304
Epoch   6 Batch  282/575   train_loss = 4.607
Epoch   6 Batch  283/575   train_loss = 4.855
Epoch   6 Batch  284/575   train_loss = 5.033
Epoch   6 Batch  285/575   train_loss = 4.285
Epoch   6 Batch  286/575   train_loss = 4.595
Epoch   6 Batch  287/575   train_loss = 4.744
Epoch   6 Batch  288/575   train_loss = 4.485
Epoch   6 Batch  289/575   train_loss = 4.516
Epoch   6 Batch  290/575   train_loss = 4.579
Epoch   6 Batch  291/575   train_loss = 5.151
Epoch   6 Batch  292/575   train_loss = 5.052
Epoch   6 Batch  293/575   train_loss = 5.239
Epoch   6 Batch  294/575   train_loss = 4.883
Epoch   6 Batch  295/575   train_loss = 4.441
Epoch   6 Batch  296/575   train_loss = 4.579
Epoch   6 Batch  297/575   train_loss = 4.634
Epoch   6 Batch  298/575   train_loss = 4.754
Epoch   6 Batch  299/575   train_loss = 4.671
Epoch   6 Batch  300/575   train_loss = 4.539
Epoch   6 Batch  301/575   train_loss = 4.408
Epoch   6 Batch  302/575   train_loss = 4.804
Epoch   6 Batch  303/575   train_loss = 4.268
Epoch   6 Batch  304/575   train_loss = 4.400
Epoch   6 Batch  305/575   train_loss = 4.383
Epoch   6 Batch  306/575   train_loss = 4.687
Epoch   6 Batch  307/575   train_loss = 4.739
Epoch   6 Batch  308/575   train_loss = 4.620
Epoch   6 Batch  309/575   train_loss = 4.889
Epoch   6 Batch  310/575   train_loss = 4.929
Epoch   6 Batch  311/575   train_loss = 4.250
Epoch   6 Batch  312/575   train_loss = 4.664
Epoch   6 Batch  313/575   train_loss = 5.017
Epoch   6 Batch  314/575   train_loss = 4.919
Epoch   6 Batch  315/575   train_loss = 5.123
Epoch   6 Batch  316/575   train_loss = 4.487
Epoch   6 Batch  317/575   train_loss = 4.143
Epoch   6 Batch  318/575   train_loss = 3.857
Epoch   6 Batch  319/575   train_loss = 4.581
Epoch   6 Batch  320/575   train_loss = 4.406
Epoch   6 Batch  321/575   train_loss = 4.892
Epoch   6 Batch  322/575   train_loss = 4.490
Epoch   6 Batch  323/575   train_loss = 4.990
Epoch   6 Batch  324/575   train_loss = 4.480
Epoch   6 Batch  325/575   train_loss = 4.624
Epoch   6 Batch  326/575   train_loss = 4.389
Epoch   6 Batch  327/575   train_loss = 4.786
Epoch   6 Batch  328/575   train_loss = 4.416
Epoch   6 Batch  329/575   train_loss = 5.026
Epoch   6 Batch  330/575   train_loss = 4.625
Epoch   6 Batch  331/575   train_loss = 5.116
Epoch   6 Batch  332/575   train_loss = 4.738
Epoch   6 Batch  333/575   train_loss = 4.681
Epoch   6 Batch  334/575   train_loss = 4.531
Epoch   6 Batch  335/575   train_loss = 4.279
Epoch   6 Batch  336/575   train_loss = 4.648
Epoch   6 Batch  337/575   train_loss = 4.518
Epoch   6 Batch  338/575   train_loss = 4.334
Epoch   6 Batch  339/575   train_loss = 4.646
Epoch   6 Batch  340/575   train_loss = 4.447
Epoch   6 Batch  341/575   train_loss = 4.443
Epoch   6 Batch  342/575   train_loss = 4.295
Epoch   6 Batch  343/575   train_loss = 4.779
Epoch   6 Batch  344/575   train_loss = 4.809
Epoch   6 Batch  345/575   train_loss = 4.423
Epoch   6 Batch  346/575   train_loss = 5.119
Epoch   6 Batch  347/575   train_loss = 4.288
Epoch   6 Batch  348/575   train_loss = 4.305
Epoch   6 Batch  349/575   train_loss = 4.104
Epoch   6 Batch  350/575   train_loss = 4.709
Epoch   6 Batch  351/575   train_loss = 5.033
Epoch   6 Batch  352/575   train_loss = 4.876
Epoch   6 Batch  353/575   train_loss = 4.768
Epoch   6 Batch  354/575   train_loss = 4.373
Epoch   6 Batch  355/575   train_loss = 4.991
Epoch   6 Batch  356/575   train_loss = 4.754
Epoch   6 Batch  357/575   train_loss = 4.701
Epoch   6 Batch  358/575   train_loss = 4.872
Epoch   6 Batch  359/575   train_loss = 5.070
Epoch   6 Batch  360/575   train_loss = 4.177
Epoch   6 Batch  361/575   train_loss = 4.710
Epoch   6 Batch  362/575   train_loss = 4.519
Epoch   6 Batch  363/575   train_loss = 4.611
Epoch   6 Batch  364/575   train_loss = 4.322
Epoch   6 Batch  365/575   train_loss = 4.733
Epoch   6 Batch  366/575   train_loss = 4.141
Epoch   6 Batch  367/575   train_loss = 4.446
Epoch   6 Batch  368/575   train_loss = 5.188
Epoch   6 Batch  369/575   train_loss = 4.895
Epoch   6 Batch  370/575   train_loss = 4.771
Epoch   6 Batch  371/575   train_loss = 4.824
Epoch   6 Batch  372/575   train_loss = 4.395
Epoch   6 Batch  373/575   train_loss = 4.850
Epoch   6 Batch  374/575   train_loss = 4.008
Epoch   6 Batch  375/575   train_loss = 4.375
Epoch   6 Batch  376/575   train_loss = 4.723
Epoch   6 Batch  377/575   train_loss = 5.024
Epoch   6 Batch  378/575   train_loss = 5.142
Epoch   6 Batch  379/575   train_loss = 4.489
Epoch   6 Batch  380/575   train_loss = 4.158
Epoch   6 Batch  381/575   train_loss = 4.375
Epoch   6 Batch  382/575   train_loss = 4.636
Epoch   6 Batch  383/575   train_loss = 4.458
Epoch   6 Batch  384/575   train_loss = 4.600
Epoch   6 Batch  385/575   train_loss = 4.455
Epoch   6 Batch  386/575   train_loss = 4.379
Epoch   6 Batch  387/575   train_loss = 5.048
Epoch   6 Batch  388/575   train_loss = 4.544
Epoch   6 Batch  389/575   train_loss = 4.471
Epoch   6 Batch  390/575   train_loss = 4.719
Epoch   6 Batch  391/575   train_loss = 4.757
Epoch   6 Batch  392/575   train_loss = 4.667
Epoch   6 Batch  393/575   train_loss = 4.678
Epoch   6 Batch  394/575   train_loss = 4.893
Epoch   6 Batch  395/575   train_loss = 3.998
Epoch   6 Batch  396/575   train_loss = 4.313
Epoch   6 Batch  397/575   train_loss = 4.674
Epoch   6 Batch  398/575   train_loss = 5.115
Epoch   6 Batch  399/575   train_loss = 5.004
Epoch   6 Batch  400/575   train_loss = 4.885
Epoch   6 Batch  401/575   train_loss = 4.253
Epoch   6 Batch  402/575   train_loss = 4.344
Epoch   6 Batch  403/575   train_loss = 4.755
Epoch   6 Batch  404/575   train_loss = 4.750
Epoch   6 Batch  405/575   train_loss = 4.810
Epoch   6 Batch  406/575   train_loss = 4.315
Epoch   6 Batch  407/575   train_loss = 4.677
Epoch   6 Batch  408/575   train_loss = 4.515
Epoch   6 Batch  409/575   train_loss = 4.595
Epoch   6 Batch  410/575   train_loss = 4.366
Epoch   6 Batch  411/575   train_loss = 4.691
Epoch   6 Batch  412/575   train_loss = 5.187
Epoch   6 Batch  413/575   train_loss = 4.817
Epoch   6 Batch  414/575   train_loss = 4.448
Epoch   6 Batch  415/575   train_loss = 4.952
Epoch   6 Batch  416/575   train_loss = 4.521
Epoch   6 Batch  417/575   train_loss = 4.194
Epoch   6 Batch  418/575   train_loss = 4.665
Epoch   6 Batch  419/575   train_loss = 4.513
Epoch   6 Batch  420/575   train_loss = 4.385
Epoch   6 Batch  421/575   train_loss = 5.038
Epoch   6 Batch  422/575   train_loss = 4.783
Epoch   6 Batch  423/575   train_loss = 5.138
Epoch   6 Batch  424/575   train_loss = 5.115
Epoch   6 Batch  425/575   train_loss = 4.787
Epoch   6 Batch  426/575   train_loss = 4.708
Epoch   6 Batch  427/575   train_loss = 4.619
Epoch   6 Batch  428/575   train_loss = 4.508
Epoch   6 Batch  429/575   train_loss = 4.381
Epoch   6 Batch  430/575   train_loss = 4.708
Epoch   6 Batch  431/575   train_loss = 4.581
Epoch   6 Batch  432/575   train_loss = 4.923
Epoch   6 Batch  433/575   train_loss = 4.923
Epoch   6 Batch  434/575   train_loss = 4.772
Epoch   6 Batch  435/575   train_loss = 4.537
Epoch   6 Batch  436/575   train_loss = 4.397
Epoch   6 Batch  437/575   train_loss = 4.542
Epoch   6 Batch  438/575   train_loss = 4.781
Epoch   6 Batch  439/575   train_loss = 4.675
Epoch   6 Batch  440/575   train_loss = 4.909
Epoch   6 Batch  441/575   train_loss = 4.576
Epoch   6 Batch  442/575   train_loss = 4.809
Epoch   6 Batch  443/575   train_loss = 4.723
Epoch   6 Batch  444/575   train_loss = 4.789
Epoch   6 Batch  445/575   train_loss = 4.347
Epoch   6 Batch  446/575   train_loss = 4.314
Epoch   6 Batch  447/575   train_loss = 4.833
Epoch   6 Batch  448/575   train_loss = 4.699
Epoch   6 Batch  449/575   train_loss = 4.627
Epoch   6 Batch  450/575   train_loss = 5.121
Epoch   6 Batch  451/575   train_loss = 5.097
Epoch   6 Batch  452/575   train_loss = 5.148
Epoch   6 Batch  453/575   train_loss = 4.714
Epoch   6 Batch  454/575   train_loss = 5.079
Epoch   6 Batch  455/575   train_loss = 4.352
Epoch   6 Batch  456/575   train_loss = 4.990
Epoch   6 Batch  457/575   train_loss = 4.236
Epoch   6 Batch  458/575   train_loss = 5.003
Epoch   6 Batch  459/575   train_loss = 4.696
Epoch   6 Batch  460/575   train_loss = 4.475
Epoch   6 Batch  461/575   train_loss = 4.641
Epoch   6 Batch  462/575   train_loss = 4.576
Epoch   6 Batch  463/575   train_loss = 4.427
Epoch   6 Batch  464/575   train_loss = 4.418
Epoch   6 Batch  465/575   train_loss = 4.552
Epoch   6 Batch  466/575   train_loss = 4.527
Epoch   6 Batch  467/575   train_loss = 3.926
Epoch   6 Batch  468/575   train_loss = 4.501
Epoch   6 Batch  469/575   train_loss = 4.949
Epoch   6 Batch  470/575   train_loss = 5.119
Epoch   6 Batch  471/575   train_loss = 4.436
Epoch   6 Batch  472/575   train_loss = 4.885
Epoch   6 Batch  473/575   train_loss = 4.736
Epoch   6 Batch  474/575   train_loss = 4.740
Epoch   6 Batch  475/575   train_loss = 4.429
Epoch   6 Batch  476/575   train_loss = 4.586
Epoch   6 Batch  477/575   train_loss = 5.133
Epoch   6 Batch  478/575   train_loss = 5.194
Epoch   6 Batch  479/575   train_loss = 4.464
Epoch   6 Batch  480/575   train_loss = 4.759
Epoch   6 Batch  481/575   train_loss = 4.860
Epoch   6 Batch  482/575   train_loss = 4.195
Epoch   6 Batch  483/575   train_loss = 5.354
Epoch   6 Batch  484/575   train_loss = 4.555
Epoch   6 Batch  485/575   train_loss = 5.197
Epoch   6 Batch  486/575   train_loss = 4.658
Epoch   6 Batch  487/575   train_loss = 4.954
Epoch   6 Batch  488/575   train_loss = 4.658
Epoch   6 Batch  489/575   train_loss = 4.855
Epoch   6 Batch  490/575   train_loss = 4.843
Epoch   6 Batch  491/575   train_loss = 4.160
Epoch   6 Batch  492/575   train_loss = 4.136
Epoch   6 Batch  493/575   train_loss = 4.237
Epoch   6 Batch  494/575   train_loss = 4.536
Epoch   6 Batch  495/575   train_loss = 4.576
Epoch   6 Batch  496/575   train_loss = 4.723
Epoch   6 Batch  497/575   train_loss = 4.854
Epoch   6 Batch  498/575   train_loss = 4.457
Epoch   6 Batch  499/575   train_loss = 4.416
Epoch   6 Batch  500/575   train_loss = 4.746
Epoch   6 Batch  501/575   train_loss = 4.708
Epoch   6 Batch  502/575   train_loss = 4.045
Epoch   6 Batch  503/575   train_loss = 4.908
Epoch   6 Batch  504/575   train_loss = 4.094
Epoch   6 Batch  505/575   train_loss = 4.551
Epoch   6 Batch  506/575   train_loss = 4.846
Epoch   6 Batch  507/575   train_loss = 4.953
Epoch   6 Batch  508/575   train_loss = 4.969
Epoch   6 Batch  509/575   train_loss = 4.640
Epoch   6 Batch  510/575   train_loss = 4.048
Epoch   6 Batch  511/575   train_loss = 4.136
Epoch   6 Batch  512/575   train_loss = 4.975
Epoch   6 Batch  513/575   train_loss = 4.683
Epoch   6 Batch  514/575   train_loss = 4.558
Epoch   6 Batch  515/575   train_loss = 4.661
Epoch   6 Batch  516/575   train_loss = 4.955
Epoch   6 Batch  517/575   train_loss = 4.161
Epoch   6 Batch  518/575   train_loss = 4.345
Epoch   6 Batch  519/575   train_loss = 4.541
Epoch   6 Batch  520/575   train_loss = 3.933
Epoch   6 Batch  521/575   train_loss = 4.274
Epoch   6 Batch  522/575   train_loss = 4.391
Epoch   6 Batch  523/575   train_loss = 4.936
Epoch   6 Batch  524/575   train_loss = 5.620
Epoch   6 Batch  525/575   train_loss = 4.813
Epoch   6 Batch  526/575   train_loss = 4.338
Epoch   6 Batch  527/575   train_loss = 4.876
Epoch   6 Batch  528/575   train_loss = 4.400
Epoch   6 Batch  529/575   train_loss = 4.912
Epoch   6 Batch  530/575   train_loss = 4.696
Epoch   6 Batch  531/575   train_loss = 4.782
Epoch   6 Batch  532/575   train_loss = 4.395
Epoch   6 Batch  533/575   train_loss = 4.320
Epoch   6 Batch  534/575   train_loss = 4.399
Epoch   6 Batch  535/575   train_loss = 4.671
Epoch   6 Batch  536/575   train_loss = 4.470
Epoch   6 Batch  537/575   train_loss = 4.268
Epoch   6 Batch  538/575   train_loss = 4.568
Epoch   6 Batch  539/575   train_loss = 4.437
Epoch   6 Batch  540/575   train_loss = 4.677
Epoch   6 Batch  541/575   train_loss = 5.105
Epoch   6 Batch  542/575   train_loss = 4.631
Epoch   6 Batch  543/575   train_loss = 4.782
Epoch   6 Batch  544/575   train_loss = 4.566
Epoch   6 Batch  545/575   train_loss = 4.600
Epoch   6 Batch  546/575   train_loss = 4.634
Epoch   6 Batch  547/575   train_loss = 4.630
Epoch   6 Batch  548/575   train_loss = 4.711
Epoch   6 Batch  549/575   train_loss = 4.486
Epoch   6 Batch  550/575   train_loss = 4.423
Epoch   6 Batch  551/575   train_loss = 4.382
Epoch   6 Batch  552/575   train_loss = 4.615
Epoch   6 Batch  553/575   train_loss = 4.843
Epoch   6 Batch  554/575   train_loss = 4.305
Epoch   6 Batch  555/575   train_loss = 4.549
Epoch   6 Batch  556/575   train_loss = 4.328
Epoch   6 Batch  557/575   train_loss = 4.266
Epoch   6 Batch  558/575   train_loss = 4.594
Epoch   6 Batch  559/575   train_loss = 4.781
Epoch   6 Batch  560/575   train_loss = 4.175
Epoch   6 Batch  561/575   train_loss = 4.594
Epoch   6 Batch  562/575   train_loss = 4.085
Epoch   6 Batch  563/575   train_loss = 4.508
Epoch   6 Batch  564/575   train_loss = 4.241
Epoch   6 Batch  565/575   train_loss = 3.743
Epoch   6 Batch  566/575   train_loss = 4.260
Epoch   6 Batch  567/575   train_loss = 4.267
Epoch   6 Batch  568/575   train_loss = 4.363
Epoch   6 Batch  569/575   train_loss = 4.623
Epoch   6 Batch  570/575   train_loss = 4.233
Epoch   6 Batch  571/575   train_loss = 4.022
Epoch   6 Batch  572/575   train_loss = 3.787
Epoch   6 Batch  573/575   train_loss = 4.127
Epoch   6 Batch  574/575   train_loss = 4.704
Epoch   7 Batch    0/575   train_loss = 4.411
Epoch   7 Batch    1/575   train_loss = 4.389
Epoch   7 Batch    2/575   train_loss = 4.547
Epoch   7 Batch    3/575   train_loss = 4.341
Epoch   7 Batch    4/575   train_loss = 4.251
Epoch   7 Batch    5/575   train_loss = 4.230
Epoch   7 Batch    6/575   train_loss = 4.109
Epoch   7 Batch    7/575   train_loss = 4.423
Epoch   7 Batch    8/575   train_loss = 4.390
Epoch   7 Batch    9/575   train_loss = 4.635
Epoch   7 Batch   10/575   train_loss = 4.125
Epoch   7 Batch   11/575   train_loss = 4.219
Epoch   7 Batch   12/575   train_loss = 4.382
Epoch   7 Batch   13/575   train_loss = 4.553
Epoch   7 Batch   14/575   train_loss = 4.990
Epoch   7 Batch   15/575   train_loss = 4.662
Epoch   7 Batch   16/575   train_loss = 4.525
Epoch   7 Batch   17/575   train_loss = 3.898
Epoch   7 Batch   18/575   train_loss = 4.868
Epoch   7 Batch   19/575   train_loss = 4.534
Epoch   7 Batch   20/575   train_loss = 3.925
Epoch   7 Batch   21/575   train_loss = 4.415
Epoch   7 Batch   22/575   train_loss = 4.951
Epoch   7 Batch   23/575   train_loss = 4.507
Epoch   7 Batch   24/575   train_loss = 4.425
Epoch   7 Batch   25/575   train_loss = 4.575
Epoch   7 Batch   26/575   train_loss = 4.803
Epoch   7 Batch   27/575   train_loss = 4.506
Epoch   7 Batch   28/575   train_loss = 4.043
Epoch   7 Batch   29/575   train_loss = 4.244
Epoch   7 Batch   30/575   train_loss = 4.974
Epoch   7 Batch   31/575   train_loss = 5.238
Epoch   7 Batch   32/575   train_loss = 4.579
Epoch   7 Batch   33/575   train_loss = 4.847
Epoch   7 Batch   34/575   train_loss = 4.482
Epoch   7 Batch   35/575   train_loss = 4.263
Epoch   7 Batch   36/575   train_loss = 4.802
Epoch   7 Batch   37/575   train_loss = 3.885
Epoch   7 Batch   38/575   train_loss = 4.628
Epoch   7 Batch   39/575   train_loss = 3.959
Epoch   7 Batch   40/575   train_loss = 3.805
Epoch   7 Batch   41/575   train_loss = 5.659
Epoch   7 Batch   42/575   train_loss = 4.609
Epoch   7 Batch   43/575   train_loss = 4.505
Epoch   7 Batch   44/575   train_loss = 4.397
Epoch   7 Batch   45/575   train_loss = 4.283
Epoch   7 Batch   46/575   train_loss = 4.292
Epoch   7 Batch   47/575   train_loss = 4.746
Epoch   7 Batch   48/575   train_loss = 3.895
Epoch   7 Batch   49/575   train_loss = 4.142
Epoch   7 Batch   50/575   train_loss = 4.382
Epoch   7 Batch   51/575   train_loss = 4.271
Epoch   7 Batch   52/575   train_loss = 4.270
Epoch   7 Batch   53/575   train_loss = 3.920
Epoch   7 Batch   54/575   train_loss = 4.415
Epoch   7 Batch   55/575   train_loss = 4.720
Epoch   7 Batch   56/575   train_loss = 4.124
Epoch   7 Batch   57/575   train_loss = 4.550
Epoch   7 Batch   58/575   train_loss = 4.109
Epoch   7 Batch   59/575   train_loss = 3.980
Epoch   7 Batch   60/575   train_loss = 4.536
Epoch   7 Batch   61/575   train_loss = 4.579
Epoch   7 Batch   62/575   train_loss = 4.023
Epoch   7 Batch   63/575   train_loss = 4.803
Epoch   7 Batch   64/575   train_loss = 4.742
Epoch   7 Batch   65/575   train_loss = 4.284
Epoch   7 Batch   66/575   train_loss = 4.250
Epoch   7 Batch   67/575   train_loss = 4.169
Epoch   7 Batch   68/575   train_loss = 4.183
Epoch   7 Batch   69/575   train_loss = 3.969
Epoch   7 Batch   70/575   train_loss = 4.386
Epoch   7 Batch   71/575   train_loss = 4.158
Epoch   7 Batch   72/575   train_loss = 4.714
Epoch   7 Batch   73/575   train_loss = 4.737
Epoch   7 Batch   74/575   train_loss = 4.863
Epoch   7 Batch   75/575   train_loss = 4.496
Epoch   7 Batch   76/575   train_loss = 4.784
Epoch   7 Batch   77/575   train_loss = 4.918
Epoch   7 Batch   78/575   train_loss = 4.625
Epoch   7 Batch   79/575   train_loss = 4.396
Epoch   7 Batch   80/575   train_loss = 4.386
Epoch   7 Batch   81/575   train_loss = 4.295
Epoch   7 Batch   82/575   train_loss = 4.083
Epoch   7 Batch   83/575   train_loss = 4.379
Epoch   7 Batch   84/575   train_loss = 4.362
Epoch   7 Batch   85/575   train_loss = 4.965
Epoch   7 Batch   86/575   train_loss = 4.320
Epoch   7 Batch   87/575   train_loss = 4.907
Epoch   7 Batch   88/575   train_loss = 3.786
Epoch   7 Batch   89/575   train_loss = 4.020
Epoch   7 Batch   90/575   train_loss = 4.188
Epoch   7 Batch   91/575   train_loss = 4.431
Epoch   7 Batch   92/575   train_loss = 4.959
Epoch   7 Batch   93/575   train_loss = 4.585
Epoch   7 Batch   94/575   train_loss = 4.111
Epoch   7 Batch   95/575   train_loss = 4.468
Epoch   7 Batch   96/575   train_loss = 4.490
Epoch   7 Batch   97/575   train_loss = 4.578
Epoch   7 Batch   98/575   train_loss = 4.357
Epoch   7 Batch   99/575   train_loss = 4.911
Epoch   7 Batch  100/575   train_loss = 4.642
Epoch   7 Batch  101/575   train_loss = 4.251
Epoch   7 Batch  102/575   train_loss = 4.102
Epoch   7 Batch  103/575   train_loss = 4.581
Epoch   7 Batch  104/575   train_loss = 4.446
Epoch   7 Batch  105/575   train_loss = 4.601
Epoch   7 Batch  106/575   train_loss = 4.242
Epoch   7 Batch  107/575   train_loss = 4.160
Epoch   7 Batch  108/575   train_loss = 4.578
Epoch   7 Batch  109/575   train_loss = 4.321
Epoch   7 Batch  110/575   train_loss = 3.454
Epoch   7 Batch  111/575   train_loss = 4.414
Epoch   7 Batch  112/575   train_loss = 4.470
Epoch   7 Batch  113/575   train_loss = 5.024
Epoch   7 Batch  114/575   train_loss = 4.722
Epoch   7 Batch  115/575   train_loss = 4.241
Epoch   7 Batch  116/575   train_loss = 4.660
Epoch   7 Batch  117/575   train_loss = 4.068
Epoch   7 Batch  118/575   train_loss = 4.470
Epoch   7 Batch  119/575   train_loss = 4.975
Epoch   7 Batch  120/575   train_loss = 4.559
Epoch   7 Batch  121/575   train_loss = 4.606
Epoch   7 Batch  122/575   train_loss = 4.649
Epoch   7 Batch  123/575   train_loss = 4.377
Epoch   7 Batch  124/575   train_loss = 4.795
Epoch   7 Batch  125/575   train_loss = 4.571
Epoch   7 Batch  126/575   train_loss = 4.445
Epoch   7 Batch  127/575   train_loss = 3.974
Epoch   7 Batch  128/575   train_loss = 4.475
Epoch   7 Batch  129/575   train_loss = 4.408
Epoch   7 Batch  130/575   train_loss = 4.692
Epoch   7 Batch  131/575   train_loss = 3.944
Epoch   7 Batch  132/575   train_loss = 4.305
Epoch   7 Batch  133/575   train_loss = 4.475
Epoch   7 Batch  134/575   train_loss = 4.358
Epoch   7 Batch  135/575   train_loss = 4.016
Epoch   7 Batch  136/575   train_loss = 5.297
Epoch   7 Batch  137/575   train_loss = 4.647
Epoch   7 Batch  138/575   train_loss = 4.964
Epoch   7 Batch  139/575   train_loss = 4.576
Epoch   7 Batch  140/575   train_loss = 4.563
Epoch   7 Batch  141/575   train_loss = 4.897
Epoch   7 Batch  142/575   train_loss = 5.017
Epoch   7 Batch  143/575   train_loss = 4.632
Epoch   7 Batch  144/575   train_loss = 4.219
Epoch   7 Batch  145/575   train_loss = 4.178
Epoch   7 Batch  146/575   train_loss = 4.186
Epoch   7 Batch  147/575   train_loss = 4.357
Epoch   7 Batch  148/575   train_loss = 3.879
Epoch   7 Batch  149/575   train_loss = 4.550
Epoch   7 Batch  150/575   train_loss = 4.795
Epoch   7 Batch  151/575   train_loss = 4.106
Epoch   7 Batch  152/575   train_loss = 4.062
Epoch   7 Batch  153/575   train_loss = 3.615
Epoch   7 Batch  154/575   train_loss = 3.798
Epoch   7 Batch  155/575   train_loss = 4.515
Epoch   7 Batch  156/575   train_loss = 4.394
Epoch   7 Batch  157/575   train_loss = 4.484
Epoch   7 Batch  158/575   train_loss = 4.468
Epoch   7 Batch  159/575   train_loss = 4.597
Epoch   7 Batch  160/575   train_loss = 4.209
Epoch   7 Batch  161/575   train_loss = 4.759
Epoch   7 Batch  162/575   train_loss = 4.603
Epoch   7 Batch  163/575   train_loss = 4.391
Epoch   7 Batch  164/575   train_loss = 4.699
Epoch   7 Batch  165/575   train_loss = 4.524
Epoch   7 Batch  166/575   train_loss = 4.162
Epoch   7 Batch  167/575   train_loss = 4.184
Epoch   7 Batch  168/575   train_loss = 4.588
Epoch   7 Batch  169/575   train_loss = 4.229
Epoch   7 Batch  170/575   train_loss = 4.661
Epoch   7 Batch  171/575   train_loss = 4.295
Epoch   7 Batch  172/575   train_loss = 4.505
Epoch   7 Batch  173/575   train_loss = 4.468
Epoch   7 Batch  174/575   train_loss = 4.714
Epoch   7 Batch  175/575   train_loss = 4.478
Epoch   7 Batch  176/575   train_loss = 4.569
Epoch   7 Batch  177/575   train_loss = 4.569
Epoch   7 Batch  178/575   train_loss = 4.419
Epoch   7 Batch  179/575   train_loss = 4.160
Epoch   7 Batch  180/575   train_loss = 4.255
Epoch   7 Batch  181/575   train_loss = 4.460
Epoch   7 Batch  182/575   train_loss = 4.286
Epoch   7 Batch  183/575   train_loss = 4.646
Epoch   7 Batch  184/575   train_loss = 3.812
Epoch   7 Batch  185/575   train_loss = 4.368
Epoch   7 Batch  186/575   train_loss = 4.518
Epoch   7 Batch  187/575   train_loss = 4.402
Epoch   7 Batch  188/575   train_loss = 4.359
Epoch   7 Batch  189/575   train_loss = 4.351
Epoch   7 Batch  190/575   train_loss = 4.395
Epoch   7 Batch  191/575   train_loss = 4.880
Epoch   7 Batch  192/575   train_loss = 4.692
Epoch   7 Batch  193/575   train_loss = 4.427
Epoch   7 Batch  194/575   train_loss = 4.554
Epoch   7 Batch  195/575   train_loss = 4.164
Epoch   7 Batch  196/575   train_loss = 4.256
Epoch   7 Batch  197/575   train_loss = 4.198
Epoch   7 Batch  198/575   train_loss = 4.696
Epoch   7 Batch  199/575   train_loss = 3.926
Epoch   7 Batch  200/575   train_loss = 4.192
Epoch   7 Batch  201/575   train_loss = 4.443
Epoch   7 Batch  202/575   train_loss = 4.125
Epoch   7 Batch  203/575   train_loss = 4.321
Epoch   7 Batch  204/575   train_loss = 4.266
Epoch   7 Batch  205/575   train_loss = 4.051
Epoch   7 Batch  206/575   train_loss = 4.343
Epoch   7 Batch  207/575   train_loss = 4.197
Epoch   7 Batch  208/575   train_loss = 4.064
Epoch   7 Batch  209/575   train_loss = 4.133
Epoch   7 Batch  210/575   train_loss = 4.512
Epoch   7 Batch  211/575   train_loss = 4.990
Epoch   7 Batch  212/575   train_loss = 4.645
Epoch   7 Batch  213/575   train_loss = 4.468
Epoch   7 Batch  214/575   train_loss = 4.162
Epoch   7 Batch  215/575   train_loss = 3.721
Epoch   7 Batch  216/575   train_loss = 4.122
Epoch   7 Batch  217/575   train_loss = 3.886
Epoch   7 Batch  218/575   train_loss = 4.561
Epoch   7 Batch  219/575   train_loss = 4.184
Epoch   7 Batch  220/575   train_loss = 3.833
Epoch   7 Batch  221/575   train_loss = 4.333
Epoch   7 Batch  222/575   train_loss = 4.443
Epoch   7 Batch  223/575   train_loss = 4.704
Epoch   7 Batch  224/575   train_loss = 4.025
Epoch   7 Batch  225/575   train_loss = 4.157
Epoch   7 Batch  226/575   train_loss = 4.522
Epoch   7 Batch  227/575   train_loss = 4.813
Epoch   7 Batch  228/575   train_loss = 4.625
Epoch   7 Batch  229/575   train_loss = 3.722
Epoch   7 Batch  230/575   train_loss = 3.888
Epoch   7 Batch  231/575   train_loss = 4.327
Epoch   7 Batch  232/575   train_loss = 4.491
Epoch   7 Batch  233/575   train_loss = 4.424
Epoch   7 Batch  234/575   train_loss = 4.554
Epoch   7 Batch  235/575   train_loss = 4.246
Epoch   7 Batch  236/575   train_loss = 3.808
Epoch   7 Batch  237/575   train_loss = 4.108
Epoch   7 Batch  238/575   train_loss = 4.121
Epoch   7 Batch  239/575   train_loss = 4.432
Epoch   7 Batch  240/575   train_loss = 4.649
Epoch   7 Batch  241/575   train_loss = 4.722
Epoch   7 Batch  242/575   train_loss = 4.264
Epoch   7 Batch  243/575   train_loss = 4.403
Epoch   7 Batch  244/575   train_loss = 4.295
Epoch   7 Batch  245/575   train_loss = 4.517
Epoch   7 Batch  246/575   train_loss = 4.715
Epoch   7 Batch  247/575   train_loss = 4.330
Epoch   7 Batch  248/575   train_loss = 4.522
Epoch   7 Batch  249/575   train_loss = 4.392
Epoch   7 Batch  250/575   train_loss = 4.284
Epoch   7 Batch  251/575   train_loss = 4.434
Epoch   7 Batch  252/575   train_loss = 4.747
Epoch   7 Batch  253/575   train_loss = 4.377
Epoch   7 Batch  254/575   train_loss = 4.001
Epoch   7 Batch  255/575   train_loss = 4.614
Epoch   7 Batch  256/575   train_loss = 4.273
Epoch   7 Batch  257/575   train_loss = 4.420
Epoch   7 Batch  258/575   train_loss = 4.788
Epoch   7 Batch  259/575   train_loss = 3.952
Epoch   7 Batch  260/575   train_loss = 4.176
Epoch   7 Batch  261/575   train_loss = 4.875
Epoch   7 Batch  262/575   train_loss = 4.610
Epoch   7 Batch  263/575   train_loss = 4.567
Epoch   7 Batch  264/575   train_loss = 3.772
Epoch   7 Batch  265/575   train_loss = 3.752
Epoch   7 Batch  266/575   train_loss = 3.876
Epoch   7 Batch  267/575   train_loss = 4.343
Epoch   7 Batch  268/575   train_loss = 4.346
Epoch   7 Batch  269/575   train_loss = 4.530
Epoch   7 Batch  270/575   train_loss = 4.918
Epoch   7 Batch  271/575   train_loss = 4.082
Epoch   7 Batch  272/575   train_loss = 4.580
Epoch   7 Batch  273/575   train_loss = 4.593
Epoch   7 Batch  274/575   train_loss = 4.565
Epoch   7 Batch  275/575   train_loss = 4.388
Epoch   7 Batch  276/575   train_loss = 4.948
Epoch   7 Batch  277/575   train_loss = 3.713
Epoch   7 Batch  278/575   train_loss = 4.484
Epoch   7 Batch  279/575   train_loss = 4.630
Epoch   7 Batch  280/575   train_loss = 4.651
Epoch   7 Batch  281/575   train_loss = 4.205
Epoch   7 Batch  282/575   train_loss = 4.515
Epoch   7 Batch  283/575   train_loss = 4.730
Epoch   7 Batch  284/575   train_loss = 4.888
Epoch   7 Batch  285/575   train_loss = 4.153
Epoch   7 Batch  286/575   train_loss = 4.455
Epoch   7 Batch  287/575   train_loss = 4.590
Epoch   7 Batch  288/575   train_loss = 4.347
Epoch   7 Batch  289/575   train_loss = 4.395
Epoch   7 Batch  290/575   train_loss = 4.440
Epoch   7 Batch  291/575   train_loss = 5.020
Epoch   7 Batch  292/575   train_loss = 4.933
Epoch   7 Batch  293/575   train_loss = 5.116
Epoch   7 Batch  294/575   train_loss = 4.742
Epoch   7 Batch  295/575   train_loss = 4.347
Epoch   7 Batch  296/575   train_loss = 4.521
Epoch   7 Batch  297/575   train_loss = 4.492
Epoch   7 Batch  298/575   train_loss = 4.644
Epoch   7 Batch  299/575   train_loss = 4.557
Epoch   7 Batch  300/575   train_loss = 4.455
Epoch   7 Batch  301/575   train_loss = 4.298
Epoch   7 Batch  302/575   train_loss = 4.682
Epoch   7 Batch  303/575   train_loss = 4.195
Epoch   7 Batch  304/575   train_loss = 4.298
Epoch   7 Batch  305/575   train_loss = 4.288
Epoch   7 Batch  306/575   train_loss = 4.543
Epoch   7 Batch  307/575   train_loss = 4.601
Epoch   7 Batch  308/575   train_loss = 4.476
Epoch   7 Batch  309/575   train_loss = 4.750
Epoch   7 Batch  310/575   train_loss = 4.807
Epoch   7 Batch  311/575   train_loss = 4.161
Epoch   7 Batch  312/575   train_loss = 4.508
Epoch   7 Batch  313/575   train_loss = 4.829
Epoch   7 Batch  314/575   train_loss = 4.802
Epoch   7 Batch  315/575   train_loss = 4.957
Epoch   7 Batch  316/575   train_loss = 4.367
Epoch   7 Batch  317/575   train_loss = 4.022
Epoch   7 Batch  318/575   train_loss = 3.749
Epoch   7 Batch  319/575   train_loss = 4.465
Epoch   7 Batch  320/575   train_loss = 4.315
Epoch   7 Batch  321/575   train_loss = 4.733
Epoch   7 Batch  322/575   train_loss = 4.379
Epoch   7 Batch  323/575   train_loss = 4.905
Epoch   7 Batch  324/575   train_loss = 4.353
Epoch   7 Batch  325/575   train_loss = 4.515
Epoch   7 Batch  326/575   train_loss = 4.272
Epoch   7 Batch  327/575   train_loss = 4.652
Epoch   7 Batch  328/575   train_loss = 4.255
Epoch   7 Batch  329/575   train_loss = 4.900
Epoch   7 Batch  330/575   train_loss = 4.509
Epoch   7 Batch  331/575   train_loss = 4.970
Epoch   7 Batch  332/575   train_loss = 4.568
Epoch   7 Batch  333/575   train_loss = 4.536
Epoch   7 Batch  334/575   train_loss = 4.433
Epoch   7 Batch  335/575   train_loss = 4.162
Epoch   7 Batch  336/575   train_loss = 4.547
Epoch   7 Batch  337/575   train_loss = 4.372
Epoch   7 Batch  338/575   train_loss = 4.200
Epoch   7 Batch  339/575   train_loss = 4.519
Epoch   7 Batch  340/575   train_loss = 4.325
Epoch   7 Batch  341/575   train_loss = 4.339
Epoch   7 Batch  342/575   train_loss = 4.187
Epoch   7 Batch  343/575   train_loss = 4.671
Epoch   7 Batch  344/575   train_loss = 4.708
Epoch   7 Batch  345/575   train_loss = 4.301
Epoch   7 Batch  346/575   train_loss = 4.969
Epoch   7 Batch  347/575   train_loss = 4.170
Epoch   7 Batch  348/575   train_loss = 4.199
Epoch   7 Batch  349/575   train_loss = 3.984
Epoch   7 Batch  350/575   train_loss = 4.552
Epoch   7 Batch  351/575   train_loss = 4.903
Epoch   7 Batch  352/575   train_loss = 4.761
Epoch   7 Batch  353/575   train_loss = 4.608
Epoch   7 Batch  354/575   train_loss = 4.218
Epoch   7 Batch  355/575   train_loss = 4.840
Epoch   7 Batch  356/575   train_loss = 4.639
Epoch   7 Batch  357/575   train_loss = 4.641
Epoch   7 Batch  358/575   train_loss = 4.746
Epoch   7 Batch  359/575   train_loss = 4.927
Epoch   7 Batch  360/575   train_loss = 4.059
Epoch   7 Batch  361/575   train_loss = 4.603
Epoch   7 Batch  362/575   train_loss = 4.394
Epoch   7 Batch  363/575   train_loss = 4.507
Epoch   7 Batch  364/575   train_loss = 4.237
Epoch   7 Batch  365/575   train_loss = 4.581
Epoch   7 Batch  366/575   train_loss = 4.019
Epoch   7 Batch  367/575   train_loss = 4.290
Epoch   7 Batch  368/575   train_loss = 5.068
Epoch   7 Batch  369/575   train_loss = 4.772
Epoch   7 Batch  370/575   train_loss = 4.625
Epoch   7 Batch  371/575   train_loss = 4.639
Epoch   7 Batch  372/575   train_loss = 4.276
Epoch   7 Batch  373/575   train_loss = 4.720
Epoch   7 Batch  374/575   train_loss = 3.880
Epoch   7 Batch  375/575   train_loss = 4.265
Epoch   7 Batch  376/575   train_loss = 4.581
Epoch   7 Batch  377/575   train_loss = 4.882
Epoch   7 Batch  378/575   train_loss = 4.996
Epoch   7 Batch  379/575   train_loss = 4.385
Epoch   7 Batch  380/575   train_loss = 4.060
Epoch   7 Batch  381/575   train_loss = 4.246
Epoch   7 Batch  382/575   train_loss = 4.519
Epoch   7 Batch  383/575   train_loss = 4.324
Epoch   7 Batch  384/575   train_loss = 4.488
Epoch   7 Batch  385/575   train_loss = 4.367
Epoch   7 Batch  386/575   train_loss = 4.273
Epoch   7 Batch  387/575   train_loss = 4.889
Epoch   7 Batch  388/575   train_loss = 4.476
Epoch   7 Batch  389/575   train_loss = 4.381
Epoch   7 Batch  390/575   train_loss = 4.609
Epoch   7 Batch  391/575   train_loss = 4.626
Epoch   7 Batch  392/575   train_loss = 4.578
Epoch   7 Batch  393/575   train_loss = 4.572
Epoch   7 Batch  394/575   train_loss = 4.759
Epoch   7 Batch  395/575   train_loss = 3.898
Epoch   7 Batch  396/575   train_loss = 4.141
Epoch   7 Batch  397/575   train_loss = 4.542
Epoch   7 Batch  398/575   train_loss = 4.995
Epoch   7 Batch  399/575   train_loss = 4.893
Epoch   7 Batch  400/575   train_loss = 4.718
Epoch   7 Batch  401/575   train_loss = 4.150
Epoch   7 Batch  402/575   train_loss = 4.231
Epoch   7 Batch  403/575   train_loss = 4.649
Epoch   7 Batch  404/575   train_loss = 4.579
Epoch   7 Batch  405/575   train_loss = 4.662
Epoch   7 Batch  406/575   train_loss = 4.194
Epoch   7 Batch  407/575   train_loss = 4.567
Epoch   7 Batch  408/575   train_loss = 4.377
Epoch   7 Batch  409/575   train_loss = 4.475
Epoch   7 Batch  410/575   train_loss = 4.216
Epoch   7 Batch  411/575   train_loss = 4.610
Epoch   7 Batch  412/575   train_loss = 5.055
Epoch   7 Batch  413/575   train_loss = 4.647
Epoch   7 Batch  414/575   train_loss = 4.305
Epoch   7 Batch  415/575   train_loss = 4.778
Epoch   7 Batch  416/575   train_loss = 4.372
Epoch   7 Batch  417/575   train_loss = 4.108
Epoch   7 Batch  418/575   train_loss = 4.542
Epoch   7 Batch  419/575   train_loss = 4.386
Epoch   7 Batch  420/575   train_loss = 4.260
Epoch   7 Batch  421/575   train_loss = 4.891
Epoch   7 Batch  422/575   train_loss = 4.663
Epoch   7 Batch  423/575   train_loss = 4.957
Epoch   7 Batch  424/575   train_loss = 4.956
Epoch   7 Batch  425/575   train_loss = 4.596
Epoch   7 Batch  426/575   train_loss = 4.586
Epoch   7 Batch  427/575   train_loss = 4.515
Epoch   7 Batch  428/575   train_loss = 4.327
Epoch   7 Batch  429/575   train_loss = 4.280
Epoch   7 Batch  430/575   train_loss = 4.568
Epoch   7 Batch  431/575   train_loss = 4.436
Epoch   7 Batch  432/575   train_loss = 4.801
Epoch   7 Batch  433/575   train_loss = 4.757
Epoch   7 Batch  434/575   train_loss = 4.644
Epoch   7 Batch  435/575   train_loss = 4.402
Epoch   7 Batch  436/575   train_loss = 4.295
Epoch   7 Batch  437/575   train_loss = 4.406
Epoch   7 Batch  438/575   train_loss = 4.652
Epoch   7 Batch  439/575   train_loss = 4.583
Epoch   7 Batch  440/575   train_loss = 4.808
Epoch   7 Batch  441/575   train_loss = 4.407
Epoch   7 Batch  442/575   train_loss = 4.720
Epoch   7 Batch  443/575   train_loss = 4.575
Epoch   7 Batch  444/575   train_loss = 4.650
Epoch   7 Batch  445/575   train_loss = 4.180
Epoch   7 Batch  446/575   train_loss = 4.190
Epoch   7 Batch  447/575   train_loss = 4.675
Epoch   7 Batch  448/575   train_loss = 4.603
Epoch   7 Batch  449/575   train_loss = 4.487
Epoch   7 Batch  450/575   train_loss = 4.945
Epoch   7 Batch  451/575   train_loss = 4.952
Epoch   7 Batch  452/575   train_loss = 4.978
Epoch   7 Batch  453/575   train_loss = 4.575
Epoch   7 Batch  454/575   train_loss = 4.951
Epoch   7 Batch  455/575   train_loss = 4.239
Epoch   7 Batch  456/575   train_loss = 4.803
Epoch   7 Batch  457/575   train_loss = 4.114
Epoch   7 Batch  458/575   train_loss = 4.860
Epoch   7 Batch  459/575   train_loss = 4.540
Epoch   7 Batch  460/575   train_loss = 4.303
Epoch   7 Batch  461/575   train_loss = 4.480
Epoch   7 Batch  462/575   train_loss = 4.444
Epoch   7 Batch  463/575   train_loss = 4.304
Epoch   7 Batch  464/575   train_loss = 4.285
Epoch   7 Batch  465/575   train_loss = 4.433
Epoch   7 Batch  466/575   train_loss = 4.390
Epoch   7 Batch  467/575   train_loss = 3.813
Epoch   7 Batch  468/575   train_loss = 4.387
Epoch   7 Batch  469/575   train_loss = 4.825
Epoch   7 Batch  470/575   train_loss = 4.964
Epoch   7 Batch  471/575   train_loss = 4.297
Epoch   7 Batch  472/575   train_loss = 4.758
Epoch   7 Batch  473/575   train_loss = 4.600
Epoch   7 Batch  474/575   train_loss = 4.625
Epoch   7 Batch  475/575   train_loss = 4.292
Epoch   7 Batch  476/575   train_loss = 4.435
Epoch   7 Batch  477/575   train_loss = 5.014
Epoch   7 Batch  478/575   train_loss = 5.044
Epoch   7 Batch  479/575   train_loss = 4.335
Epoch   7 Batch  480/575   train_loss = 4.586
Epoch   7 Batch  481/575   train_loss = 4.714
Epoch   7 Batch  482/575   train_loss = 4.114
Epoch   7 Batch  483/575   train_loss = 5.202
Epoch   7 Batch  484/575   train_loss = 4.407
Epoch   7 Batch  485/575   train_loss = 5.057
Epoch   7 Batch  486/575   train_loss = 4.527
Epoch   7 Batch  487/575   train_loss = 4.835
Epoch   7 Batch  488/575   train_loss = 4.544
Epoch   7 Batch  489/575   train_loss = 4.701
Epoch   7 Batch  490/575   train_loss = 4.693
Epoch   7 Batch  491/575   train_loss = 4.065
Epoch   7 Batch  492/575   train_loss = 4.061
Epoch   7 Batch  493/575   train_loss = 4.115
Epoch   7 Batch  494/575   train_loss = 4.438
Epoch   7 Batch  495/575   train_loss = 4.440
Epoch   7 Batch  496/575   train_loss = 4.580
Epoch   7 Batch  497/575   train_loss = 4.696
Epoch   7 Batch  498/575   train_loss = 4.325
Epoch   7 Batch  499/575   train_loss = 4.283
Epoch   7 Batch  500/575   train_loss = 4.635
Epoch   7 Batch  501/575   train_loss = 4.607
Epoch   7 Batch  502/575   train_loss = 3.941
Epoch   7 Batch  503/575   train_loss = 4.849
Epoch   7 Batch  504/575   train_loss = 3.967
Epoch   7 Batch  505/575   train_loss = 4.449
Epoch   7 Batch  506/575   train_loss = 4.683
Epoch   7 Batch  507/575   train_loss = 4.811
Epoch   7 Batch  508/575   train_loss = 4.831
Epoch   7 Batch  509/575   train_loss = 4.543
Epoch   7 Batch  510/575   train_loss = 3.929
Epoch   7 Batch  511/575   train_loss = 4.045
Epoch   7 Batch  512/575   train_loss = 4.841
Epoch   7 Batch  513/575   train_loss = 4.548
Epoch   7 Batch  514/575   train_loss = 4.457
Epoch   7 Batch  515/575   train_loss = 4.497
Epoch   7 Batch  516/575   train_loss = 4.821
Epoch   7 Batch  517/575   train_loss = 4.031
Epoch   7 Batch  518/575   train_loss = 4.226
Epoch   7 Batch  519/575   train_loss = 4.417
Epoch   7 Batch  520/575   train_loss = 3.860
Epoch   7 Batch  521/575   train_loss = 4.175
Epoch   7 Batch  522/575   train_loss = 4.300
Epoch   7 Batch  523/575   train_loss = 4.764
Epoch   7 Batch  524/575   train_loss = 5.359
Epoch   7 Batch  525/575   train_loss = 4.716
Epoch   7 Batch  526/575   train_loss = 4.201
Epoch   7 Batch  527/575   train_loss = 4.768
Epoch   7 Batch  528/575   train_loss = 4.279
Epoch   7 Batch  529/575   train_loss = 4.802
Epoch   7 Batch  530/575   train_loss = 4.575
Epoch   7 Batch  531/575   train_loss = 4.682
Epoch   7 Batch  532/575   train_loss = 4.275
Epoch   7 Batch  533/575   train_loss = 4.196
Epoch   7 Batch  534/575   train_loss = 4.254
Epoch   7 Batch  535/575   train_loss = 4.526
Epoch   7 Batch  536/575   train_loss = 4.326
Epoch   7 Batch  537/575   train_loss = 4.181
Epoch   7 Batch  538/575   train_loss = 4.422
Epoch   7 Batch  539/575   train_loss = 4.299
Epoch   7 Batch  540/575   train_loss = 4.564
Epoch   7 Batch  541/575   train_loss = 4.975
Epoch   7 Batch  542/575   train_loss = 4.499
Epoch   7 Batch  543/575   train_loss = 4.642
Epoch   7 Batch  544/575   train_loss = 4.436
Epoch   7 Batch  545/575   train_loss = 4.454
Epoch   7 Batch  546/575   train_loss = 4.477
Epoch   7 Batch  547/575   train_loss = 4.496
Epoch   7 Batch  548/575   train_loss = 4.604
Epoch   7 Batch  549/575   train_loss = 4.399
Epoch   7 Batch  550/575   train_loss = 4.332
Epoch   7 Batch  551/575   train_loss = 4.229
Epoch   7 Batch  552/575   train_loss = 4.482
Epoch   7 Batch  553/575   train_loss = 4.754
Epoch   7 Batch  554/575   train_loss = 4.153
Epoch   7 Batch  555/575   train_loss = 4.389
Epoch   7 Batch  556/575   train_loss = 4.200
Epoch   7 Batch  557/575   train_loss = 4.182
Epoch   7 Batch  558/575   train_loss = 4.474
Epoch   7 Batch  559/575   train_loss = 4.642
Epoch   7 Batch  560/575   train_loss = 4.072
Epoch   7 Batch  561/575   train_loss = 4.437
Epoch   7 Batch  562/575   train_loss = 3.982
Epoch   7 Batch  563/575   train_loss = 4.375
Epoch   7 Batch  564/575   train_loss = 4.106
Epoch   7 Batch  565/575   train_loss = 3.640
Epoch   7 Batch  566/575   train_loss = 4.124
Epoch   7 Batch  567/575   train_loss = 4.219
Epoch   7 Batch  568/575   train_loss = 4.283
Epoch   7 Batch  569/575   train_loss = 4.516
Epoch   7 Batch  570/575   train_loss = 4.097
Epoch   7 Batch  571/575   train_loss = 3.898
Epoch   7 Batch  572/575   train_loss = 3.673
Epoch   7 Batch  573/575   train_loss = 4.045
Epoch   7 Batch  574/575   train_loss = 4.585
Epoch   8 Batch    0/575   train_loss = 4.297
Epoch   8 Batch    1/575   train_loss = 4.296
Epoch   8 Batch    2/575   train_loss = 4.447
Epoch   8 Batch    3/575   train_loss = 4.240
Epoch   8 Batch    4/575   train_loss = 4.181
Epoch   8 Batch    5/575   train_loss = 4.168
Epoch   8 Batch    6/575   train_loss = 4.010
Epoch   8 Batch    7/575   train_loss = 4.328
Epoch   8 Batch    8/575   train_loss = 4.250
Epoch   8 Batch    9/575   train_loss = 4.534
Epoch   8 Batch   10/575   train_loss = 4.040
Epoch   8 Batch   11/575   train_loss = 4.099
Epoch   8 Batch   12/575   train_loss = 4.305
Epoch   8 Batch   13/575   train_loss = 4.435
Epoch   8 Batch   14/575   train_loss = 4.819
Epoch   8 Batch   15/575   train_loss = 4.521
Epoch   8 Batch   16/575   train_loss = 4.389
Epoch   8 Batch   17/575   train_loss = 3.788
Epoch   8 Batch   18/575   train_loss = 4.730
Epoch   8 Batch   19/575   train_loss = 4.430
Epoch   8 Batch   20/575   train_loss = 3.800
Epoch   8 Batch   21/575   train_loss = 4.319
Epoch   8 Batch   22/575   train_loss = 4.818
Epoch   8 Batch   23/575   train_loss = 4.384
Epoch   8 Batch   24/575   train_loss = 4.302
Epoch   8 Batch   25/575   train_loss = 4.442
Epoch   8 Batch   26/575   train_loss = 4.683
Epoch   8 Batch   27/575   train_loss = 4.368
Epoch   8 Batch   28/575   train_loss = 3.927
Epoch   8 Batch   29/575   train_loss = 4.121
Epoch   8 Batch   30/575   train_loss = 4.808
Epoch   8 Batch   31/575   train_loss = 5.094
Epoch   8 Batch   32/575   train_loss = 4.441
Epoch   8 Batch   33/575   train_loss = 4.724
Epoch   8 Batch   34/575   train_loss = 4.393
Epoch   8 Batch   35/575   train_loss = 4.109
Epoch   8 Batch   36/575   train_loss = 4.679
Epoch   8 Batch   37/575   train_loss = 3.796
Epoch   8 Batch   38/575   train_loss = 4.518
Epoch   8 Batch   39/575   train_loss = 3.855
Epoch   8 Batch   40/575   train_loss = 3.742
Epoch   8 Batch   41/575   train_loss = 5.447
Epoch   8 Batch   42/575   train_loss = 4.499
Epoch   8 Batch   43/575   train_loss = 4.390
Epoch   8 Batch   44/575   train_loss = 4.259
Epoch   8 Batch   45/575   train_loss = 4.175
Epoch   8 Batch   46/575   train_loss = 4.156
Epoch   8 Batch   47/575   train_loss = 4.670
Epoch   8 Batch   48/575   train_loss = 3.806
Epoch   8 Batch   49/575   train_loss = 4.057
Epoch   8 Batch   50/575   train_loss = 4.285
Epoch   8 Batch   51/575   train_loss = 4.174
Epoch   8 Batch   52/575   train_loss = 4.168
Epoch   8 Batch   53/575   train_loss = 3.818
Epoch   8 Batch   54/575   train_loss = 4.283
Epoch   8 Batch   55/575   train_loss = 4.609
Epoch   8 Batch   56/575   train_loss = 4.001
Epoch   8 Batch   57/575   train_loss = 4.468
Epoch   8 Batch   58/575   train_loss = 3.983
Epoch   8 Batch   59/575   train_loss = 3.880
Epoch   8 Batch   60/575   train_loss = 4.380
Epoch   8 Batch   61/575   train_loss = 4.477
Epoch   8 Batch   62/575   train_loss = 3.896
Epoch   8 Batch   63/575   train_loss = 4.661
Epoch   8 Batch   64/575   train_loss = 4.615
Epoch   8 Batch   65/575   train_loss = 4.194
Epoch   8 Batch   66/575   train_loss = 4.149
Epoch   8 Batch   67/575   train_loss = 4.085
Epoch   8 Batch   68/575   train_loss = 4.081
Epoch   8 Batch   69/575   train_loss = 3.871
Epoch   8 Batch   70/575   train_loss = 4.270
Epoch   8 Batch   71/575   train_loss = 4.046
Epoch   8 Batch   72/575   train_loss = 4.589
Epoch   8 Batch   73/575   train_loss = 4.631
Epoch   8 Batch   74/575   train_loss = 4.713
Epoch   8 Batch   75/575   train_loss = 4.411
Epoch   8 Batch   76/575   train_loss = 4.629
Epoch   8 Batch   77/575   train_loss = 4.813
Epoch   8 Batch   78/575   train_loss = 4.505
Epoch   8 Batch   79/575   train_loss = 4.295
Epoch   8 Batch   80/575   train_loss = 4.290
Epoch   8 Batch   81/575   train_loss = 4.158
Epoch   8 Batch   82/575   train_loss = 3.986
Epoch   8 Batch   83/575   train_loss = 4.261
Epoch   8 Batch   84/575   train_loss = 4.250
Epoch   8 Batch   85/575   train_loss = 4.826
Epoch   8 Batch   86/575   train_loss = 4.187
Epoch   8 Batch   87/575   train_loss = 4.772
Epoch   8 Batch   88/575   train_loss = 3.700
Epoch   8 Batch   89/575   train_loss = 3.907
Epoch   8 Batch   90/575   train_loss = 4.065
Epoch   8 Batch   91/575   train_loss = 4.307
Epoch   8 Batch   92/575   train_loss = 4.801
Epoch   8 Batch   93/575   train_loss = 4.488
Epoch   8 Batch   94/575   train_loss = 3.993
Epoch   8 Batch   95/575   train_loss = 4.336
Epoch   8 Batch   96/575   train_loss = 4.355
Epoch   8 Batch   97/575   train_loss = 4.432
Epoch   8 Batch   98/575   train_loss = 4.244
Epoch   8 Batch   99/575   train_loss = 4.765
Epoch   8 Batch  100/575   train_loss = 4.517
Epoch   8 Batch  101/575   train_loss = 4.130
Epoch   8 Batch  102/575   train_loss = 3.999
Epoch   8 Batch  103/575   train_loss = 4.419
Epoch   8 Batch  104/575   train_loss = 4.331
Epoch   8 Batch  105/575   train_loss = 4.471
Epoch   8 Batch  106/575   train_loss = 4.112
Epoch   8 Batch  107/575   train_loss = 4.059
Epoch   8 Batch  108/575   train_loss = 4.445
Epoch   8 Batch  109/575   train_loss = 4.185
Epoch   8 Batch  110/575   train_loss = 3.354
Epoch   8 Batch  111/575   train_loss = 4.321
Epoch   8 Batch  112/575   train_loss = 4.339
Epoch   8 Batch  113/575   train_loss = 4.883
Epoch   8 Batch  114/575   train_loss = 4.565
Epoch   8 Batch  115/575   train_loss = 4.125
Epoch   8 Batch  116/575   train_loss = 4.543
Epoch   8 Batch  117/575   train_loss = 3.952
Epoch   8 Batch  118/575   train_loss = 4.319
Epoch   8 Batch  119/575   train_loss = 4.831
Epoch   8 Batch  120/575   train_loss = 4.432
Epoch   8 Batch  121/575   train_loss = 4.444
Epoch   8 Batch  122/575   train_loss = 4.553
Epoch   8 Batch  123/575   train_loss = 4.254
Epoch   8 Batch  124/575   train_loss = 4.629
Epoch   8 Batch  125/575   train_loss = 4.409
Epoch   8 Batch  126/575   train_loss = 4.285
Epoch   8 Batch  127/575   train_loss = 3.859
Epoch   8 Batch  128/575   train_loss = 4.369
Epoch   8 Batch  129/575   train_loss = 4.290
Epoch   8 Batch  130/575   train_loss = 4.582
Epoch   8 Batch  131/575   train_loss = 3.797
Epoch   8 Batch  132/575   train_loss = 4.200
Epoch   8 Batch  133/575   train_loss = 4.365
Epoch   8 Batch  134/575   train_loss = 4.262
Epoch   8 Batch  135/575   train_loss = 3.884
Epoch   8 Batch  136/575   train_loss = 5.112
Epoch   8 Batch  137/575   train_loss = 4.559
Epoch   8 Batch  138/575   train_loss = 4.844
Epoch   8 Batch  139/575   train_loss = 4.429
Epoch   8 Batch  140/575   train_loss = 4.421
Epoch   8 Batch  141/575   train_loss = 4.737
Epoch   8 Batch  142/575   train_loss = 4.813
Epoch   8 Batch  143/575   train_loss = 4.508
Epoch   8 Batch  144/575   train_loss = 4.104
Epoch   8 Batch  145/575   train_loss = 4.044
Epoch   8 Batch  146/575   train_loss = 4.085
Epoch   8 Batch  147/575   train_loss = 4.239
Epoch   8 Batch  148/575   train_loss = 3.783
Epoch   8 Batch  149/575   train_loss = 4.442
Epoch   8 Batch  150/575   train_loss = 4.660
Epoch   8 Batch  151/575   train_loss = 4.021
Epoch   8 Batch  152/575   train_loss = 3.957
Epoch   8 Batch  153/575   train_loss = 3.523
Epoch   8 Batch  154/575   train_loss = 3.704
Epoch   8 Batch  155/575   train_loss = 4.390
Epoch   8 Batch  156/575   train_loss = 4.314
Epoch   8 Batch  157/575   train_loss = 4.346
Epoch   8 Batch  158/575   train_loss = 4.376
Epoch   8 Batch  159/575   train_loss = 4.468
Epoch   8 Batch  160/575   train_loss = 4.124
Epoch   8 Batch  161/575   train_loss = 4.605
Epoch   8 Batch  162/575   train_loss = 4.462
Epoch   8 Batch  163/575   train_loss = 4.293
Epoch   8 Batch  164/575   train_loss = 4.596
Epoch   8 Batch  165/575   train_loss = 4.406
Epoch   8 Batch  166/575   train_loss = 4.080
Epoch   8 Batch  167/575   train_loss = 4.066
Epoch   8 Batch  168/575   train_loss = 4.439
Epoch   8 Batch  169/575   train_loss = 4.137
Epoch   8 Batch  170/575   train_loss = 4.492
Epoch   8 Batch  171/575   train_loss = 4.197
Epoch   8 Batch  172/575   train_loss = 4.382
Epoch   8 Batch  173/575   train_loss = 4.339
Epoch   8 Batch  174/575   train_loss = 4.568
Epoch   8 Batch  175/575   train_loss = 4.350
Epoch   8 Batch  176/575   train_loss = 4.430
Epoch   8 Batch  177/575   train_loss = 4.397
Epoch   8 Batch  178/575   train_loss = 4.302
Epoch   8 Batch  179/575   train_loss = 4.026
Epoch   8 Batch  180/575   train_loss = 4.129
Epoch   8 Batch  181/575   train_loss = 4.335
Epoch   8 Batch  182/575   train_loss = 4.188
Epoch   8 Batch  183/575   train_loss = 4.489
Epoch   8 Batch  184/575   train_loss = 3.677
Epoch   8 Batch  185/575   train_loss = 4.253
Epoch   8 Batch  186/575   train_loss = 4.359
Epoch   8 Batch  187/575   train_loss = 4.286
Epoch   8 Batch  188/575   train_loss = 4.209
Epoch   8 Batch  189/575   train_loss = 4.260
Epoch   8 Batch  190/575   train_loss = 4.209
Epoch   8 Batch  191/575   train_loss = 4.745
Epoch   8 Batch  192/575   train_loss = 4.526
Epoch   8 Batch  193/575   train_loss = 4.321
Epoch   8 Batch  194/575   train_loss = 4.434
Epoch   8 Batch  195/575   train_loss = 4.035
Epoch   8 Batch  196/575   train_loss = 4.154
Epoch   8 Batch  197/575   train_loss = 4.076
Epoch   8 Batch  198/575   train_loss = 4.555
Epoch   8 Batch  199/575   train_loss = 3.818
Epoch   8 Batch  200/575   train_loss = 4.107
Epoch   8 Batch  201/575   train_loss = 4.324
Epoch   8 Batch  202/575   train_loss = 4.037
Epoch   8 Batch  203/575   train_loss = 4.236
Epoch   8 Batch  204/575   train_loss = 4.144
Epoch   8 Batch  205/575   train_loss = 3.939
Epoch   8 Batch  206/575   train_loss = 4.199
Epoch   8 Batch  207/575   train_loss = 4.085
Epoch   8 Batch  208/575   train_loss = 3.975
Epoch   8 Batch  209/575   train_loss = 4.054
Epoch   8 Batch  210/575   train_loss = 4.410
Epoch   8 Batch  211/575   train_loss = 4.828
Epoch   8 Batch  212/575   train_loss = 4.506
Epoch   8 Batch  213/575   train_loss = 4.345
Epoch   8 Batch  214/575   train_loss = 4.051
Epoch   8 Batch  215/575   train_loss = 3.634
Epoch   8 Batch  216/575   train_loss = 3.979
Epoch   8 Batch  217/575   train_loss = 3.750
Epoch   8 Batch  218/575   train_loss = 4.423
Epoch   8 Batch  219/575   train_loss = 4.027
Epoch   8 Batch  220/575   train_loss = 3.717
Epoch   8 Batch  221/575   train_loss = 4.202
Epoch   8 Batch  222/575   train_loss = 4.299
Epoch   8 Batch  223/575   train_loss = 4.568
Epoch   8 Batch  224/575   train_loss = 3.902
Epoch   8 Batch  225/575   train_loss = 4.014
Epoch   8 Batch  226/575   train_loss = 4.400
Epoch   8 Batch  227/575   train_loss = 4.683
Epoch   8 Batch  228/575   train_loss = 4.493
Epoch   8 Batch  229/575   train_loss = 3.654
Epoch   8 Batch  230/575   train_loss = 3.782
Epoch   8 Batch  231/575   train_loss = 4.244
Epoch   8 Batch  232/575   train_loss = 4.412
Epoch   8 Batch  233/575   train_loss = 4.301
Epoch   8 Batch  234/575   train_loss = 4.422
Epoch   8 Batch  235/575   train_loss = 4.176
Epoch   8 Batch  236/575   train_loss = 3.708
Epoch   8 Batch  237/575   train_loss = 3.969
Epoch   8 Batch  238/575   train_loss = 4.000
Epoch   8 Batch  239/575   train_loss = 4.304
Epoch   8 Batch  240/575   train_loss = 4.515
Epoch   8 Batch  241/575   train_loss = 4.579
Epoch   8 Batch  242/575   train_loss = 4.169
Epoch   8 Batch  243/575   train_loss = 4.268
Epoch   8 Batch  244/575   train_loss = 4.170
Epoch   8 Batch  245/575   train_loss = 4.374
Epoch   8 Batch  246/575   train_loss = 4.580
Epoch   8 Batch  247/575   train_loss = 4.259
Epoch   8 Batch  248/575   train_loss = 4.380
Epoch   8 Batch  249/575   train_loss = 4.248
Epoch   8 Batch  250/575   train_loss = 4.171
Epoch   8 Batch  251/575   train_loss = 4.277
Epoch   8 Batch  252/575   train_loss = 4.641
Epoch   8 Batch  253/575   train_loss = 4.270
Epoch   8 Batch  254/575   train_loss = 3.914
Epoch   8 Batch  255/575   train_loss = 4.486
Epoch   8 Batch  256/575   train_loss = 4.142
Epoch   8 Batch  257/575   train_loss = 4.290
Epoch   8 Batch  258/575   train_loss = 4.654
Epoch   8 Batch  259/575   train_loss = 3.811
Epoch   8 Batch  260/575   train_loss = 4.072
Epoch   8 Batch  261/575   train_loss = 4.706
Epoch   8 Batch  262/575   train_loss = 4.475
Epoch   8 Batch  263/575   train_loss = 4.440
Epoch   8 Batch  264/575   train_loss = 3.655
Epoch   8 Batch  265/575   train_loss = 3.647
Epoch   8 Batch  266/575   train_loss = 3.774
Epoch   8 Batch  267/575   train_loss = 4.249
Epoch   8 Batch  268/575   train_loss = 4.220
Epoch   8 Batch  269/575   train_loss = 4.416
Epoch   8 Batch  270/575   train_loss = 4.787
Epoch   8 Batch  271/575   train_loss = 3.955
Epoch   8 Batch  272/575   train_loss = 4.484
Epoch   8 Batch  273/575   train_loss = 4.489
Epoch   8 Batch  274/575   train_loss = 4.454
Epoch   8 Batch  275/575   train_loss = 4.255
Epoch   8 Batch  276/575   train_loss = 4.809
Epoch   8 Batch  277/575   train_loss = 3.607
Epoch   8 Batch  278/575   train_loss = 4.382
Epoch   8 Batch  279/575   train_loss = 4.523
Epoch   8 Batch  280/575   train_loss = 4.513
Epoch   8 Batch  281/575   train_loss = 4.124
Epoch   8 Batch  282/575   train_loss = 4.417
Epoch   8 Batch  283/575   train_loss = 4.631
Epoch   8 Batch  284/575   train_loss = 4.764
Epoch   8 Batch  285/575   train_loss = 4.011
Epoch   8 Batch  286/575   train_loss = 4.333
Epoch   8 Batch  287/575   train_loss = 4.449
Epoch   8 Batch  288/575   train_loss = 4.239
Epoch   8 Batch  289/575   train_loss = 4.303
Epoch   8 Batch  290/575   train_loss = 4.312
Epoch   8 Batch  291/575   train_loss = 4.862
Epoch   8 Batch  292/575   train_loss = 4.826
Epoch   8 Batch  293/575   train_loss = 4.972
Epoch   8 Batch  294/575   train_loss = 4.590
Epoch   8 Batch  295/575   train_loss = 4.251
Epoch   8 Batch  296/575   train_loss = 4.435
Epoch   8 Batch  297/575   train_loss = 4.336
Epoch   8 Batch  298/575   train_loss = 4.544
Epoch   8 Batch  299/575   train_loss = 4.457
Epoch   8 Batch  300/575   train_loss = 4.365
Epoch   8 Batch  301/575   train_loss = 4.175
Epoch   8 Batch  302/575   train_loss = 4.555
Epoch   8 Batch  303/575   train_loss = 4.128
Epoch   8 Batch  304/575   train_loss = 4.187
Epoch   8 Batch  305/575   train_loss = 4.175
Epoch   8 Batch  306/575   train_loss = 4.425
Epoch   8 Batch  307/575   train_loss = 4.459
Epoch   8 Batch  308/575   train_loss = 4.330
Epoch   8 Batch  309/575   train_loss = 4.614
Epoch   8 Batch  310/575   train_loss = 4.691
Epoch   8 Batch  311/575   train_loss = 4.068
Epoch   8 Batch  312/575   train_loss = 4.374
Epoch   8 Batch  313/575   train_loss = 4.689
Epoch   8 Batch  314/575   train_loss = 4.654
Epoch   8 Batch  315/575   train_loss = 4.807
Epoch   8 Batch  316/575   train_loss = 4.236
Epoch   8 Batch  317/575   train_loss = 3.934
Epoch   8 Batch  318/575   train_loss = 3.675
Epoch   8 Batch  319/575   train_loss = 4.362
Epoch   8 Batch  320/575   train_loss = 4.222
Epoch   8 Batch  321/575   train_loss = 4.575
Epoch   8 Batch  322/575   train_loss = 4.268
Epoch   8 Batch  323/575   train_loss = 4.809
Epoch   8 Batch  324/575   train_loss = 4.257
Epoch   8 Batch  325/575   train_loss = 4.409
Epoch   8 Batch  326/575   train_loss = 4.179
Epoch   8 Batch  327/575   train_loss = 4.524
Epoch   8 Batch  328/575   train_loss = 4.103
Epoch   8 Batch  329/575   train_loss = 4.790
Epoch   8 Batch  330/575   train_loss = 4.400
Epoch   8 Batch  331/575   train_loss = 4.811
Epoch   8 Batch  332/575   train_loss = 4.422
Epoch   8 Batch  333/575   train_loss = 4.394
Epoch   8 Batch  334/575   train_loss = 4.341
Epoch   8 Batch  335/575   train_loss = 4.065
Epoch   8 Batch  336/575   train_loss = 4.427
Epoch   8 Batch  337/575   train_loss = 4.245
Epoch   8 Batch  338/575   train_loss = 4.068
Epoch   8 Batch  339/575   train_loss = 4.415
Epoch   8 Batch  340/575   train_loss = 4.223
Epoch   8 Batch  341/575   train_loss = 4.239
Epoch   8 Batch  342/575   train_loss = 4.080
Epoch   8 Batch  343/575   train_loss = 4.569
Epoch   8 Batch  344/575   train_loss = 4.605
Epoch   8 Batch  345/575   train_loss = 4.193
Epoch   8 Batch  346/575   train_loss = 4.822
Epoch   8 Batch  347/575   train_loss = 4.059
Epoch   8 Batch  348/575   train_loss = 4.098
Epoch   8 Batch  349/575   train_loss = 3.887
Epoch   8 Batch  350/575   train_loss = 4.421
Epoch   8 Batch  351/575   train_loss = 4.742
Epoch   8 Batch  352/575   train_loss = 4.645
Epoch   8 Batch  353/575   train_loss = 4.467
Epoch   8 Batch  354/575   train_loss = 4.041
Epoch   8 Batch  355/575   train_loss = 4.716
Epoch   8 Batch  356/575   train_loss = 4.523
Epoch   8 Batch  357/575   train_loss = 4.571
Epoch   8 Batch  358/575   train_loss = 4.642
Epoch   8 Batch  359/575   train_loss = 4.765
Epoch   8 Batch  360/575   train_loss = 3.981
Epoch   8 Batch  361/575   train_loss = 4.481
Epoch   8 Batch  362/575   train_loss = 4.284
Epoch   8 Batch  363/575   train_loss = 4.396
Epoch   8 Batch  364/575   train_loss = 4.151
Epoch   8 Batch  365/575   train_loss = 4.447
Epoch   8 Batch  366/575   train_loss = 3.895
Epoch   8 Batch  367/575   train_loss = 4.163
Epoch   8 Batch  368/575   train_loss = 4.938
Epoch   8 Batch  369/575   train_loss = 4.656
Epoch   8 Batch  370/575   train_loss = 4.468
Epoch   8 Batch  371/575   train_loss = 4.461
Epoch   8 Batch  372/575   train_loss = 4.149
Epoch   8 Batch  373/575   train_loss = 4.591
Epoch   8 Batch  374/575   train_loss = 3.761
Epoch   8 Batch  375/575   train_loss = 4.151
Epoch   8 Batch  376/575   train_loss = 4.469
Epoch   8 Batch  377/575   train_loss = 4.744
Epoch   8 Batch  378/575   train_loss = 4.852
Epoch   8 Batch  379/575   train_loss = 4.299
Epoch   8 Batch  380/575   train_loss = 3.979
Epoch   8 Batch  381/575   train_loss = 4.122
Epoch   8 Batch  382/575   train_loss = 4.435
Epoch   8 Batch  383/575   train_loss = 4.210
Epoch   8 Batch  384/575   train_loss = 4.337
Epoch   8 Batch  385/575   train_loss = 4.246
Epoch   8 Batch  386/575   train_loss = 4.166
Epoch   8 Batch  387/575   train_loss = 4.734
Epoch   8 Batch  388/575   train_loss = 4.413
Epoch   8 Batch  389/575   train_loss = 4.299
Epoch   8 Batch  390/575   train_loss = 4.479
Epoch   8 Batch  391/575   train_loss = 4.500
Epoch   8 Batch  392/575   train_loss = 4.489
Epoch   8 Batch  393/575   train_loss = 4.479
Epoch   8 Batch  394/575   train_loss = 4.609
Epoch   8 Batch  395/575   train_loss = 3.808
Epoch   8 Batch  396/575   train_loss = 4.016
Epoch   8 Batch  397/575   train_loss = 4.431
Epoch   8 Batch  398/575   train_loss = 4.871
Epoch   8 Batch  399/575   train_loss = 4.762
Epoch   8 Batch  400/575   train_loss = 4.603
Epoch   8 Batch  401/575   train_loss = 4.065
Epoch   8 Batch  402/575   train_loss = 4.130
Epoch   8 Batch  403/575   train_loss = 4.511
Epoch   8 Batch  404/575   train_loss = 4.426
Epoch   8 Batch  405/575   train_loss = 4.526
Epoch   8 Batch  406/575   train_loss = 4.074
Epoch   8 Batch  407/575   train_loss = 4.453
Epoch   8 Batch  408/575   train_loss = 4.229
Epoch   8 Batch  409/575   train_loss = 4.374
Epoch   8 Batch  410/575   train_loss = 4.090
Epoch   8 Batch  411/575   train_loss = 4.545
Epoch   8 Batch  412/575   train_loss = 4.931
Epoch   8 Batch  413/575   train_loss = 4.483
Epoch   8 Batch  414/575   train_loss = 4.181
Epoch   8 Batch  415/575   train_loss = 4.624
Epoch   8 Batch  416/575   train_loss = 4.243
Epoch   8 Batch  417/575   train_loss = 4.024
Epoch   8 Batch  418/575   train_loss = 4.425
Epoch   8 Batch  419/575   train_loss = 4.279
Epoch   8 Batch  420/575   train_loss = 4.146
Epoch   8 Batch  421/575   train_loss = 4.760
Epoch   8 Batch  422/575   train_loss = 4.539
Epoch   8 Batch  423/575   train_loss = 4.802
Epoch   8 Batch  424/575   train_loss = 4.775
Epoch   8 Batch  425/575   train_loss = 4.430
Epoch   8 Batch  426/575   train_loss = 4.491
Epoch   8 Batch  427/575   train_loss = 4.400
Epoch   8 Batch  428/575   train_loss = 4.147
Epoch   8 Batch  429/575   train_loss = 4.194
Epoch   8 Batch  430/575   train_loss = 4.457
Epoch   8 Batch  431/575   train_loss = 4.328
Epoch   8 Batch  432/575   train_loss = 4.692
Epoch   8 Batch  433/575   train_loss = 4.640
Epoch   8 Batch  434/575   train_loss = 4.520
Epoch   8 Batch  435/575   train_loss = 4.246
Epoch   8 Batch  436/575   train_loss = 4.202
Epoch   8 Batch  437/575   train_loss = 4.283
Epoch   8 Batch  438/575   train_loss = 4.508
Epoch   8 Batch  439/575   train_loss = 4.491
Epoch   8 Batch  440/575   train_loss = 4.696
Epoch   8 Batch  441/575   train_loss = 4.251
Epoch   8 Batch  442/575   train_loss = 4.621
Epoch   8 Batch  443/575   train_loss = 4.458
Epoch   8 Batch  444/575   train_loss = 4.505
Epoch   8 Batch  445/575   train_loss = 4.020
Epoch   8 Batch  446/575   train_loss = 4.076
Epoch   8 Batch  447/575   train_loss = 4.548
Epoch   8 Batch  448/575   train_loss = 4.521
Epoch   8 Batch  449/575   train_loss = 4.378
Epoch   8 Batch  450/575   train_loss = 4.748
Epoch   8 Batch  451/575   train_loss = 4.808
Epoch   8 Batch  452/575   train_loss = 4.825
Epoch   8 Batch  453/575   train_loss = 4.465
Epoch   8 Batch  454/575   train_loss = 4.835
Epoch   8 Batch  455/575   train_loss = 4.111
Epoch   8 Batch  456/575   train_loss = 4.653
Epoch   8 Batch  457/575   train_loss = 3.987
Epoch   8 Batch  458/575   train_loss = 4.730
Epoch   8 Batch  459/575   train_loss = 4.419
Epoch   8 Batch  460/575   train_loss = 4.182
Epoch   8 Batch  461/575   train_loss = 4.316
Epoch   8 Batch  462/575   train_loss = 4.312
Epoch   8 Batch  463/575   train_loss = 4.153
Epoch   8 Batch  464/575   train_loss = 4.189
Epoch   8 Batch  465/575   train_loss = 4.319
Epoch   8 Batch  466/575   train_loss = 4.261
Epoch   8 Batch  467/575   train_loss = 3.718
Epoch   8 Batch  468/575   train_loss = 4.304
Epoch   8 Batch  469/575   train_loss = 4.702
Epoch   8 Batch  470/575   train_loss = 4.808
Epoch   8 Batch  471/575   train_loss = 4.192
Epoch   8 Batch  472/575   train_loss = 4.660
Epoch   8 Batch  473/575   train_loss = 4.508
Epoch   8 Batch  474/575   train_loss = 4.516
Epoch   8 Batch  475/575   train_loss = 4.165
Epoch   8 Batch  476/575   train_loss = 4.305
Epoch   8 Batch  477/575   train_loss = 4.853
Epoch   8 Batch  478/575   train_loss = 4.901
Epoch   8 Batch  479/575   train_loss = 4.208
Epoch   8 Batch  480/575   train_loss = 4.433
Epoch   8 Batch  481/575   train_loss = 4.601
Epoch   8 Batch  482/575   train_loss = 4.025
Epoch   8 Batch  483/575   train_loss = 5.033
Epoch   8 Batch  484/575   train_loss = 4.269
Epoch   8 Batch  485/575   train_loss = 4.924
Epoch   8 Batch  486/575   train_loss = 4.425
Epoch   8 Batch  487/575   train_loss = 4.699
Epoch   8 Batch  488/575   train_loss = 4.439
Epoch   8 Batch  489/575   train_loss = 4.610
Epoch   8 Batch  490/575   train_loss = 4.564
Epoch   8 Batch  491/575   train_loss = 3.961
Epoch   8 Batch  492/575   train_loss = 3.970
Epoch   8 Batch  493/575   train_loss = 3.993
Epoch   8 Batch  494/575   train_loss = 4.346
Epoch   8 Batch  495/575   train_loss = 4.296
Epoch   8 Batch  496/575   train_loss = 4.483
Epoch   8 Batch  497/575   train_loss = 4.558
Epoch   8 Batch  498/575   train_loss = 4.212
Epoch   8 Batch  499/575   train_loss = 4.215
Epoch   8 Batch  500/575   train_loss = 4.526
Epoch   8 Batch  501/575   train_loss = 4.492
Epoch   8 Batch  502/575   train_loss = 3.842
Epoch   8 Batch  503/575   train_loss = 4.731
Epoch   8 Batch  504/575   train_loss = 3.824
Epoch   8 Batch  505/575   train_loss = 4.338
Epoch   8 Batch  506/575   train_loss = 4.536
Epoch   8 Batch  507/575   train_loss = 4.672
Epoch   8 Batch  508/575   train_loss = 4.732
Epoch   8 Batch  509/575   train_loss = 4.452
Epoch   8 Batch  510/575   train_loss = 3.820
Epoch   8 Batch  511/575   train_loss = 3.953
Epoch   8 Batch  512/575   train_loss = 4.709
Epoch   8 Batch  513/575   train_loss = 4.418
Epoch   8 Batch  514/575   train_loss = 4.343
Epoch   8 Batch  515/575   train_loss = 4.374
Epoch   8 Batch  516/575   train_loss = 4.698
Epoch   8 Batch  517/575   train_loss = 3.905
Epoch   8 Batch  518/575   train_loss = 4.134
Epoch   8 Batch  519/575   train_loss = 4.303
Epoch   8 Batch  520/575   train_loss = 3.794
Epoch   8 Batch  521/575   train_loss = 4.074
Epoch   8 Batch  522/575   train_loss = 4.234
Epoch   8 Batch  523/575   train_loss = 4.560
Epoch   8 Batch  524/575   train_loss = 5.087
Epoch   8 Batch  525/575   train_loss = 4.633
Epoch   8 Batch  526/575   train_loss = 4.074
Epoch   8 Batch  527/575   train_loss = 4.658
Epoch   8 Batch  528/575   train_loss = 4.180
Epoch   8 Batch  529/575   train_loss = 4.692
Epoch   8 Batch  530/575   train_loss = 4.482
Epoch   8 Batch  531/575   train_loss = 4.588
Epoch   8 Batch  532/575   train_loss = 4.180
Epoch   8 Batch  533/575   train_loss = 4.067
Epoch   8 Batch  534/575   train_loss = 4.119
Epoch   8 Batch  535/575   train_loss = 4.376
Epoch   8 Batch  536/575   train_loss = 4.214
Epoch   8 Batch  537/575   train_loss = 4.064
Epoch   8 Batch  538/575   train_loss = 4.286
Epoch   8 Batch  539/575   train_loss = 4.172
Epoch   8 Batch  540/575   train_loss = 4.440
Epoch   8 Batch  541/575   train_loss = 4.836
Epoch   8 Batch  542/575   train_loss = 4.387
Epoch   8 Batch  543/575   train_loss = 4.455
Epoch   8 Batch  544/575   train_loss = 4.315
Epoch   8 Batch  545/575   train_loss = 4.332
Epoch   8 Batch  546/575   train_loss = 4.357
Epoch   8 Batch  547/575   train_loss = 4.385
Epoch   8 Batch  548/575   train_loss = 4.522
Epoch   8 Batch  549/575   train_loss = 4.309
Epoch   8 Batch  550/575   train_loss = 4.203
Epoch   8 Batch  551/575   train_loss = 4.092
Epoch   8 Batch  552/575   train_loss = 4.382
Epoch   8 Batch  553/575   train_loss = 4.654
Epoch   8 Batch  554/575   train_loss = 4.002
Epoch   8 Batch  555/575   train_loss = 4.246
Epoch   8 Batch  556/575   train_loss = 4.062
Epoch   8 Batch  557/575   train_loss = 4.108
Epoch   8 Batch  558/575   train_loss = 4.377
Epoch   8 Batch  559/575   train_loss = 4.517
Epoch   8 Batch  560/575   train_loss = 3.977
Epoch   8 Batch  561/575   train_loss = 4.331
Epoch   8 Batch  562/575   train_loss = 3.880
Epoch   8 Batch  563/575   train_loss = 4.231
Epoch   8 Batch  564/575   train_loss = 4.003
Epoch   8 Batch  565/575   train_loss = 3.517
Epoch   8 Batch  566/575   train_loss = 3.995
Epoch   8 Batch  567/575   train_loss = 4.159
Epoch   8 Batch  568/575   train_loss = 4.197
Epoch   8 Batch  569/575   train_loss = 4.421
Epoch   8 Batch  570/575   train_loss = 4.006
Epoch   8 Batch  571/575   train_loss = 3.792
Epoch   8 Batch  572/575   train_loss = 3.590
Epoch   8 Batch  573/575   train_loss = 3.942
Epoch   8 Batch  574/575   train_loss = 4.453
Epoch   9 Batch    0/575   train_loss = 4.189
Epoch   9 Batch    1/575   train_loss = 4.202
Epoch   9 Batch    2/575   train_loss = 4.337
Epoch   9 Batch    3/575   train_loss = 4.152
Epoch   9 Batch    4/575   train_loss = 4.066
Epoch   9 Batch    5/575   train_loss = 4.072
Epoch   9 Batch    6/575   train_loss = 3.911
Epoch   9 Batch    7/575   train_loss = 4.233
Epoch   9 Batch    8/575   train_loss = 4.112
Epoch   9 Batch    9/575   train_loss = 4.426
Epoch   9 Batch   10/575   train_loss = 3.940
Epoch   9 Batch   11/575   train_loss = 3.983
Epoch   9 Batch   12/575   train_loss = 4.173
Epoch   9 Batch   13/575   train_loss = 4.331
Epoch   9 Batch   14/575   train_loss = 4.675
Epoch   9 Batch   15/575   train_loss = 4.379
Epoch   9 Batch   16/575   train_loss = 4.272
Epoch   9 Batch   17/575   train_loss = 3.677
Epoch   9 Batch   18/575   train_loss = 4.596
Epoch   9 Batch   19/575   train_loss = 4.328
Epoch   9 Batch   20/575   train_loss = 3.691
Epoch   9 Batch   21/575   train_loss = 4.219
Epoch   9 Batch   22/575   train_loss = 4.680
Epoch   9 Batch   23/575   train_loss = 4.264
Epoch   9 Batch   24/575   train_loss = 4.176
Epoch   9 Batch   25/575   train_loss = 4.271
Epoch   9 Batch   26/575   train_loss = 4.524
Epoch   9 Batch   27/575   train_loss = 4.208
Epoch   9 Batch   28/575   train_loss = 3.814
Epoch   9 Batch   29/575   train_loss = 4.004
Epoch   9 Batch   30/575   train_loss = 4.683
Epoch   9 Batch   31/575   train_loss = 4.922
Epoch   9 Batch   32/575   train_loss = 4.348
Epoch   9 Batch   33/575   train_loss = 4.560
Epoch   9 Batch   34/575   train_loss = 4.294
Epoch   9 Batch   35/575   train_loss = 3.957
Epoch   9 Batch   36/575   train_loss = 4.561
Epoch   9 Batch   37/575   train_loss = 3.741
Epoch   9 Batch   38/575   train_loss = 4.411
Epoch   9 Batch   39/575   train_loss = 3.741
Epoch   9 Batch   40/575   train_loss = 3.642
Epoch   9 Batch   41/575   train_loss = 5.311
Epoch   9 Batch   42/575   train_loss = 4.398
Epoch   9 Batch   43/575   train_loss = 4.256
Epoch   9 Batch   44/575   train_loss = 4.118
Epoch   9 Batch   45/575   train_loss = 4.067
Epoch   9 Batch   46/575   train_loss = 4.034
Epoch   9 Batch   47/575   train_loss = 4.570
Epoch   9 Batch   48/575   train_loss = 3.753
Epoch   9 Batch   49/575   train_loss = 3.978
Epoch   9 Batch   50/575   train_loss = 4.178
Epoch   9 Batch   51/575   train_loss = 4.106
Epoch   9 Batch   52/575   train_loss = 4.104
Epoch   9 Batch   53/575   train_loss = 3.713
Epoch   9 Batch   54/575   train_loss = 4.170
Epoch   9 Batch   55/575   train_loss = 4.456
Epoch   9 Batch   56/575   train_loss = 3.895
Epoch   9 Batch   57/575   train_loss = 4.354
Epoch   9 Batch   58/575   train_loss = 3.903
Epoch   9 Batch   59/575   train_loss = 3.760
Epoch   9 Batch   60/575   train_loss = 4.232
Epoch   9 Batch   61/575   train_loss = 4.384
Epoch   9 Batch   62/575   train_loss = 3.792
Epoch   9 Batch   63/575   train_loss = 4.543
Epoch   9 Batch   64/575   train_loss = 4.487
Epoch   9 Batch   65/575   train_loss = 4.080
Epoch   9 Batch   66/575   train_loss = 4.053
Epoch   9 Batch   67/575   train_loss = 3.977
Epoch   9 Batch   68/575   train_loss = 3.965
Epoch   9 Batch   69/575   train_loss = 3.778
Epoch   9 Batch   70/575   train_loss = 4.153
Epoch   9 Batch   71/575   train_loss = 3.957
Epoch   9 Batch   72/575   train_loss = 4.466
Epoch   9 Batch   73/575   train_loss = 4.495
Epoch   9 Batch   74/575   train_loss = 4.572
Epoch   9 Batch   75/575   train_loss = 4.288
Epoch   9 Batch   76/575   train_loss = 4.480
Epoch   9 Batch   77/575   train_loss = 4.709
Epoch   9 Batch   78/575   train_loss = 4.373
Epoch   9 Batch   79/575   train_loss = 4.195
Epoch   9 Batch   80/575   train_loss = 4.194
Epoch   9 Batch   81/575   train_loss = 4.044
Epoch   9 Batch   82/575   train_loss = 3.921
Epoch   9 Batch   83/575   train_loss = 4.162
Epoch   9 Batch   84/575   train_loss = 4.136
Epoch   9 Batch   85/575   train_loss = 4.686
Epoch   9 Batch   86/575   train_loss = 4.078
Epoch   9 Batch   87/575   train_loss = 4.652
Epoch   9 Batch   88/575   train_loss = 3.632
Epoch   9 Batch   89/575   train_loss = 3.800
Epoch   9 Batch   90/575   train_loss = 3.916
Epoch   9 Batch   91/575   train_loss = 4.198
Epoch   9 Batch   92/575   train_loss = 4.678
Epoch   9 Batch   93/575   train_loss = 4.365
Epoch   9 Batch   94/575   train_loss = 3.860
Epoch   9 Batch   95/575   train_loss = 4.218
Epoch   9 Batch   96/575   train_loss = 4.234
Epoch   9 Batch   97/575   train_loss = 4.314
Epoch   9 Batch   98/575   train_loss = 4.133
Epoch   9 Batch   99/575   train_loss = 4.615
Epoch   9 Batch  100/575   train_loss = 4.393
Epoch   9 Batch  101/575   train_loss = 4.020
Epoch   9 Batch  102/575   train_loss = 3.914
Epoch   9 Batch  103/575   train_loss = 4.262
Epoch   9 Batch  104/575   train_loss = 4.219
Epoch   9 Batch  105/575   train_loss = 4.327
Epoch   9 Batch  106/575   train_loss = 4.006
Epoch   9 Batch  107/575   train_loss = 3.977
Epoch   9 Batch  108/575   train_loss = 4.350
Epoch   9 Batch  109/575   train_loss = 4.081
Epoch   9 Batch  110/575   train_loss = 3.273
Epoch   9 Batch  111/575   train_loss = 4.218
Epoch   9 Batch  112/575   train_loss = 4.216
Epoch   9 Batch  113/575   train_loss = 4.754
Epoch   9 Batch  114/575   train_loss = 4.464
Epoch   9 Batch  115/575   train_loss = 4.015
Epoch   9 Batch  116/575   train_loss = 4.407
Epoch   9 Batch  117/575   train_loss = 3.876
Epoch   9 Batch  118/575   train_loss = 4.179
Epoch   9 Batch  119/575   train_loss = 4.688
Epoch   9 Batch  120/575   train_loss = 4.317
Epoch   9 Batch  121/575   train_loss = 4.292
Epoch   9 Batch  122/575   train_loss = 4.453
Epoch   9 Batch  123/575   train_loss = 4.149
Epoch   9 Batch  124/575   train_loss = 4.493
Epoch   9 Batch  125/575   train_loss = 4.288
Epoch   9 Batch  126/575   train_loss = 4.129
Epoch   9 Batch  127/575   train_loss = 3.771
Epoch   9 Batch  128/575   train_loss = 4.253
Epoch   9 Batch  129/575   train_loss = 4.157
Epoch   9 Batch  130/575   train_loss = 4.494
Epoch   9 Batch  131/575   train_loss = 3.675
Epoch   9 Batch  132/575   train_loss = 4.153
Epoch   9 Batch  133/575   train_loss = 4.244
Epoch   9 Batch  134/575   train_loss = 4.180
Epoch   9 Batch  135/575   train_loss = 3.776
Epoch   9 Batch  136/575   train_loss = 4.957
Epoch   9 Batch  137/575   train_loss = 4.494
Epoch   9 Batch  138/575   train_loss = 4.717
Epoch   9 Batch  139/575   train_loss = 4.259
Epoch   9 Batch  140/575   train_loss = 4.283
Epoch   9 Batch  141/575   train_loss = 4.598
Epoch   9 Batch  142/575   train_loss = 4.607
Epoch   9 Batch  143/575   train_loss = 4.403
Epoch   9 Batch  144/575   train_loss = 3.983
Epoch   9 Batch  145/575   train_loss = 3.942
Epoch   9 Batch  146/575   train_loss = 3.972
Epoch   9 Batch  147/575   train_loss = 4.128
Epoch   9 Batch  148/575   train_loss = 3.700
Epoch   9 Batch  149/575   train_loss = 4.352
Epoch   9 Batch  150/575   train_loss = 4.536
Epoch   9 Batch  151/575   train_loss = 3.943
Epoch   9 Batch  152/575   train_loss = 3.865
Epoch   9 Batch  153/575   train_loss = 3.437
Epoch   9 Batch  154/575   train_loss = 3.617
Epoch   9 Batch  155/575   train_loss = 4.259
Epoch   9 Batch  156/575   train_loss = 4.197
Epoch   9 Batch  157/575   train_loss = 4.220
Epoch   9 Batch  158/575   train_loss = 4.256
Epoch   9 Batch  159/575   train_loss = 4.342
Epoch   9 Batch  160/575   train_loss = 4.033
Epoch   9 Batch  161/575   train_loss = 4.445
Epoch   9 Batch  162/575   train_loss = 4.346
Epoch   9 Batch  163/575   train_loss = 4.177
Epoch   9 Batch  164/575   train_loss = 4.465
Epoch   9 Batch  165/575   train_loss = 4.297
Epoch   9 Batch  166/575   train_loss = 4.005
Epoch   9 Batch  167/575   train_loss = 3.940
Epoch   9 Batch  168/575   train_loss = 4.333
Epoch   9 Batch  169/575   train_loss = 4.055
Epoch   9 Batch  170/575   train_loss = 4.338
Epoch   9 Batch  171/575   train_loss = 4.093
Epoch   9 Batch  172/575   train_loss = 4.271
Epoch   9 Batch  173/575   train_loss = 4.230
Epoch   9 Batch  174/575   train_loss = 4.468
Epoch   9 Batch  175/575   train_loss = 4.210
Epoch   9 Batch  176/575   train_loss = 4.275
Epoch   9 Batch  177/575   train_loss = 4.202
Epoch   9 Batch  178/575   train_loss = 4.185
Epoch   9 Batch  179/575   train_loss = 3.935
Epoch   9 Batch  180/575   train_loss = 4.014
Epoch   9 Batch  181/575   train_loss = 4.236
Epoch   9 Batch  182/575   train_loss = 4.099
Epoch   9 Batch  183/575   train_loss = 4.342
Epoch   9 Batch  184/575   train_loss = 3.538
Epoch   9 Batch  185/575   train_loss = 4.154
Epoch   9 Batch  186/575   train_loss = 4.234
Epoch   9 Batch  187/575   train_loss = 4.178
Epoch   9 Batch  188/575   train_loss = 4.084
Epoch   9 Batch  189/575   train_loss = 4.150
Epoch   9 Batch  190/575   train_loss = 4.069
Epoch   9 Batch  191/575   train_loss = 4.627
Epoch   9 Batch  192/575   train_loss = 4.381
Epoch   9 Batch  193/575   train_loss = 4.212
Epoch   9 Batch  194/575   train_loss = 4.318
Epoch   9 Batch  195/575   train_loss = 3.910
Epoch   9 Batch  196/575   train_loss = 4.039
Epoch   9 Batch  197/575   train_loss = 3.962
Epoch   9 Batch  198/575   train_loss = 4.413
Epoch   9 Batch  199/575   train_loss = 3.730
Epoch   9 Batch  200/575   train_loss = 3.993
Epoch   9 Batch  201/575   train_loss = 4.213
Epoch   9 Batch  202/575   train_loss = 3.949
Epoch   9 Batch  203/575   train_loss = 4.126
Epoch   9 Batch  204/575   train_loss = 4.040
Epoch   9 Batch  205/575   train_loss = 3.843
Epoch   9 Batch  206/575   train_loss = 4.079
Epoch   9 Batch  207/575   train_loss = 3.999
Epoch   9 Batch  208/575   train_loss = 3.901
Epoch   9 Batch  209/575   train_loss = 3.981
Epoch   9 Batch  210/575   train_loss = 4.314
Epoch   9 Batch  211/575   train_loss = 4.685
Epoch   9 Batch  212/575   train_loss = 4.379
Epoch   9 Batch  213/575   train_loss = 4.230
Epoch   9 Batch  214/575   train_loss = 3.958
Epoch   9 Batch  215/575   train_loss = 3.557
Epoch   9 Batch  216/575   train_loss = 3.862
Epoch   9 Batch  217/575   train_loss = 3.639
Epoch   9 Batch  218/575   train_loss = 4.325
Epoch   9 Batch  219/575   train_loss = 3.880
Epoch   9 Batch  220/575   train_loss = 3.621
Epoch   9 Batch  221/575   train_loss = 4.088
Epoch   9 Batch  222/575   train_loss = 4.174
Epoch   9 Batch  223/575   train_loss = 4.436
Epoch   9 Batch  224/575   train_loss = 3.793
Epoch   9 Batch  225/575   train_loss = 3.874
Epoch   9 Batch  226/575   train_loss = 4.294
Epoch   9 Batch  227/575   train_loss = 4.558
Epoch   9 Batch  228/575   train_loss = 4.366
Epoch   9 Batch  229/575   train_loss = 3.582
Epoch   9 Batch  230/575   train_loss = 3.704
Epoch   9 Batch  231/575   train_loss = 4.146
Epoch   9 Batch  232/575   train_loss = 4.322
Epoch   9 Batch  233/575   train_loss = 4.176
Epoch   9 Batch  234/575   train_loss = 4.294
Epoch   9 Batch  235/575   train_loss = 4.096
Epoch   9 Batch  236/575   train_loss = 3.626
Epoch   9 Batch  237/575   train_loss = 3.874
Epoch   9 Batch  238/575   train_loss = 3.905
Epoch   9 Batch  239/575   train_loss = 4.181
Epoch   9 Batch  240/575   train_loss = 4.404
Epoch   9 Batch  241/575   train_loss = 4.448
Epoch   9 Batch  242/575   train_loss = 4.081
Epoch   9 Batch  243/575   train_loss = 4.140
Epoch   9 Batch  244/575   train_loss = 4.061
Epoch   9 Batch  245/575   train_loss = 4.244
Epoch   9 Batch  246/575   train_loss = 4.457
Epoch   9 Batch  247/575   train_loss = 4.191
Epoch   9 Batch  248/575   train_loss = 4.247
Epoch   9 Batch  249/575   train_loss = 4.120
Epoch   9 Batch  250/575   train_loss = 4.091
Epoch   9 Batch  251/575   train_loss = 4.130
Epoch   9 Batch  252/575   train_loss = 4.518
Epoch   9 Batch  253/575   train_loss = 4.168
Epoch   9 Batch  254/575   train_loss = 3.831
Epoch   9 Batch  255/575   train_loss = 4.366
Epoch   9 Batch  256/575   train_loss = 4.028
Epoch   9 Batch  257/575   train_loss = 4.169
Epoch   9 Batch  258/575   train_loss = 4.535
Epoch   9 Batch  259/575   train_loss = 3.671
Epoch   9 Batch  260/575   train_loss = 3.978
Epoch   9 Batch  261/575   train_loss = 4.583
Epoch   9 Batch  262/575   train_loss = 4.362
Epoch   9 Batch  263/575   train_loss = 4.318
Epoch   9 Batch  264/575   train_loss = 3.562
Epoch   9 Batch  265/575   train_loss = 3.554
Epoch   9 Batch  266/575   train_loss = 3.675
Epoch   9 Batch  267/575   train_loss = 4.169
Epoch   9 Batch  268/575   train_loss = 4.101
Epoch   9 Batch  269/575   train_loss = 4.299
Epoch   9 Batch  270/575   train_loss = 4.651
Epoch   9 Batch  271/575   train_loss = 3.846
Epoch   9 Batch  272/575   train_loss = 4.379
Epoch   9 Batch  273/575   train_loss = 4.364
Epoch   9 Batch  274/575   train_loss = 4.299
Epoch   9 Batch  275/575   train_loss = 4.100
Epoch   9 Batch  276/575   train_loss = 4.663
Epoch   9 Batch  277/575   train_loss = 3.521
Epoch   9 Batch  278/575   train_loss = 4.274
Epoch   9 Batch  279/575   train_loss = 4.422
Epoch   9 Batch  280/575   train_loss = 4.351
Epoch   9 Batch  281/575   train_loss = 4.027
Epoch   9 Batch  282/575   train_loss = 4.337
Epoch   9 Batch  283/575   train_loss = 4.488
Epoch   9 Batch  284/575   train_loss = 4.591
Epoch   9 Batch  285/575   train_loss = 3.891
Epoch   9 Batch  286/575   train_loss = 4.216
Epoch   9 Batch  287/575   train_loss = 4.296
Epoch   9 Batch  288/575   train_loss = 4.137
Epoch   9 Batch  289/575   train_loss = 4.175
Epoch   9 Batch  290/575   train_loss = 4.193
Epoch   9 Batch  291/575   train_loss = 4.687
Epoch   9 Batch  292/575   train_loss = 4.729
Epoch   9 Batch  293/575   train_loss = 4.796
Epoch   9 Batch  294/575   train_loss = 4.453
Epoch   9 Batch  295/575   train_loss = 4.116
Epoch   9 Batch  296/575   train_loss = 4.353
Epoch   9 Batch  297/575   train_loss = 4.226
Epoch   9 Batch  298/575   train_loss = 4.418
Epoch   9 Batch  299/575   train_loss = 4.333
Epoch   9 Batch  300/575   train_loss = 4.282
Epoch   9 Batch  301/575   train_loss = 4.070
Epoch   9 Batch  302/575   train_loss = 4.434
Epoch   9 Batch  303/575   train_loss = 4.056
Epoch   9 Batch  304/575   train_loss = 4.057
Epoch   9 Batch  305/575   train_loss = 4.056
Epoch   9 Batch  306/575   train_loss = 4.301
Epoch   9 Batch  307/575   train_loss = 4.310
Epoch   9 Batch  308/575   train_loss = 4.216
Epoch   9 Batch  309/575   train_loss = 4.460
Epoch   9 Batch  310/575   train_loss = 4.565
Epoch   9 Batch  311/575   train_loss = 3.980
Epoch   9 Batch  312/575   train_loss = 4.263
Epoch   9 Batch  313/575   train_loss = 4.547
Epoch   9 Batch  314/575   train_loss = 4.512
Epoch   9 Batch  315/575   train_loss = 4.651
Epoch   9 Batch  316/575   train_loss = 4.118
Epoch   9 Batch  317/575   train_loss = 3.879
Epoch   9 Batch  318/575   train_loss = 3.602
Epoch   9 Batch  319/575   train_loss = 4.242
Epoch   9 Batch  320/575   train_loss = 4.126
Epoch   9 Batch  321/575   train_loss = 4.432
Epoch   9 Batch  322/575   train_loss = 4.158
Epoch   9 Batch  323/575   train_loss = 4.710
Epoch   9 Batch  324/575   train_loss = 4.158
Epoch   9 Batch  325/575   train_loss = 4.291
Epoch   9 Batch  326/575   train_loss = 4.049
Epoch   9 Batch  327/575   train_loss = 4.392
Epoch   9 Batch  328/575   train_loss = 3.971
Epoch   9 Batch  329/575   train_loss = 4.662
Epoch   9 Batch  330/575   train_loss = 4.301
Epoch   9 Batch  331/575   train_loss = 4.656
Epoch   9 Batch  332/575   train_loss = 4.283
Epoch   9 Batch  333/575   train_loss = 4.268
Epoch   9 Batch  334/575   train_loss = 4.214
Epoch   9 Batch  335/575   train_loss = 3.947
Epoch   9 Batch  336/575   train_loss = 4.304
Epoch   9 Batch  337/575   train_loss = 4.101
Epoch   9 Batch  338/575   train_loss = 3.948
Epoch   9 Batch  339/575   train_loss = 4.298
Epoch   9 Batch  340/575   train_loss = 4.099
Epoch   9 Batch  341/575   train_loss = 4.115
Epoch   9 Batch  342/575   train_loss = 3.987
Epoch   9 Batch  343/575   train_loss = 4.444
Epoch   9 Batch  344/575   train_loss = 4.505
Epoch   9 Batch  345/575   train_loss = 4.105
Epoch   9 Batch  346/575   train_loss = 4.678
Epoch   9 Batch  347/575   train_loss = 3.978
Epoch   9 Batch  348/575   train_loss = 3.973
Epoch   9 Batch  349/575   train_loss = 3.809
Epoch   9 Batch  350/575   train_loss = 4.278
Epoch   9 Batch  351/575   train_loss = 4.590
Epoch   9 Batch  352/575   train_loss = 4.506
Epoch   9 Batch  353/575   train_loss = 4.339
Epoch   9 Batch  354/575   train_loss = 3.896
Epoch   9 Batch  355/575   train_loss = 4.586
Epoch   9 Batch  356/575   train_loss = 4.397
Epoch   9 Batch  357/575   train_loss = 4.516
Epoch   9 Batch  358/575   train_loss = 4.507
Epoch   9 Batch  359/575   train_loss = 4.622
Epoch   9 Batch  360/575   train_loss = 3.893
Epoch   9 Batch  361/575   train_loss = 4.357
Epoch   9 Batch  362/575   train_loss = 4.182
Epoch   9 Batch  363/575   train_loss = 4.287
Epoch   9 Batch  364/575   train_loss = 4.060
Epoch   9 Batch  365/575   train_loss = 4.333
Epoch   9 Batch  366/575   train_loss = 3.796
Epoch   9 Batch  367/575   train_loss = 4.074
Epoch   9 Batch  368/575   train_loss = 4.802
Epoch   9 Batch  369/575   train_loss = 4.534
Epoch   9 Batch  370/575   train_loss = 4.342
Epoch   9 Batch  371/575   train_loss = 4.341
Epoch   9 Batch  372/575   train_loss = 4.033
Epoch   9 Batch  373/575   train_loss = 4.450
Epoch   9 Batch  374/575   train_loss = 3.661
Epoch   9 Batch  375/575   train_loss = 4.055
Epoch   9 Batch  376/575   train_loss = 4.330
Epoch   9 Batch  377/575   train_loss = 4.621
Epoch   9 Batch  378/575   train_loss = 4.739
Epoch   9 Batch  379/575   train_loss = 4.238
Epoch   9 Batch  380/575   train_loss = 3.902
Epoch   9 Batch  381/575   train_loss = 4.017
Epoch   9 Batch  382/575   train_loss = 4.313
Epoch   9 Batch  383/575   train_loss = 4.087
Epoch   9 Batch  384/575   train_loss = 4.199
Epoch   9 Batch  385/575   train_loss = 4.140
Epoch   9 Batch  386/575   train_loss = 4.058
Epoch   9 Batch  387/575   train_loss = 4.602
Epoch   9 Batch  388/575   train_loss = 4.301
Epoch   9 Batch  389/575   train_loss = 4.185
Epoch   9 Batch  390/575   train_loss = 4.341
Epoch   9 Batch  391/575   train_loss = 4.372
Epoch   9 Batch  392/575   train_loss = 4.400
Epoch   9 Batch  393/575   train_loss = 4.410
Epoch   9 Batch  394/575   train_loss = 4.473
Epoch   9 Batch  395/575   train_loss = 3.728
Epoch   9 Batch  396/575   train_loss = 3.875
Epoch   9 Batch  397/575   train_loss = 4.296
Epoch   9 Batch  398/575   train_loss = 4.738
Epoch   9 Batch  399/575   train_loss = 4.622
Epoch   9 Batch  400/575   train_loss = 4.472
Epoch   9 Batch  401/575   train_loss = 3.988
Epoch   9 Batch  402/575   train_loss = 4.038
Epoch   9 Batch  403/575   train_loss = 4.384
Epoch   9 Batch  404/575   train_loss = 4.312
Epoch   9 Batch  405/575   train_loss = 4.429
Epoch   9 Batch  406/575   train_loss = 3.974
Epoch   9 Batch  407/575   train_loss = 4.355
Epoch   9 Batch  408/575   train_loss = 4.103
Epoch   9 Batch  409/575   train_loss = 4.274
Epoch   9 Batch  410/575   train_loss = 3.981
Epoch   9 Batch  411/575   train_loss = 4.475
Epoch   9 Batch  412/575   train_loss = 4.799
Epoch   9 Batch  413/575   train_loss = 4.319
Epoch   9 Batch  414/575   train_loss = 4.048
Epoch   9 Batch  415/575   train_loss = 4.460
Epoch   9 Batch  416/575   train_loss = 4.120
Epoch   9 Batch  417/575   train_loss = 3.922
Epoch   9 Batch  418/575   train_loss = 4.292
Epoch   9 Batch  419/575   train_loss = 4.175
Epoch   9 Batch  420/575   train_loss = 4.041
Epoch   9 Batch  421/575   train_loss = 4.618
Epoch   9 Batch  422/575   train_loss = 4.433
Epoch   9 Batch  423/575   train_loss = 4.682
Epoch   9 Batch  424/575   train_loss = 4.608
Epoch   9 Batch  425/575   train_loss = 4.221
Epoch   9 Batch  426/575   train_loss = 4.405
Epoch   9 Batch  427/575   train_loss = 4.292
Epoch   9 Batch  428/575   train_loss = 3.991
Epoch   9 Batch  429/575   train_loss = 4.135
Epoch   9 Batch  430/575   train_loss = 4.370
Epoch   9 Batch  431/575   train_loss = 4.214
Epoch   9 Batch  432/575   train_loss = 4.565
Epoch   9 Batch  433/575   train_loss = 4.538
Epoch   9 Batch  434/575   train_loss = 4.400
Epoch   9 Batch  435/575   train_loss = 4.111
Epoch   9 Batch  436/575   train_loss = 4.127
Epoch   9 Batch  437/575   train_loss = 4.174
Epoch   9 Batch  438/575   train_loss = 4.382
Epoch   9 Batch  439/575   train_loss = 4.410
Epoch   9 Batch  440/575   train_loss = 4.560
Epoch   9 Batch  441/575   train_loss = 4.132
Epoch   9 Batch  442/575   train_loss = 4.490
Epoch   9 Batch  443/575   train_loss = 4.333
Epoch   9 Batch  444/575   train_loss = 4.368
Epoch   9 Batch  445/575   train_loss = 3.857
Epoch   9 Batch  446/575   train_loss = 3.977
Epoch   9 Batch  447/575   train_loss = 4.436
Epoch   9 Batch  448/575   train_loss = 4.437
Epoch   9 Batch  449/575   train_loss = 4.252
Epoch   9 Batch  450/575   train_loss = 4.590
Epoch   9 Batch  451/575   train_loss = 4.666
Epoch   9 Batch  452/575   train_loss = 4.618
Epoch   9 Batch  453/575   train_loss = 4.320
Epoch   9 Batch  454/575   train_loss = 4.733
Epoch   9 Batch  455/575   train_loss = 4.011
Epoch   9 Batch  456/575   train_loss = 4.497
Epoch   9 Batch  457/575   train_loss = 3.850
Epoch   9 Batch  458/575   train_loss = 4.607
Epoch   9 Batch  459/575   train_loss = 4.294
Epoch   9 Batch  460/575   train_loss = 4.045
Epoch   9 Batch  461/575   train_loss = 4.163
Epoch   9 Batch  462/575   train_loss = 4.184
Epoch   9 Batch  463/575   train_loss = 4.007
Epoch   9 Batch  464/575   train_loss = 4.090
Epoch   9 Batch  465/575   train_loss = 4.218
Epoch   9 Batch  466/575   train_loss = 4.133
Epoch   9 Batch  467/575   train_loss = 3.608
Epoch   9 Batch  468/575   train_loss = 4.242
Epoch   9 Batch  469/575   train_loss = 4.585
Epoch   9 Batch  470/575   train_loss = 4.669
Epoch   9 Batch  471/575   train_loss = 4.085
Epoch   9 Batch  472/575   train_loss = 4.538
Epoch   9 Batch  473/575   train_loss = 4.391
Epoch   9 Batch  474/575   train_loss = 4.404
Epoch   9 Batch  475/575   train_loss = 4.051
Epoch   9 Batch  476/575   train_loss = 4.205
Epoch   9 Batch  477/575   train_loss = 4.732
Epoch   9 Batch  478/575   train_loss = 4.754
Epoch   9 Batch  479/575   train_loss = 4.081
Epoch   9 Batch  480/575   train_loss = 4.300
Epoch   9 Batch  481/575   train_loss = 4.472
Epoch   9 Batch  482/575   train_loss = 3.928
Epoch   9 Batch  483/575   train_loss = 4.861
Epoch   9 Batch  484/575   train_loss = 4.134
Epoch   9 Batch  485/575   train_loss = 4.791
Epoch   9 Batch  486/575   train_loss = 4.351
Epoch   9 Batch  487/575   train_loss = 4.574
Epoch   9 Batch  488/575   train_loss = 4.351
Epoch   9 Batch  489/575   train_loss = 4.512
Epoch   9 Batch  490/575   train_loss = 4.440
Epoch   9 Batch  491/575   train_loss = 3.883
Epoch   9 Batch  492/575   train_loss = 3.892
Epoch   9 Batch  493/575   train_loss = 3.898
Epoch   9 Batch  494/575   train_loss = 4.262
Epoch   9 Batch  495/575   train_loss = 4.195
Epoch   9 Batch  496/575   train_loss = 4.370
Epoch   9 Batch  497/575   train_loss = 4.417
Epoch   9 Batch  498/575   train_loss = 4.106
Epoch   9 Batch  499/575   train_loss = 4.077
Epoch   9 Batch  500/575   train_loss = 4.434
Epoch   9 Batch  501/575   train_loss = 4.382
Epoch   9 Batch  502/575   train_loss = 3.748
Epoch   9 Batch  503/575   train_loss = 4.659
Epoch   9 Batch  504/575   train_loss = 3.726
Epoch   9 Batch  505/575   train_loss = 4.244
Epoch   9 Batch  506/575   train_loss = 4.404
Epoch   9 Batch  507/575   train_loss = 4.540
Epoch   9 Batch  508/575   train_loss = 4.589
Epoch   9 Batch  509/575   train_loss = 4.382
Epoch   9 Batch  510/575   train_loss = 3.742
Epoch   9 Batch  511/575   train_loss = 3.883
Epoch   9 Batch  512/575   train_loss = 4.564
Epoch   9 Batch  513/575   train_loss = 4.277
Epoch   9 Batch  514/575   train_loss = 4.249
Epoch   9 Batch  515/575   train_loss = 4.258
Epoch   9 Batch  516/575   train_loss = 4.547
Epoch   9 Batch  517/575   train_loss = 3.789
Epoch   9 Batch  518/575   train_loss = 4.046
Epoch   9 Batch  519/575   train_loss = 4.168
Epoch   9 Batch  520/575   train_loss = 3.718
Epoch   9 Batch  521/575   train_loss = 3.951
Epoch   9 Batch  522/575   train_loss = 4.146
Epoch   9 Batch  523/575   train_loss = 4.384
Epoch   9 Batch  524/575   train_loss = 4.868
Epoch   9 Batch  525/575   train_loss = 4.529
Epoch   9 Batch  526/575   train_loss = 3.973
Epoch   9 Batch  527/575   train_loss = 4.555
Epoch   9 Batch  528/575   train_loss = 4.049
Epoch   9 Batch  529/575   train_loss = 4.618
Epoch   9 Batch  530/575   train_loss = 4.363
Epoch   9 Batch  531/575   train_loss = 4.457
Epoch   9 Batch  532/575   train_loss = 4.063
Epoch   9 Batch  533/575   train_loss = 3.921
Epoch   9 Batch  534/575   train_loss = 3.995
Epoch   9 Batch  535/575   train_loss = 4.250
Epoch   9 Batch  536/575   train_loss = 4.034
Epoch   9 Batch  537/575   train_loss = 3.968
Epoch   9 Batch  538/575   train_loss = 4.172
Epoch   9 Batch  539/575   train_loss = 4.080
Epoch   9 Batch  540/575   train_loss = 4.315
Epoch   9 Batch  541/575   train_loss = 4.691
Epoch   9 Batch  542/575   train_loss = 4.272
Epoch   9 Batch  543/575   train_loss = 4.328
Epoch   9 Batch  544/575   train_loss = 4.181
Epoch   9 Batch  545/575   train_loss = 4.204
Epoch   9 Batch  546/575   train_loss = 4.254
Epoch   9 Batch  547/575   train_loss = 4.275
Epoch   9 Batch  548/575   train_loss = 4.428
Epoch   9 Batch  549/575   train_loss = 4.220
Epoch   9 Batch  550/575   train_loss = 4.081
Epoch   9 Batch  551/575   train_loss = 3.994
Epoch   9 Batch  552/575   train_loss = 4.258
Epoch   9 Batch  553/575   train_loss = 4.564
Epoch   9 Batch  554/575   train_loss = 3.875
Epoch   9 Batch  555/575   train_loss = 4.075
Epoch   9 Batch  556/575   train_loss = 3.954
Epoch   9 Batch  557/575   train_loss = 4.001
Epoch   9 Batch  558/575   train_loss = 4.287
Epoch   9 Batch  559/575   train_loss = 4.392
Epoch   9 Batch  560/575   train_loss = 3.882
Epoch   9 Batch  561/575   train_loss = 4.225
Epoch   9 Batch  562/575   train_loss = 3.804
Epoch   9 Batch  563/575   train_loss = 4.123
Epoch   9 Batch  564/575   train_loss = 3.921
Epoch   9 Batch  565/575   train_loss = 3.440
Epoch   9 Batch  566/575   train_loss = 3.866
Epoch   9 Batch  567/575   train_loss = 4.086
Epoch   9 Batch  568/575   train_loss = 4.120
Epoch   9 Batch  569/575   train_loss = 4.353
Epoch   9 Batch  570/575   train_loss = 3.896
Epoch   9 Batch  571/575   train_loss = 3.684
Epoch   9 Batch  572/575   train_loss = 3.501
Epoch   9 Batch  573/575   train_loss = 3.832
Epoch   9 Batch  574/575   train_loss = 4.339
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h2><p>Save <code>seq_length</code> and <code>save_dir</code> for generating a new TV script.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">((</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">,</span> <span class="n">int_to_vocab</span><span class="p">,</span> <span class="n">token_dict</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">seq_length</span><span class="p">,</span> <span class="n">load_dir</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Generate-Functions">Implement Generate Functions<a class="anchor-link" href="#Implement-Generate-Functions">&#182;</a></h2><h3 id="Get-Tensors">Get Tensors<a class="anchor-link" href="#Get-Tensors">&#182;</a></h3><p>Get tensors from <code>loaded_graph</code> using the function <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#get_tensor_by_name"><code>get_tensor_by_name()</code></a>.  Get the tensors using the following names:</p>
<ul>
<li>"input:0"</li>
<li>"initial_state:0"</li>
<li>"final_state:0"</li>
<li>"probs:0"</li>
</ul>
<p>Return the tensors in the following tuple <code>(InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_tensors</span><span class="p">(</span><span class="n">loaded_graph</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get input, initial state, final state, and probabilities tensor from &lt;loaded_graph&gt;</span>
<span class="sd">    :param loaded_graph: TensorFlow graph loaded from file</span>
<span class="sd">    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">initial_state</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;initial_state:0&#39;</span><span class="p">)</span>
    <span class="n">final_state</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;final_state:0&#39;</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;probs:0&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inp</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">probs</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_tensors</span><span class="p">(</span><span class="n">get_tensors</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Choose-Word">Choose Word<a class="anchor-link" href="#Choose-Word">&#182;</a></h3><p>Implement the <code>pick_word()</code> function to select the next word using <code>probabilities</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">pick_word</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">int_to_vocab</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pick the next word in the generated text</span>
<span class="sd">    :param probabilities: Probabilites of the next word</span>
<span class="sd">    :param int_to_vocab: Dictionary of word ids as the keys and words as the values</span>
<span class="sd">    :return: String of the predicted word</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1"># print(probabilities)</span>
    <span class="c1"># print(int_to_vocab)</span>
    
    <span class="k">return</span> <span class="n">int_to_vocab</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)]</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_pick_word</span><span class="p">(</span><span class="n">pick_word</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Generate-TV-Script">Generate TV Script<a class="anchor-link" href="#Generate-TV-Script">&#182;</a></h2><p>This will generate the TV script for you.  Set <code>gen_length</code> to the length of TV script you want to generate.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gen_length</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1"># homer_simpson, moe_szyslak, or Barney_Gumble</span>
<span class="n">prime_word</span> <span class="o">=</span> <span class="s1">&#39;moe_szyslak&#39;</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_dir</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_dir</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loader stored&#39;</span><span class="p">)</span>

    <span class="c1"># Get Tensors from loaded model</span>
    <span class="n">input_text</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">get_tensors</span><span class="p">(</span><span class="n">loaded_graph</span><span class="p">)</span>

    <span class="c1"># Sentences generation setup</span>
    <span class="n">gen_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">prime_word</span> <span class="o">+</span> <span class="s1">&#39;:&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;gen_sentences&#39;</span><span class="p">,</span> <span class="n">gen_sentences</span><span class="p">)</span>
    <span class="n">prev_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">initial_state</span><span class="p">,</span> <span class="p">{</span><span class="n">input_text</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])})</span>

    <span class="c1"># Generate sentences</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gen_length</span><span class="p">):</span>
        <span class="c1"># Dynamic Input</span>
        <span class="n">dyn_input</span> <span class="o">=</span> <span class="p">[[</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">gen_sentences</span><span class="p">[</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:]]]</span>
        <span class="c1"># print(&#39;dyn_input&#39;, dyn_input)</span>
        <span class="n">dyn_seq_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dyn_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># print(&#39;run prediction&#39;)</span>
        <span class="c1"># Get Prediction</span>
        <span class="n">probabilities</span><span class="p">,</span> <span class="n">prev_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="p">[</span><span class="n">probs</span><span class="p">,</span> <span class="n">final_state</span><span class="p">],</span>
            <span class="p">{</span><span class="n">input_text</span><span class="p">:</span> <span class="n">dyn_input</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">:</span> <span class="n">prev_state</span><span class="p">})</span>
        <span class="c1"># print(&#39;prediction done&#39;)</span>
        
        <span class="n">pred_word</span> <span class="o">=</span> <span class="n">pick_word</span><span class="p">(</span><span class="n">probabilities</span><span class="p">[</span><span class="n">dyn_seq_length</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">int_to_vocab</span><span class="p">)</span>
        <span class="c1"># print(pred_word)</span>

        <span class="n">gen_sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_word</span><span class="p">)</span>
    
    <span class="c1"># print(&#39;sentences generated&#39;, gen_sentences)</span>
    <span class="c1"># Remove tokens</span>
    <span class="n">tv_script</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gen_sentences</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">token_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">ending</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;(&#39;</span><span class="p">,</span> <span class="s1">&#39;&quot;&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="n">tv_script</span> <span class="o">=</span> <span class="n">tv_script</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="n">key</span><span class="p">)</span>
    <span class="n">tv_script</span> <span class="o">=</span> <span class="n">tv_script</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> &#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">tv_script</span> <span class="o">=</span> <span class="n">tv_script</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;( &#39;</span><span class="p">,</span> <span class="s1">&#39;(&#39;</span><span class="p">)</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="n">tv_script</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>loader stored
gen_sentences [&#39;moe_szyslak:&#39;]
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh, i got a bar.
moe_szyslak:(to phone) oh
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="The-TV-Script-is-Nonsensical">The TV Script is Nonsensical<a class="anchor-link" href="#The-TV-Script-is-Nonsensical">&#182;</a></h1><p>It's ok if the TV script doesn't make any sense.  We trained on less than a megabyte of text.  In order to get good results, you'll have to use a smaller vocabulary or get more data.  Luckly there's more data!  As we mentioned in the begging of this project, this is a subset of <a href="https://www.kaggle.com/wcukierski/the-simpsons-by-the-data">another dataset</a>.  We didn't have you train on all the data, because that would take too long.  However, you are free to train your neural network on all the data.  After you complete the project, of course.</p>
<h1 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h1><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_tv_script_generation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
